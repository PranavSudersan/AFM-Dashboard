{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def189e8-b539-409b-a4e1-401ce180bf2d",
   "metadata": {},
   "source": [
    "# AFM DASHBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847284ca-8263-4285-a8fc-3dfb5acb05e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab57d58-1341-49d2-bb0d-cf6363836c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib ipympl\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.subplots as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import itables\n",
    "from itables.widget import ITable\n",
    "from itables import init_notebook_mode\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import display, HTML, Image, clear_output\n",
    "from tkinter import filedialog\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simpson\n",
    "from scipy.optimize import fsolve\n",
    "from numba import njit\n",
    "from pathlib import Path\n",
    "import threading\n",
    "\n",
    "from wsxm_read import *\n",
    "from wsxm_analyze import *\n",
    "from plot_funcs import *\n",
    "import transform_funcs as tsf\n",
    "from gui_functions import custom_filedialog\n",
    "from Sader_GCI_demo import SaderGCI_GetLeverList\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "#initial configuration\n",
    "\n",
    "#theme\n",
    "set_theme('dark') #'dark','light\n",
    "\n",
    "#units\n",
    "unit_dict = {\n",
    "    'X': 'nm', # 'Å', 'nm', 'µm' \n",
    "    'Y': 'nm', # 'Å', 'nm', 'µm' \n",
    "    'Z': 'nm', # 'Å', 'nm', 'µm' \n",
    "    'Topography': 'nm', # 'Å', 'nm', 'µm' \n",
    "    'Normal force': 'nN', # 'V', 'nN'\n",
    "    'Normal deflection': 'nm', # 'V', 'nm'\n",
    "    'Amplitude': 'V', # 'V', 'nm'\n",
    "    'True Amplitude': 'nm', # 'V', 'nm'\n",
    "    'Amplitude dissipated': 'nm',\n",
    "    'Amplitude-sample distance': 'nm',\n",
    "    'Excitation frequency': 'Hz', # 'V', 'Hz', 'kHz'\n",
    "    'Frequency shift': 'Hz',\n",
    "    'Phase': 'V', # 'V'\n",
    "    'True Phase': '°', # 'V', '°',             \n",
    "    'Sample deformation': 'nm',\n",
    "    'Energy dissipated': 'aJ', #'V2', 'aJ'\n",
    "    'Spring constant': 'N/m',\n",
    "    'Resonance frequency': 'Hz',\n",
    "    'Quality factor': '',\n",
    "    'X-Y components': 'V',\n",
    "    '2nd Feedback Out': 'V',\n",
    "    'Lateral force': 'V',\n",
    "            }\n",
    "\n",
    "if unit_dict['Z'] != unit_dict['Normal deflection']:\n",
    "    print(\"WARNING! Tip-sample distance won't be calculated correctly because Z and Normal deflection units don't match! Please check unit_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5c1f1-44c9-409b-a6e1-87050add304b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FILE BROWSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ec2b5-2969-436e-a513-4f2bb420a3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folderpath = filedialog.askdirectory(initialdir='/home/pranav/Work/Data/Murcia/AFM2/') #use folder picker dialogbox\n",
    "# folderpath = '/home/pranav/Work/Data/Murcia/AFM/20240412 thiol interdigielec Sitip old'\n",
    "# folderpath = 'data/newdata'\n",
    "# print(f'Data folder: {folderpath}')\n",
    "\n",
    "#create folder to save dashboard output files in\n",
    "# outputpath = f'{folderpath}/dashboard output'\n",
    "# os.makedirs(outputpath, exist_ok=True) #creates folder only if it doesn't already exist\n",
    "# os.makedirs(outputpath + '/Force volume', exist_ok=True)\n",
    "# os.makedirs(outputpath + '/Specroscopy', exist_ok=True)\n",
    "# os.makedirs(outputpath + '/Imaging', exist_ok=True)\n",
    "refresh=False\n",
    "flatten_chan = ['Topography']\n",
    "make_plot=True\n",
    "sort_asc = True #in case of missing columns or to see image of different direction, change this. \n",
    "\n",
    "dash0_filedict = {'full': '', 'summary': ''}\n",
    "#creates data file list contained within the folder as \"datalist.pkl\" & \"datalist.xlsx\"\n",
    "#Set refresh=True to recreate file list again, else set to False to use previously created file list/create one if it doesn't exist\n",
    "#Set flatten_chan='all' to flatten all images. To flatten only specific channels, set it as a list e.g. ['Topography', 'Amplitude']. \n",
    "#flatten_chan=[] will not flatten anything. flatten_chan only works if refresh=True.\n",
    "# file_df = wsxm_collect_files(folderpath, refresh=True, flatten_chan = ['Topography'], make_plot=False)\n",
    "\n",
    "# chans_list = list(file_df['channel'].unique()) #list of unique channels in all files\n",
    "\n",
    "# # List of regex patterns to ignore in header names\n",
    "# # bad_patterns = [re.compile(r'Image \\d{3}'), re.compile(r'scale,'), re.compile(r'Line \\d{1}'), re.compile(r'-- None --'),\n",
    "# #                 re.compile(r'color'), re.compile(r'Header sections'), re.compile(r'style')] \n",
    "# bad_patterns = [re.compile(r'Image \\d{3}'), re.compile(r'Curve Settings'), \n",
    "#                 re.compile(r'User digital signals out'), re.compile(r'Header sections')] \n",
    "# #generate unique header list\n",
    "# header_unique_names = np.unique(np.concatenate(file_df['header names'].to_list()))\n",
    "# mask = np.vectorize(lambda s: not any(pattern.search(s) for pattern in bad_patterns))(header_unique_names) # Use numpy's vectorize with a lambda function to create a boolean mask\n",
    "# header_unique_names = header_unique_names[mask].tolist() # Filter the original array with the boolean mask\n",
    "# # header_unique_names = [name if name not in chans_list else name + \"1\" for name in header_unique_names]\n",
    "# file_df.drop(columns= ['header names'], inplace=True)\n",
    "\n",
    "#File Viewer Dashboard\n",
    "dash0_browse_button = widgets.Button(description='Choose data folder')\n",
    "dash0_browsepath_text = widgets.Output()\n",
    "dash0_data_type_button = widgets.ToggleButtons(options=['all','1D', '2D', '3D'],\n",
    "                                               value='all', style={\"button_width\": \"50px\"})\n",
    "dash0_channel_view_select = widgets.SelectMultiple(options=[])#chans_list, #description='channels',\n",
    "                                             # value=['Topography' if 'Topography' in chans_list else chans_list[0]])\n",
    "dash0_header_select = widgets.TagsInput(allowed_tags=[],#header_unique_names, \n",
    "                                        value=[], allow_duplicates=False, placeholder='add column from header info', \n",
    "                                        layout=widgets.Layout(width='450px'))\n",
    "dash0_table_type_button = widgets.ToggleButtons(options=['full', 'summary'], value='summary',\n",
    "                                         disabled=False)\n",
    "dash0_save_button = widgets.Button(description='Save')\n",
    "dash0_save_text = widgets.Text(value='', placeholder='Enter file name and save displayed table')\n",
    "\n",
    "# dash0_data_type_button.value = ''\n",
    "# Inject custom CSS to style the header dropdown list width\n",
    "dash0_header_css = widgets.HTML(\"\"\"\n",
    "<style>\n",
    "    input[type=\"text\"] { width: 200px;}  /* Adjust the datalist width */   \n",
    "</style>\n",
    "\"\"\")\n",
    "dash0_tab1_output = widgets.Output()\n",
    "dash0_tab2_output = widgets.Output()\n",
    "dash0_output = widgets.Output()\n",
    "dash0_table_tab = widgets.Tab()\n",
    "dash0_table_tab.children = [dash0_tab1_output, dash0_tab2_output, dash0_output]\n",
    "dash0_table_tab.titles = ['summary', 'full', 'debug']\n",
    "\n",
    "dash0_box1 = widgets.VBox([dash0_data_type_button, widgets.VBox([dash0_header_select, dash0_header_css])])\n",
    "dash0_box2 = widgets.HBox([dash0_channel_view_select, dash0_box1, \n",
    "                           widgets.VBox([dash0_browsepath_text, dash0_browse_button, dash0_save_text, dash0_save_button])])\n",
    "\n",
    "# dash0_tab2init = False #recreate full table on clicking the tab initially. Due to an unknown bug, it doesn't show the table otherwise\n",
    "\n",
    "@dash0_output.capture()\n",
    "def dash0_load_filedata(change):    \n",
    "    global folderpath\n",
    "    global outputpath\n",
    "       \n",
    "    # global dash0_tab2init\n",
    "    # dash0_tab2init = False\n",
    "    # dash0_table_tab.unobserve_all(dash0_tabchange)\n",
    "    folderpath = filedialog.askdirectory(initialdir='/home/pranav/Work/Data/Murcia/AFM2/') #use folder picker dialogbox\n",
    "    folderpath = Path(folderpath)\n",
    "    dash0_browsepath_text.clear_output(wait=True)\n",
    "    with dash0_browsepath_text:\n",
    "        display(str(folderpath))\n",
    "    dash0_tab1_output.clear_output()\n",
    "    dash0_tab2_output.clear_output()\n",
    "    dash0_output.clear_output()\n",
    "    \n",
    "    #create folder to save dashboard output files in\n",
    "    # outputpath = f'{folderpath}/dashboard output'\n",
    "    outputpath = folderpath / 'dashboard output'\n",
    "    os.makedirs(outputpath, exist_ok=True) #creates folder only if it doesn't already exist\n",
    "    os.makedirs(outputpath / 'Force volume', exist_ok=True)\n",
    "    os.makedirs(outputpath / 'Specroscopy', exist_ok=True)\n",
    "    os.makedirs(outputpath / 'Imaging', exist_ok=True)\n",
    "    \n",
    "    dash0_filedict['full'] = wsxm_collect_files(folderpath, refresh=refresh, \n",
    "                                                flatten_chan=flatten_chan, make_plot=make_plot)\n",
    "    dash0_filedict['full'].sort_values(by=['time'], inplace=True)\n",
    "    chans_list = list(dash0_filedict['full']['channel'].unique()) #list of unique channels in all files\n",
    "\n",
    "    # List of regex patterns to ignore in header names\n",
    "    bad_patterns = [re.compile(r'Image \\d{3}'), re.compile(r'Curve Settings'), \n",
    "                    re.compile(r'User digital signals out'), re.compile(r'Header sections')] \n",
    "    #generate unique header list\n",
    "    header_unique_names = np.unique(np.concatenate(dash0_filedict['full']['header names'].to_list()))\n",
    "    mask = np.vectorize(lambda s: not any(pattern.search(s) for pattern in bad_patterns))(header_unique_names) # Use numpy's vectorize with a lambda function to create a boolean mask\n",
    "    header_unique_names = header_unique_names[mask].tolist() # Filter the original array with the boolean mask\n",
    "    # header_unique_names = [name if name not in chans_list else name + \"1\" for name in header_unique_names]\n",
    "    dash0_filedict['full'].drop(columns= ['header names'], inplace=True)\n",
    "    # print('a')\n",
    "    dash0_channel_view_select.unobserve(dash0_update_summarytable, 'value')\n",
    "    dash0_channel_view_select.options = chans_list\n",
    "    dash0_channel_view_select.value = [chans_list[0]] #['Topography' if 'Topography' in chans_list else chans_list[0]]\n",
    "    dash0_channel_view_select.observe(dash0_update_summarytable, 'value')\n",
    "    dash0_header_select.observe(dash0_update_header, 'value')\n",
    "    dash0_header_select.allowed_tags = header_unique_names\n",
    "    dash0_header_select.observe(dash0_update_header, 'value')\n",
    "    # dash0_tab2init = False\n",
    "    # print('b')\n",
    "    dash0_update_header(None)\n",
    "    # print('c')\n",
    "    # dash0_table_tab.observe(dash0_tabchange, 'selected_index')\n",
    "    # dash0_update_summarytable(None)\n",
    "    # dash0_tab2_output.clear_output(wait=True)\n",
    "    # with dash0_tab2_output:\n",
    "    #     itables.show(dash0_filedict['full'], column_filters = \"footer\", layout={\"topEnd\": None})\n",
    "    # dash0_table_tab.observe(dash0_tabchange, 'selected_index')\n",
    "    # dash0_table_tab.selected_index = 0\n",
    "    \n",
    "\n",
    "@dash0_output.capture()\n",
    "def dash0_create_summarytable(view_channels, data_type):\n",
    "    # print('yay')\n",
    "    file_df =  dash0_filedict['full']\n",
    "    chans_list = list(file_df['channel'].unique()) #list of unique channels in all files\n",
    "    df_list = []\n",
    "    for key in file_df['file'].unique():\n",
    "        for chan in view_channels:\n",
    "            if data_type == 'all':\n",
    "                file_df_filter = file_df.loc[(file_df.file==key) & (file_df.channel==chan)]\n",
    "            else:\n",
    "                file_df_filter = file_df.loc[(file_df.type==data_type) & (file_df.file==key) & (file_df.channel==chan)]\n",
    "            if file_df_filter.size!=0:                    \n",
    "                df_list.append(file_df_filter.sort_values(by=['name'], ascending=sort_asc).iloc[0]) #first file (forward dir)\n",
    "    if len(df_list) == 0:\n",
    "        dash0_tab1_output.clear_output()\n",
    "        dash0_filedict['summary'] = pd.DataFrame()\n",
    "    else:\n",
    "        file_df2 = pd.concat(df_list, axis=1).transpose()\n",
    "        #remame column name if it is same as a channel name (eg Amplitude)\n",
    "        header_names_edit = [name if name not in chans_list else f'{name}1' for name in list(dash0_header_select.value)]\n",
    "        file_info_cols = ['size','resolution'] + header_names_edit #list(header_select.value)\n",
    "        column_group = ['file', 'type'] + file_info_cols\n",
    "        file_df_pivot = file_df2.pivot_table(columns='channel', values='plot', \n",
    "                                              index=column_group,\n",
    "                                             aggfunc='first').reset_index()\n",
    "        file_df_mintime = file_df2.groupby(column_group)['time'].min().reset_index()\n",
    "        file_df_summary = pd.merge(file_df_pivot, file_df_mintime, on=column_group)\n",
    "        file_df_summary = file_df_summary.reindex(view_channels + ['file'] + file_info_cols + ['time'], axis=1)\n",
    "        file_df_summary.sort_values(by=['time'], inplace=True)\n",
    "        file_df_summary.dropna(inplace=True) #only show rows which contain images of all selected channels\n",
    "        return file_df_summary\n",
    "\n",
    "@dash0_output.capture()\n",
    "def dash0_update_summarytable(change):\n",
    "    # table_type = dash0_table_type_button.value\n",
    "    # if table_type == 'summary':\n",
    "    # global file_df_summary\n",
    "    # file_df =  dash0_filedict['full']\n",
    "    view_channels = list(dash0_channel_view_select.value) #['Topography', 'Normal force', 'Excitation frequency', 'Adhesion']\n",
    "    # chans_list = dash0_channel_view_select.options\n",
    "    data_type = dash0_data_type_button.value\n",
    "    file_df_summary = dash0_create_summarytable(view_channels, data_type)\n",
    "    # df_list = []\n",
    "    # for key in file_df['file'].unique():\n",
    "    #     for chan in view_channels:\n",
    "    #         if data_type == 'all':\n",
    "    #             file_df_filter = file_df.loc[(file_df.file==key) & (file_df.channel==chan)]\n",
    "    #         else:\n",
    "    #             file_df_filter = file_df.loc[(file_df.type==data_type) & (file_df.file==key) & (file_df.channel==chan)]\n",
    "    #         if file_df_filter.size!=0:                    \n",
    "    #             df_list.append(file_df_filter.sort_values(by=['name'], ascending=sort_asc).iloc[0]) #first file (forward dir)\n",
    "    # if len(df_list) == 0:\n",
    "    #     dash0_tab1_output.clear_output()\n",
    "    # else:\n",
    "    #     file_df2 = pd.concat(df_list, axis=1).transpose()\n",
    "    #     #remame column name if it is same as a channel name (eg Amplitude)\n",
    "    #     header_names_edit = [name if name not in chans_list else f'{name}1' for name in list(dash0_header_select.value)]\n",
    "    #     file_info_cols = ['size','resolution'] + header_names_edit #list(header_select.value)\n",
    "    #     column_group = ['file', 'type'] + file_info_cols\n",
    "    #     file_df_pivot = file_df2.pivot_table(columns='channel', values='plot', \n",
    "    #                                           index=column_group,\n",
    "    #                                          aggfunc='first').reset_index()\n",
    "    #     file_df_mintime = file_df2.groupby(column_group)['time'].min().reset_index()\n",
    "    #     file_df_summary = pd.merge(file_df_pivot, file_df_mintime, on=column_group)\n",
    "    #     file_df_summary = file_df_summary.reindex(view_channels + ['file'] + file_info_cols + ['time'], axis=1)\n",
    "    #     file_df_summary.sort_values(by=['time'], inplace=True)\n",
    "    #     file_df_summary.dropna(inplace=True) #only show rows which contain images of all selected channels\n",
    "    #     dash0_filedict['summary'] =  file_df_summary\n",
    "    dash0_filedict['summary'] =  file_df_summary\n",
    "    dash0_tab1_output.clear_output(wait=True)\n",
    "    with dash0_tab1_output:\n",
    "        # itables.show(dash0_filedict['summary'], classes=\"display\")\n",
    "        display(ITable(dash0_filedict['summary']))\n",
    "                         #columnDefs=[{\"width\": \"10px\", \"targets\": [0]}])\n",
    "                        #style=\"text-wrap:wrap\")#classes=\"display\") width:100%;margin:auto;\n",
    "\n",
    "# @dash0_output.capture()\n",
    "# def dash0_update_tabletype(change):\n",
    "#     table_type = dash0_table_type_button.value\n",
    "#     if table_type == 'full':\n",
    "#         dash0_tab2_output.clear_output()\n",
    "#         with dash0_output:\n",
    "#             itables.show(file_df, column_filters = \"footer\", layout={\"topEnd\": None})\n",
    "#         dash0_box2.layout.display='none'\n",
    "#     if table_type == 'summary':\n",
    "#         dash0_update_summarytable(None)\n",
    "#         dash0_box2.layout.display=None\n",
    "\n",
    "@dash0_output.capture()\n",
    "def dash0_update_header(change):\n",
    "    header_selection = dash0_header_select.value\n",
    "    chans_list = dash0_channel_view_select.options\n",
    "    file_df =  dash0_filedict['full']\n",
    "    for header_i in header_selection:\n",
    "        if header_i not in file_df.columns:\n",
    "            #remame column name if it is same as a channel name (eg Amplitude)\n",
    "            col_name = header_i if header_i not in chans_list else f'{header_i}1'\n",
    "            file_df.insert(len(file_df.columns)-1, col_name, None)\n",
    "            for i in file_df.index:\n",
    "                if header_i in file_df.loc[i,'header'].keys():\n",
    "                    file_df.loc[i, col_name] = file_df.loc[i, 'header'][header_i]\n",
    "                else:\n",
    "                    file_df.loc[i, col_name] = ''\n",
    "    # itables.show(file_df)\n",
    "    # dash0_update_tabletype(None)\n",
    "    dash0_update_summarytable(None)\n",
    "    dash0_tab2_output.clear_output(wait=True)\n",
    "    with dash0_tab2_output:\n",
    "        # itables.show(file_df, column_filters = \"footer\", layout={\"topEnd\": None})\n",
    "        display(ITable(file_df))\n",
    "\n",
    "@dash0_output.capture()\n",
    "def dash0_tabchange(change):\n",
    "    # global dash0_tab2init\n",
    "    # print(change)\n",
    "    if change.new == 1: # and dash0_tab2init == False:\n",
    "        dash0_tab2_output.clear_output(wait=True)\n",
    "        with dash0_tab2_output:\n",
    "            itables.show(dash0_filedict['full'], column_filters = \"footer\", layout={\"topEnd\": None})\n",
    "        # dash0_tab2init = True\n",
    "        dash0_table_tab.unobserve_all()\n",
    "\n",
    "@dash0_output.capture()\n",
    "def dash0_save_click(change):\n",
    "    if dash0_save_text.value == '':\n",
    "        name_prefix = 'file_list'\n",
    "    else:\n",
    "        name_prefix = f'{dash0_save_text.value}'\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    name_suffix = f'{timestamp}'\n",
    "    selected_tab = dash0_table_tab.titles[dash0_table_tab.selected_index]\n",
    "    if selected_tab == 'full':\n",
    "        file_df =  dash0_filedict['full']\n",
    "        # dash0_outfilepath = f'{outputpath}/{name_prefix}_full_{name_suffix}.xlsx'\n",
    "        dash0_outfilepath = outputpath / f'{name_prefix}_full_{name_suffix}.xlsx'\n",
    "        file_df['header data'] = file_df['header'].map(str) #convert dictionary column data to string for excel saving\n",
    "        file_df.sort_values(by=['time'], inplace=True, ignore_index=True)\n",
    "        imagedf_to_excel(file_df.drop(columns=['header']),\n",
    "                         dash0_outfilepath, img_size=(100, 100))\n",
    "        file_df.drop(columns=['header data'], inplace=True) #remove \"stringed\" header data\n",
    "    elif selected_tab == 'summary':\n",
    "        file_df_summary =  dash0_filedict['summary']\n",
    "        # dash0_outfilepath = f'{outputpath}/{name_prefix}_summary_{name_suffix}.xlsx'\n",
    "        dash0_outfilepath = outputpath / f'{name_prefix}_summary_{name_suffix}.xlsx'\n",
    "        imagedf_to_excel(file_df_summary, dash0_outfilepath, img_size=(100, 100))\n",
    "\n",
    "dash0_browse_button.on_click(dash0_load_filedata)\n",
    "dash0_data_type_button.observe(dash0_update_summarytable, 'value')\n",
    "dash0_channel_view_select.observe(dash0_update_summarytable, 'value')\n",
    "dash0_header_select.observe(dash0_update_header, 'value')\n",
    "# dash0_table_tab.observe(dash0_tabchange, 'selected_index')\n",
    "dash0_save_button.on_click(dash0_save_click)\n",
    "# dash0_table_type_button.observe(dash0_update_tabletype, 'value')\n",
    "\n",
    "# display(dash0_box1)\n",
    "display(dash0_box2)\n",
    "display(dash0_table_tab)\n",
    "# display(dash0_output)\n",
    "\n",
    "# dash0_update_summarytable(None)\n",
    "# dash0_tab2_output.clear_output(wait=True)\n",
    "\n",
    "# with dash0_tab2_output:\n",
    "#     itables.show(dash0_filedict['full'], column_filters = \"footer\", layout={\"topEnd\": None})\n",
    "\n",
    "# dash0_tab2_output.clear_output(wait=True)\n",
    "# with dash0_tab2_output:\n",
    "#     itables.show(file_df, column_filters = \"footer\", layout={\"topEnd\": None})\n",
    "# dash0_update_header(None)\n",
    "# table_type_button.value = 'summary'\n",
    "# dash0_update_summarytable(None)\n",
    "# with dash0_output:\n",
    "#     itables.show(file_df, column_filters = \"header\", layout={\"topEnd\": None})\n",
    "# box1.layout.display='none'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce6781-210d-4177-adf3-35b0762b02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drift test\n",
    "drift_norm_list= []\n",
    "drift_lat_list= []\n",
    "drift_freq_list= []\n",
    "drift_amp_list= []\n",
    "file_df =  dash0_filedict['full']\n",
    "drift_channel = 'Excitation frequency'\n",
    "for file_i in file_df.file.unique():\n",
    "    file_df_filt_i = file_df.loc[(file_df.file==file_i)].iloc[0]\n",
    "    if file_df_filt_i.extension != '.cur':\n",
    "        # print(file_df_filt_i.loc['name'])\n",
    "        filepath_i = folderpath / file_df_filt_i.loc['name']\n",
    "        data_i = wsxm_readchan(filepath_i, all_files=True, mute=True)\n",
    "        data_full_i= np.concatenate([np.flip(data_i['Normal force']['Forward']['data']['Z'],1),\n",
    "                                    data_i['Normal force']['Backward']['data']['Z']], axis=1)\n",
    "        # data_full_i= np.concatenate([data_i['Normal force']['Forward']['data']['Z'],\n",
    "        #                             data_i['Normal force']['Backward']['data']['Z']], axis=1)\n",
    "        data_forw_i = np.flip(np.flip(data_full_i, axis=1).flatten()) #np.flip(data_full_i.flatten(order='C'))\n",
    "        drift_norm_list.append(data_forw_i)\n",
    "        data_full_i= np.concatenate([np.flip(data_i['Lateral force']['Forward']['data']['Z'],1),\n",
    "                                    data_i['Lateral force']['Backward']['data']['Z']], axis=1)\n",
    "        data_forw_i = np.flip(np.flip(data_full_i, axis=1).flatten()) #np.flip(data_full_i.flatten(order='C'))\n",
    "        # data_forw_i = np.flip(data_i['Lateral force']['Forward']['data']['Z'].flatten(order='C'))\n",
    "        drift_lat_list.append(data_forw_i)\n",
    "        data_full_i= np.concatenate([np.flip(data_i['Excitation frequency']['Forward']['data']['Z'],1),\n",
    "                                    data_i['Excitation frequency']['Backward']['data']['Z']], axis=1)\n",
    "        data_forw_i = np.flip(np.flip(data_full_i, axis=1).flatten()) #np.flip(data_full_i.flatten(order='C'))\n",
    "        # data_forw_i = np.flip(data_i['Excitation frequency']['Forward']['data']['Z'].flatten(order='C'))\n",
    "        drift_freq_list.append(data_forw_i)\n",
    "        data_full_i= np.concatenate([np.flip(data_i['Amplitude']['Forward']['data']['Z'],1),\n",
    "                                    data_i['Amplitude']['Backward']['data']['Z']], axis=1)\n",
    "        data_forw_i = np.flip(np.flip(data_full_i, axis=1).flatten()) #np.flip(data_full_i.flatten(order='C'))\n",
    "        # data_forw_i = np.flip(data_i['Amplitude']['Forward']['data']['Z'].flatten(order='C'))\n",
    "        drift_amp_list.append(data_forw_i)\n",
    "        # data_back_i = np.flip(data_i[drift_channel]['Backward']['data']['Z'].flatten())\n",
    "        # drift_data_list.append(data_back_i)\n",
    "\n",
    "line_rate = float(data_i[drift_channel]['Forward']['header']['X-Frequency [Control]'].split(' ')[0])\n",
    "col_num = float(data_i[drift_channel]['Forward']['header']['Number of columns [General Info]'])\n",
    "time_per_point = (1/(2*line_rate*col_num))/3600 #hours\n",
    "\n",
    "drift_data_norm = np.concatenate(drift_norm_list)\n",
    "drift_data_lat = np.concatenate(drift_lat_list)\n",
    "drift_data_freq = np.concatenate(drift_freq_list)\n",
    "drift_data_amp = np.concatenate(drift_amp_list)\n",
    "time_data = time_per_point*np.linspace(0,len(drift_data_norm)-1, len(drift_data_norm))\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(time_data, drift_data_norm, label='Normal', color='LimeGreen')\n",
    "ax.plot(time_data, drift_data_lat, label='Lateral', color='Cyan')\n",
    "ax.plot(time_data, drift_data_amp, label='Amp', color='OrangeRed')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(time_data, drift_data_freq, label='Freq', color='Yellow')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(1,0.7))\n",
    "ax.set_xlim(0,14)\n",
    "# ax.set_ylim(5,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c847bc-7632-4376-b2ee-cdc95c67b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df_filt_i = file_df.loc[(file_df.file=='drifttest_AC160TS_gain10_pllon_0000')].iloc[0]\n",
    "filepath_i = folderpath / file_df_filt_i.loc['name']\n",
    "data_i = wsxm_readchan(filepath_i, all_files=True, mute=True)\n",
    "data_for_i = data_i['Normal force']['Forward']['data']['Z']\n",
    "data_back_i = data_i['Normal force']['Backward']['data']['Z']\n",
    "test = np.concatenate([np.flip(data_for_i,1), data_back_i], axis=1), np.flip(data_for_i,1), data_back_i\n",
    "test[0].flatten(), np.flip(np.flip(test[0], axis=1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca85b5e-e23f-4f47-a2aa-bec914f2a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/pranav/Work/Data/Murcia/AFM2/20240412 thiol interdigielec Sitip old/interdigThiols_tipSi3nN_a_0003_Normal force.f.stp'\n",
    "data_dict_chan_i = wsxm_readspectra(filename, all_files=False, mute=True)\n",
    "spectrodf_i = convert_spectro2df(data_dict_chan_i['data'])\n",
    "spectrodf_i.groupby(['segment']).mean()['y'].to_dict()\n",
    "str(spectrodf_i.groupby(['segment']).min()['y'].to_dict())\n",
    "# spectrodf_i.groupby(['segment']).max()['y'].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827dca5-5b4d-4c28-b133-41dc39479220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = ['calibrate_thermalnoise_gain100_laseron_0052', 'calibrate_thermalnoise_laseron_0000']\n",
    "file_df =  dash0_filedict['full']\n",
    "filepath_i = folderpath + '/' + file_df.loc[(file_df.file==files[1])].iloc[0].loc['name']\n",
    "test = wsxm_readchan(filepath_i, all_files=True, mute=True)\n",
    "amp_data = test['Amplitude']#['Backward']['data']\n",
    "phase_data = test['Phase']\n",
    "\n",
    "amp = amp_data['Forward']['data']['Z']\n",
    "phase = phase_data['Forward']['data']['Z']\n",
    "amp_flat = amp.flatten()\n",
    "plt.plot(amp_flat)\n",
    "plt.plot(np.square(amp_flat))\n",
    "plt.plot([np.mean(np.square(amp_flat))]*len(amp_flat))\n",
    "plt.plot([np.sqrt(np.mean(np.square(amp_flat)))]*len(amp_flat))\n",
    "plt.show()\n",
    "# print(amp_f.min(), amp_f.max())\n",
    "# print(chan_data['Forward']['data']['Z'].min(), chan_data['Forward']['data']['Z'].max())\n",
    "# amp_offset = np.atleast_2d(np.mean(amp_chan['Z'], axis=1)).T\n",
    "# p, res, rank, sing, rcond = np.polyfit(amp_chan['X'], amp_chan['Z'].T, 1, full=True)\n",
    "# amp_offset = np.array([np.poly1d(p[:,i])(amp_chan['X']) for i in range(p.shape[1])])\n",
    "# amp_shifted = amp_chan['Z']-amp_offset\n",
    "# plt.pcolormesh(chan_data['Backward']['data']['Z'], cmap='afmhot')\n",
    "# # plt.clim(vmin=np.percentile(chan_data['Z'],1),vmax=np.percentile(chan_data['Z'],99))\n",
    "# plt.show()\n",
    "# zz_amp_list = []\n",
    "# zz_phase_list = []\n",
    "# for img_dir in amp_data.keys():\n",
    "#     head_data = amp_data[img_dir]['header']\n",
    "#     zz_amp = amp_data[img_dir]['data']['Z']\n",
    "#     zz_phase = phase_data[img_dir]['data']['Z']\n",
    "#     # xx, yy, zz_amp = get_imgdata(amp_data[img_dir])\n",
    "\n",
    "#     # xx, yy, zz_phase= get_imgdata(phase_data[img_dir])\n",
    "\n",
    "#     #true amplitude calculated from amp and phase channels\n",
    "#     # zz_i = np.sqrt(np.square(zz_amp) + np.square(zz_phase))\n",
    "#     zz_amp_list.append(zz_amp)\n",
    "#     zz_phase_list.append(zz_amp)\n",
    "        \n",
    "# zz_amp_full = np.concatenate(zz_amp_list, axis=1)\n",
    "# zz_phase_full = np.concatenate(zz_phase_list, axis=1)\n",
    "\n",
    "# sample_rate = 15000 #float(head_data['Sampling frequency [Miscellaneous]'].split(' ')[0])\n",
    "# freq_array, z_pow_amp = signal.periodogram(zz_amp_full, sample_rate, scaling='density') #power spectral density\n",
    "# freq_array, z_pow_phase = signal.periodogram(zz_phase_full, sample_rate, scaling='density') #power spectral density\n",
    "# z_pow_true = z_pow_amp + z_pow_phase\n",
    "# z_pow_avg = np.average(z_pow_true, axis=0) #averaged\n",
    "# plt.pcolormesh(z_pow_amp, cmap='afmhot')\n",
    "# plt.show() \n",
    "# plt.pcolormesh(z_pow_phase, cmap='afmhot')\n",
    "# plt.show() \n",
    "# plt.pcolormesh(z_pow_true, cmap='afmhot')\n",
    "# plt.show() \n",
    "# freq_array2, z_pow2 = signal.periodogram(z_pow_true, sample_rate, scaling='density') #power spectral density\n",
    "# plt.pcolormesh(z_pow2, cmap='afmhot')\n",
    "# plt.show() \n",
    "# z_pow_avg_amp = np.average(z_pow_amp, axis=0) #averaged\n",
    "# z_pow_avg_phase = np.average(z_pow_phase, axis=0) #averaged\n",
    "# z_pow_avg_true = np.average(z_pow_true, axis=0) #averaged\n",
    "# plt.plot(freq_array, z_pow_avg_amp, 'r')\n",
    "# plt.plot(freq_array, z_pow_avg_phase, 'g')\n",
    "# plt.plot(freq_array, z_pow_avg_true, 'b')\n",
    "# plt.show()\n",
    "# n_clusters = 3\n",
    "# chan_labels = tsf.segment_kmeans(chan_data, n_clusters)\n",
    "\n",
    "# plt.pcolormesh(chan_labels, cmap='afmhot')\n",
    "# plt.show()\n",
    "\n",
    "# data_clustered = {}\n",
    "# for i in range(n_clusters):\n",
    "#     data_clustered[i] = chan_data['Z'][chan_labels==i].flatten()  \n",
    "# sns.histplot(data=data_clustered)#, x=\"flipper_length_mm\", hue=\"species\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12e6f6-dcf8-40c6-a7a0-3bd412447fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#PLANE FILTER TO DO\n",
    "import itertools\n",
    "#generate Matrix to use with lstsq for levelling\n",
    "def poly_matrix(x, y, order=2):\n",
    "    ncols = (order + 1)**2\n",
    "    G = np.zeros((x.size, ncols))\n",
    "    ij = itertools.product(range(order+1), range(order+1))\n",
    "    for k, (i, j) in enumerate(ij):\n",
    "        G[:, k] = x**i * y**j\n",
    "    return G\n",
    "\n",
    "\n",
    "def level_data(points, order=1):\n",
    "    X,Y = np.meshgrid(self.df_matrix.columns,\n",
    "                      self.df_matrix.index)\n",
    "\n",
    "    if order == 1:\n",
    "        # best-fit linear plane\n",
    "        A = np.c_[points[:,0], points[:,1], np.ones(points.shape[0])]\n",
    "        C,_,_,_ = np.linalg.lstsq(A, points[:,2], rcond=None)    # coefficients\n",
    "        #print(C)\n",
    "        # evaluate it on grid\n",
    "        Z = C[0]*X + C[1]*Y + C[2]\n",
    "##            print(Z)\n",
    "        # self.df['Zero fit'] = C[0]*self.df[self.plot_x] + \\\n",
    "        #                       C[1]*self.df[self.plot_y] + C[2]\n",
    "        #print(self.df)\n",
    "    elif order == 2:\n",
    "        x, y, z = points.T\n",
    "        #x, y = x - x[0], y - y[0]  # this improves accuracy\n",
    "\n",
    "        # make Matrix:\n",
    "        G = self.poly_matrix(x, y, order)\n",
    "        # Solve for np.dot(G, m) = z:\n",
    "        m = np.linalg.lstsq(G, z, rcond=None)[0]\n",
    "        #print('m', m)\n",
    "        # Evaluate it on a grid...\n",
    "##            GG = self.poly_matrix(X.ravel(), Y.ravel(), order)\n",
    "##            Z = np.reshape(np.dot(GG, m), X.shape)\n",
    "##            print(Z)\n",
    "        self.df['Zero fit'] = np.polynomial.polynomial.polyval2d(self.df[self.plot_x],\n",
    "                                                                 self.df[self.plot_y],\n",
    "                                                                 np.reshape(m, (-1, 3)))\n",
    "\n",
    "    self.df[self.plot_z+' corrected'] = self.df[self.plot_z]-self.df['Zero fit']\n",
    "\n",
    "    #organize data into matrix for heatmap plot\n",
    "    self.df_matrix = self.df.pivot_table(values=self.plot_z+' corrected',\n",
    "                                         index=self.plot_y,\n",
    "                                         columns=self.plot_x,\n",
    "                                         aggfunc='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851facec-eccb-42f6-8a5e-f4973be7ec3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AFM CALIBRATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88651751-ff21-40d1-abd2-ff0dc630d2c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Thermal noise method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cf29c-2d0e-4209-ac14-cdf4afc7a89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gain_ini = 10 #SET GAIN\n",
    "\n",
    "#Calibrate Amplitude in nm/V from thermal noise images (laser on/off)\n",
    "# folderpath = Path(\"/home/pranav/Work/Data/Murcia/AFM2/\")\n",
    "# outputpath = Path(\"/home/pranav/Work/Data/Murcia/AFM2/\")\n",
    "# save = True #save calibration results\n",
    "\n",
    "# #register at https://sadermethod.org/ to get GCI userid and password\n",
    "# gci_uid = 'p.sudersan' #GCI user id\n",
    "# gci_pass = 'K76DyGCw' #GCI password\n",
    "# cantilever_dict = SaderGCI_GetLeverList(gci_uid, gci_pass)\n",
    "# cantilever_name = 'Multi75-G Budget Sensors' #'TAP150Al-G Budget Sensors' #'AC160TS-R3 Olympus'\n",
    "# cantilever_num = cantilever_dict[cantilever_name]\n",
    "\n",
    "# # cant_width = 40 #cantilever width (μm)\n",
    "# # cant_length = 160 #cantilever length (μm)\n",
    "# Temp = 300 #themperature in K\n",
    "# correction_factor = 1 # correction factor for static deflection calibration; Butt-Jaschke: 0.817, no correction: 1\n",
    "# k_cantilver = 4.67 #2.66637 #cantilever spring constant in N/m\n",
    "\n",
    "# files = ['thermalcalib_laseroff_0000', 'thermalcalib_laseroff_0001', 'thermalcalib_laseroff_0002','thermalcalib_laseroff_0003', 'thermalcalib_laseroff_0004',\n",
    "#         'thermalcalib_laseron_0000', 'thermalcalib_laseron_0001', 'thermalcalib_laseron_0002', 'thermalcalib_laseron_0003', 'thermalcalib_laseron_0004']\n",
    "\n",
    "# file_paths = list(filedialog.askopenfilenames(title='Choose thermal noise image files', \n",
    "#                                               initialdir=folderpath, filetypes=(('amplitude channel', '*.ch15'),)))\n",
    "\n",
    "# file_paths = custom_filedialog(title='Choose thermal noise image files',\n",
    "#                                initialdir=folderpath, filetypes=['.ch15'])\n",
    "\n",
    "# # file_df =  dash0_filedict['full']\n",
    "# # file_keys = []\n",
    "# file_keys = {}\n",
    "# for file_path_i in file_paths: #find the list of unique file keyword names\n",
    "#     filename_i = os.path.basename(file_path_i)\n",
    "#     match_i = re.search(r'\\_\\d{4}', filename_i) #regex to find 4 digit number in filename\n",
    "#     filename_com_i = filename_i[:match_i.start()+5]\n",
    "#     # file_keys.append(file_df[file_df['name']==file_name_i]['file'].iloc[0])\n",
    "#     file_keys[filename_com_i] = Path(file_path_i)\n",
    "dashtc_datadict = {}\n",
    "cantilever_list_ini = ['160AC-NA MikroMasch', '240AC-NA MikroMasch', '@LDV AD-2.8-AS Adama', '@LDV AD-2.8-P10 Adama', '@LDV AD-2.8-P20 Adama', '@LDV AD-2.8-P40 Adama', '@LDV AD-2.8-P5 Adama', '@LDV AD-2.8-SS Adama', '@LDV AD-40-AS Adama', '@LDV AD-40-P10 Adama', '@LDV AD-40-P20 Adama', '@LDV AD-40-P40 Adama', '@LDV AD-40-P5 Adama', '@LDV AD-40-SS Adama', '@LDV FM-LC Adama', '@LDV NC-LC Adama', 'AC10DS Olympus', 'AC160-R3 Olympus', 'AC160TN-R3 Olympus', 'AC160TS-R3 Olympus', 'AC200-R3 Olympus', 'AC200TN-R3 Olympus', 'AC200TS-R3 Olympus', 'AC240-R3 Olympus', 'AC240TM-R3 Olympus', 'AC240TN-R3 Olympus', 'AC240TS-R3 Olympus', 'AC40TS-C2 Olympus', 'AC55-R3 Olympus', 'AC55TN-R3 Olympus', 'AC55TS-R3 Olympus', 'ACT AppNano', 'ACTA AppNano', 'AD-2.8-AS Adama', 'AD-2.8-P10 Adama', 'AD-2.8-P20 Adama', 'AD-2.8-P40 Adama', 'AD-2.8-PS Adama', 'AD-2.8-SS Adama', 'AD-40-AS Adama', 'AD-40-P10 Adama', 'AD-40-P20 Adama', 'AD-40-P40 Adama', 'AD-40-PS Adama', 'AD-40-SS Adama', 'AD-CTCT1S-5 NaDiaProbes', 'All-In-One (A) Budget Sensors', 'All-In-One (B) Budget Sensors', 'All-In-One (C) Budget Sensors', 'All-In-One (D) Budget Sensors', 'Arrow TL1 NanoWorld', 'Arrow UHFAuD NanoWorld', 'ATEC-CONTAu Nanosensors', 'B100-NCH Nanotools', 'B100_FMR Nanotools', 'B150_FMR Nanotools', 'B20_FMR Nanotools', 'B300_FMR Nanotools', 'B40_FMR Nanotools', 'B500_FMR Nanotools', 'B50_FMR Nanotools', 'biosphere B20-FM Nanotools', 'biosphere B50-FM Nanotools', 'CDT-NCHR Nanosensors', 'CDT-NCLR Nanosensors', 'CONT NanoWorld', 'Contact-G Budget Sensors', 'CP-CONT-PM sQube', 'CP-PNPL-Au-C (1) NanoAndMore', 'CP-PNPL-Au-C (2) NanoAndMore', 'CP-qp-SCONT-SiO NanoAndMore', 'DDESP-FM-V2 Bruker', 'DNP (A) Bruker', 'DNP (B) Bruker', 'DNP (C) Bruker', 'DNP (D) Bruker', 'DNP-S10 (A) Bruker', 'DNP-S10 (B) Bruker', 'DNP-S10 (C) Bruker', 'DNP-S10 (D) Bruker', 'DUO-500 S Micromotive', 'EFM NanoWorld', 'FastScan-A Bruker', 'FastScan-B Bruker', 'FastScan-C Bruker', 'FastScan-D Bruker', 'FluidFM Nanosyringe Cytosurge', 'FM NanoWorld', 'FM-LC Adama', 'FMV Bruker', 'FORT AppNano', 'HQ:CSC37/tipless/Al BS (A) MikroMasch', 'HQ:CSC37/tipless/Al BS (B) MikroMasch', 'HQ:CSC37/tipless/Al BS (C) MikroMasch', 'HQ:CSC37/tipless/No Al (A) MikroMasch', 'HQ:CSC37/tipless/No Al (B) MikroMasch', 'HQ:CSC37/tipless/No Al (C) MikroMasch', 'HQ:CSC38/Al BS (A) MikroMasch', 'HQ:CSC38/Al BS (B) MikroMasch', 'HQ:CSC38/Al BS (C) MikroMasch', 'HQ:CSC38/Cr-Au (A) MikroMasch', 'HQ:CSC38/Cr-Au (B) MikroMasch', 'HQ:CSC38/Cr-Au (C) MikroMasch', 'HQ:CSC38/No Al (A) MikroMasch', 'HQ:CSC38/No Al (B) MikroMasch', 'HQ:CSC38/No Al (C) MikroMasch', 'HQ:DPER-XSC11 (A) MikroMasch', 'HQ:DPER-XSC11 (B) MikroMasch', 'HQ:DPER-XSC11 (C) MikroMasch', 'HQ:DPER-XSC11 (D) MikroMasch', 'HQ:NSC14/CR-AU MikroMasch', 'HQ:NSC15 MikroMasch', 'HQ:NSC15/HARD/AL BS MikroMasch', 'HQ:NSC16/HARD/AL BS MikroMasch', 'HQ:NSC18/Cr-Au BS MikroMasch', 'HQ:NSC35/tipless/No Al (A) MikroMasch', 'HQ:NSC35/tipless/No Al (B) MikroMasch', 'HQ:NSC35/tipless/No Al (C) MikroMasch', 'HQ:NSC36/Cr-Au (A) MikroMasch', 'HQ:NSC36/Cr-Au (B) MikroMasch', 'HQ:NSC36/Cr-Au (C) MikroMasch', 'HSC60 (300 kHz) Team Nanotec', 'HYDRA6R-200NG AppNano', 'LRCH250 (300 kHz) Team Nanotec', 'LRCH250 (575 kHz) Team Nanotec', 'MLCT (A) Bruker', 'MLCT (B) Bruker', 'MLCT (C) Bruker', 'MLCT (D) Bruker', 'MLCT (E) Bruker', 'MLCT (F) Bruker', 'MPP-11100-10 Bruker', 'MSNL-10 (A) Bruker', 'MSNL-10 (B) Bruker', 'MSNL-10 (C) Bruker', 'MSNL-10 (D) Bruker', 'MSNL-10 (E) Bruker', 'MSNL-10 (F) Bruker', 'Multi40 Bruker', 'Multi75-G Budget Sensors', 'Multi75E-G Budget Sensors', 'Multi75M-G Budget Sensors', 'NC-LC Adama', 'NCH NanoWorld', 'NCHV-A Bruker', 'ND-CTCT1S-5 NaDiaProbes', 'ND-CTIT2S-5 NaDiaProbes', 'ND-DYIRS-5 NaDiaProbes', 'NM-RC Adama', 'NM-TC Adama', 'NP-O10 (A) Bruker', 'NP-O10 (B) Bruker', 'NP-O10 (C) Bruker', 'NP-O10 (D) Bruker', 'NSG03 NT-MDT', 'NSG10 NT-MDT', 'NSG30 NT-MDT', 'NSG30/tipless NT-MDT', 'OBL-10 (A) Bruker', 'OBL-10 (B) Bruker', 'OCTO-500 S Micromotive', 'OLTESPA-R3 Bruker', 'OMCL-RC800PSA (A) Olympus', 'OMCL-RC800PSA (B) Olympus', 'OMCL-RC800PSA (C) Olympus', 'OMCL-RC800PSA (D) Olympus', 'OMCL-TR400PB (L) Olympus', 'OMCL-TR400PB (S) Olympus', 'OMCL-TR400PSA (L) Olympus', 'OMCL-TR400PSA (S) Olympus', 'OMCL-TR800PB (L) Olympus', 'OMCL-TR800PB (S) Olympus', 'OMCL-TR800PSA (L) Olympus', 'OMCL-TR800PSA (S) Olympus', 'OTESPA-R3 Bruker', 'OTR8 (A) Bruker', 'OTR8 (B) Bruker', 'PeakForce-Hirs-F-A Bruker', 'PeakForce-Hirs-F-B Bruker', 'PeakForce-Hirs-SSB Bruker', 'PFQNE-AL Bruker', 'PFQNM-LC-A-CAL Bruker', 'PFTUNA Bruker', 'PNP-DB (1) NanoWorld', 'PNP-DB (2) NanoWorld', 'PNP-TR (1) NanoWorld', 'PNP-TR (2) NanoWorld', 'PPP-CONTPt Nanosensors', 'PPP-EFM Nanosensors', 'PPP-FM Nanosensors', 'PPP-LFMR Nanosensors', 'PPP-NCH Nanosensors', 'PPP-NCHR Nanosensors', 'PPP-NCLR Nanosensors', 'PtSi-NCH Nanosensors', 'qp-BioAC (CB1) Nanosensors', 'qp-BioAC (CB2) Nanosensors', 'qp-BioAC (CB3) Nanosensors', 'qp-BioT (L) Nanosensors', 'qp-BioT (S) Nanosensors', 'qp-fast (CB1) Nanosensors', 'qp-fast (CB2) Nanosensors', 'qp-fast (CB3) Nanosensors', 'RC150VB (L) Olympus', 'RC150VB (S) Olympus', 'RC800PSA (A) Olympus', 'RC800PSA (B) Olympus', 'RC800PSA (C) Olympus', 'RC800PSA (D) Olympus', 'RFESP-75 Bruker', 'RMN-25PT300B RMN', 'RTESPA-150 Bruker', 'RTESPA-300 Bruker', 'RTESPA-525 Bruker', 'RTESPA-525-30 Bruker', 'SAA-HPI-SS Bruker', 'SCANASYST-AIR Bruker', 'SCANASYST-AIR-HR Bruker', 'SCANASYST-FLUID Bruker', 'SCM-PIC-V2 Bruker', 'SCM-PIT-V2 Bruker', 'SCM-PTSI Bruker', 'SCOUT 70 NuNano', 'SD-R30-CONT Nanosensors', 'SD-R30-FM Nanosensors', 'SD-R30-NCH Nanosensors', 'SECM Bruker', 'SNL-10 (A) Bruker', 'SNL-10 (B) Bruker', 'SNL-10 (C) Bruker', 'SNL-10 (D) Bruker', 'SSS-FM Nanosensors', 'T190 VISTAprobes', 'T190R VISTAprobes', 'T300 VISTAprobes', 'T300R VISTAprobes', 'TAP150 Bruker', 'TAP150-G Budget Sensors', 'TAP150Al-G Budget Sensors', 'TAP150DLC Budget Sensors', 'TAP190Al-G Budget Sensors', 'TAP300 Bruker', 'TAP300-G Budget Sensors', 'TAP300Al-G Budget Sensors', 'TAP525 Bruker', 'TESPA-V2 Bruker', 'TL-CONT Nanosensors', 'TL-NCH Nanosensors', 'TR400PB (L) Olympus', 'TR400PB (S) Olympus', 'TR400PSA (L) Olympus', 'TR400PSA (S) Olympus', 'TR800PB (L) Olympus', 'TR800PB (S) Olympus', 'TR800PSA (L) Olympus', 'TR800PSA (S) Olympus', 'USC-F0.3-k0.3 NanoWorld', 'USC-F1.2-k0.15 NanoWorld', 'XNC12/Cr-Au (A) MikroMasch', 'XNC12/Cr-Au (B) MikroMasch', 'XNC12/Cr-Au BS (A) MikroMasch', 'XNC12/Cr-Au BS (B) MikroMasch']\n",
    "dashtc_loadfiles_button = widgets.Button(description='Load files')\n",
    "dashtc_loadselection_button = widgets.Button(description='LOAD', tooltip='Load selected files in file browser',\n",
    "                                             layout=widgets.Layout(height='auto'), style={\"button_height\": \"100px\", 'font_size':\"28px\"})\n",
    "dashtc_loadcali_button = widgets.Button(description='Load calibration')\n",
    "dashtc_gciuid_text = widgets.Text(value='p.sudersan', description='GCI ID: ')\n",
    "dashtc_gcipwd_text = widgets.Password(value='K76DyGCw', description='GCI Password: ', style= {'description_width': 'initial'})\n",
    "dashtc_levername_selection = widgets.Dropdown(options=cantilever_list_ini, value='Multi75-G Budget Sensors', description='Cantilever: ')\n",
    "dashtc_temperature_text = widgets.FloatText(value=300, description='Temperature (K): ', style= {'description_width': 'initial'})\n",
    "# dashtc_autosave_checkbox = widgets.Checkbox(value=True, description='Auto save', indent=False)\n",
    "dashtc_save_button = widgets.Button(description='Save')\n",
    "dashtc_summaryout = widgets.Output()\n",
    "dashtc_fulldataout = widgets.Output()\n",
    "dashtc_filebrowserout = widgets.Output()\n",
    "dashtc_output = widgets.Output()\n",
    "\n",
    "\n",
    "dashtc_box1 = widgets.VBox([widgets.HBox([dashtc_levername_selection, dashtc_temperature_text]), \n",
    "                            widgets.HBox([dashtc_gciuid_text, dashtc_gcipwd_text])])\n",
    "dashtc_box2 = widgets.VBox([dashtc_loadfiles_button, dashtc_save_button])\n",
    "dashtc_box3 = widgets.VBox([dashtc_loadcali_button])\n",
    "dashtc_box4 = widgets.HBox([dashtc_box1, dashtc_box2, dashtc_box3, dashtc_loadselection_button])\n",
    "dashtc_results_tab = widgets.Tab()\n",
    "dashtc_results_tab.children = [dashtc_summaryout, dashtc_fulldataout, dashtc_filebrowserout, dashtc_output]\n",
    "dashtc_results_tab.titles = ['Summary', 'Full data', 'File browser', 'Debug']\n",
    "\n",
    "dashtc_filedf = dash0_create_summarytable(view_channels=['Amplitude', 'Phase'], data_type='2D')\n",
    "dashtc_filebrowser = ITable(dashtc_filedf,  select=True)\n",
    "dashtc_filebrowserout.clear_output(wait=True)\n",
    "with dashtc_filebrowserout:\n",
    "    display(dashtc_filebrowser)\n",
    "\n",
    "\n",
    "#set calibration dictionary\n",
    "def update_gaincalib(gain_value):\n",
    "    calib_summary = dashtc_datadict['Summary'].set_index(['parameters', 'gain in']) #for easy access of values\n",
    "    set_calibdict_values(channel = 'Amplitude', \n",
    "                         unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}})\n",
    "    set_calibdict_values(channel = 'True Amplitude',\n",
    "                         unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}})\n",
    "    set_calibdict_values(channel = 'Amplitude-sample distance',\n",
    "                         unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}\n",
    "                                   })\n",
    "    set_calibdict_values(channel = 'Amplitude dissipated',\n",
    "                         unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}\n",
    "                                   })\n",
    "    set_calibdict_values(channel = 'Energy dissipated',\n",
    "                         unit_kw = {'aJ': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean']**2, 'offset':0}\n",
    "                                   })\n",
    "    \n",
    "    set_calibdict_values(channel = 'Spring constant',\n",
    "                         unit_kw = {'N/m': {'factor': calib_summary.at[('Spring constant', gain_value), 'mean'], 'offset':0}})\n",
    "    set_calibdict_values(channel = 'Resonance frequency',\n",
    "                         unit_kw = {'Hz': {'factor': calib_summary.at[('Resonance frequency', gain_value), 'mean'], 'offset':0}})\n",
    "    set_calibdict_values(channel = 'Quality factor',\n",
    "                         unit_kw = {'': {'factor': calib_summary.at[('Q factor', gain_value), 'mean'], 'offset':0}})\n",
    "\n",
    "@dashtc_output.capture()\n",
    "def dashtc_calculate_thermalcalib(file_keys):\n",
    "    gci_uid = dashtc_gciuid_text.value #GCI user id\n",
    "    gci_pass = dashtc_gcipwd_text.value #GCI password\n",
    "    cantilever_name = dashtc_levername_selection.value #Cantilever name 'Multi75-G Budget Sensors' #'TAP150Al-G Budget Sensors' #'AC160TS-R3 Olympus'\n",
    "    Temp = dashtc_temperature_text.value #temperature in K\n",
    "    # save = dashtc_autosave_checkbox.value #save calibration results\n",
    "    \n",
    "    cantilever_dict = SaderGCI_GetLeverList(gci_uid, gci_pass)    \n",
    "    cantilever_num = cantilever_dict[cantilever_name]\n",
    "    \n",
    "    # file_keys = custom_filedialog(title='Choose thermal noise image files',\n",
    "    #                               initialdir=folderpath,\n",
    "    #                               file_ext = ['.ch15'],\n",
    "    #                               channels=['Amplitude'],\n",
    "    #                               flatten_chan=[],\n",
    "    #                               img_dirs=['Forward']\n",
    "    #                               )\n",
    "    \n",
    "    \n",
    "    # files = list(dict.fromkeys(file_keys))\n",
    "    files = list(file_keys.keys())\n",
    "    \n",
    "    psd_fitrange = (0, 1) #proportion of data to use for lorentzian fit of psd. useful when psd has peaks on data edges\n",
    "    # chan = 'Amplitude'\n",
    "    # chan_dir = 'Forward'\n",
    "    #AMPLITUDE BACKWARD CHANNEL IS UNUSUALLY BAD! CHECK DATA! \n",
    "    chan_dirs = ['Forward', 'Backward']\n",
    "    calib_data_dict = {'plot': [], 'file':[], 'frequency':[], \n",
    "                       'psd':[], 'psd max':[], 'zrms':[], 'gain in':[], 'Laser':[]}\n",
    "    files_skipped = []\n",
    "    for file_i in files:\n",
    "        # filepath_i = folderpath + '/' + file_df.loc[(file_df.file==file_i)].iloc[0].loc['name']\n",
    "        filepath_i = file_keys[file_i]\n",
    "        data_i = wsxm_readchan(filepath_i, all_files=True, mute=True)\n",
    "        # wsxm_calc_trueampphase(data_i, data_type='2D')\n",
    "        # for chan_dir in chan_dirs: #data_i[chan].keys():\n",
    "        amp_data_i = data_i['Amplitude']\n",
    "        phase_data_i = data_i['Phase']\n",
    "        # print(amp_data_i['Forward']['data']['Z'].min(),amp_data_i['Forward']['data']['Z'].max(),\n",
    "        #      amp_data_i['Backward']['data']['Z'].min(),amp_data_i['Backward']['data']['Z'].max(),\n",
    "        #      phase_data_i['Forward']['data']['Z'].min(),phase_data_i['Forward']['data']['Z'].max(),\n",
    "        #      phase_data_i['Backward']['data']['Z'].min(),phase_data_i['Backward']['data']['Z'].max())\n",
    "        # phase_data_i = data_i['Phase']\n",
    "        imgdir_i = list(amp_data_i.keys())[0]\n",
    "        # ampunit_i = amp_data_i['header']['Z Amplitude [General Info]'].split(' ')[1]\n",
    "        # phaseunit_i = phase_data_i['header']['Z Amplitude [General Info]'].split(' ')[1]\n",
    "        # if ampunit_i != 'V' or phaseunit_i != 'V':\n",
    "        #     files_skipped.append(f'{file_i}:{chan_dir}')\n",
    "        #     # print('RAW DATA NOT IN VOLTS! Skipping:', file_i, chan, chan_dir)\n",
    "        #     continue\n",
    "        freq_i, psd_i, psdmax_i, zrms_i, fig_i = get_psd_calib(amp_data_i, phase_data_i)\n",
    "        # print(zrms_i)\n",
    "        calib_data_dict['file'].append(file_i)\n",
    "        # calib_data_dict['direction'].append(chan_dir)\n",
    "        calib_data_dict['frequency'].append(freq_i)\n",
    "        calib_data_dict['psd'].append(psd_i)\n",
    "        calib_data_dict['psd max'].append(psdmax_i)\n",
    "        calib_data_dict['zrms'].append(zrms_i)\n",
    "        calib_data_dict['plot'].append(fig_i)\n",
    "        calib_data_dict['gain in'].append(int(amp_data_i[imgdir_i]['header']['Gain in [Dynamic settings]']))\n",
    "        calib_data_dict['Laser'].append(amp_data_i[imgdir_i]['header']['Laser On [Miscellaneous]'])\n",
    "            \n",
    "    calib_df = pd.DataFrame(calib_data_dict)\n",
    "    \n",
    "    #assort files into \"laser on\" and \"laser off\" groups using kmeans clustering algo on max of psd value\n",
    "    # rms_values = calib_df['psd max'].values.reshape(-1,1)\n",
    "    # kmeans = KMeans(n_clusters=2) # Create a KMeans instance with 2 clusters: kmeans\n",
    "    # kmeans.fit(rms_values) # Fit model to your data\n",
    "    # centroids = kmeans.cluster_centers_# Get the cluster centroids\n",
    "    # low_cluster, high_cluster = (0, 1) if centroids[0] < centroids[1] else (1, 0) # Determine which cluster corresponds to 'low' or 'high'\n",
    "    # calib_df['Laser'] = ['OFF' if label == low_cluster else 'ON' for label in kmeans.labels_]\n",
    "    calib_df_off = calib_df[calib_df['Laser'] == 'No'].sort_values(by=['gain in']).reset_index(drop=True)\n",
    "    calib_df_on = calib_df[calib_df['Laser'] == 'Yes'].sort_values(by=['gain in']).reset_index(drop=True)\n",
    "    # row_min = min([calib_df_on.shape[0],calib_df_off.shape[0]]) #for one-to-one map of ON and OFF files\n",
    "    \n",
    "    calib_result_dict = {'plot': [], 'Amplitude calib':[], 'Resonance frequency': [], 'Q factor':[], 'Spring constant':[], 'Amp rms': [], 'PSD rms':[],\n",
    "                         'gain in':[], 'file_on': [], 'file_off': []}\n",
    "    #organise data files so that each laser on file has a corresponding laser off file.\n",
    "    j_list = [] #off files already used to calibrate\n",
    "    j_exists = False #flag to check if \"off\" file was used before\n",
    "    for i in range(calib_df_on.shape[0]): #index for calib_df_on\n",
    "        j = 0 #index for calib_df_off\n",
    "        while True:\n",
    "            if j >= calib_df_off.shape[0]:\n",
    "                if j_exists == True:\n",
    "                    j = j_list[-1]\n",
    "                    calib_df_on_i = calib_df_on.iloc[i]\n",
    "                    calib_df_off_i = calib_df_off.iloc[j_list[-1]]\n",
    "                    break\n",
    "                j += 1\n",
    "            else:\n",
    "                pass\n",
    "            if calib_df_on['gain in'].iloc[i] != calib_df_off['gain in'].iloc[j]:\n",
    "                if j_exists == True:\n",
    "                    j = j_list[-1]\n",
    "                    calib_df_on_i = calib_df_on.iloc[i]\n",
    "                    calib_df_off_i = calib_df_off.iloc[j_list[-1]]\n",
    "                    break\n",
    "                j += 1\n",
    "            else:\n",
    "                if j in j_list:\n",
    "                    j_exists = True\n",
    "                    j += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    j_exists = False\n",
    "                    calib_df_on_i = calib_df_on.iloc[i]\n",
    "                    calib_df_off_i = calib_df_off.iloc[j]\n",
    "                    j_list.append(j)\n",
    "                    break\n",
    "        # print(i, j, calib_df_on_i['file'], calib_df_off_i['file'])\n",
    "        ampcali_i, kcant_i, fitdict_i,  plot_i = get_calib(calib_df_on_i,calib_df_off_i, datarange=psd_fitrange, #qfac_i, amprms_i,k_lever=k_cantilver, \n",
    "                                                           T=Temp, #corr_fac=correction_factor, \n",
    "                                                           #cant_width=cant_width, cant_length=cant_length\n",
    "                                                          lever_number=cantilever_num, userid=gci_uid, password=gci_pass)\n",
    "        # print(calib_df_on['zrms'].iloc[i], calib_df_off['zrms'].iloc[i], amprms_i)\n",
    "        # zrms_i = (calib_df_on['zrms'].iloc[i]**2 - calib_df_off['zrms'].iloc[i]**2)**0.5 #CHECK THIS!\n",
    "        calib_result_dict['Amplitude calib'].append(ampcali_i)\n",
    "        calib_result_dict['Spring constant'].append(kcant_i)\n",
    "        calib_result_dict['Resonance frequency'].append(fitdict_i['resonance freq'])\n",
    "        calib_result_dict['Q factor'].append(fitdict_i['Q factor'])\n",
    "        calib_result_dict['Amp rms'].append(fitdict_i['zrms'])#zrms_i)\n",
    "        calib_result_dict['PSD rms'].append(fitdict_i['V rms'])\n",
    "        calib_result_dict['plot'].append(plot_i)\n",
    "        calib_result_dict['gain in'].append(calib_df_on['gain in'].iloc[i])\n",
    "        calib_result_dict['file_on'].append(calib_df_on['file'].iloc[i])\n",
    "        calib_result_dict['file_off'].append(calib_df_off['file'].iloc[j])\n",
    "    calib_result_df = pd.DataFrame(calib_result_dict)\n",
    "    \n",
    "    \n",
    "    # calib_summary = pd.DataFrame({'Mean': calib_result_df.drop(columns=['plot', 'gain in','file_on','file_off']).mean(),\n",
    "    #                               'Standard Deviation': calib_result_df.drop(columns=['plot', 'gain in', 'file_on', 'file_off']).std()\n",
    "    #                               })\n",
    "    calibdf_long = pd.melt(calib_result_df,  id_vars= ['gain in'], value_vars=['Amplitude calib', 'Spring constant', 'Resonance frequency', 'Q factor',\n",
    "                                                                               'Amp rms', 'PSD rms'], var_name = 'parameters')\n",
    "    calib_summary = calibdf_long.groupby(['parameters', 'gain in'], as_index=True, sort=False).agg(mean=('value', 'mean'), std=('value', 'std')).reset_index()\n",
    "\n",
    "    calib_summary['cantilever'] = cantilever_name\n",
    "    calib_summary['temperature'] = Temp\n",
    "    # if len(files_skipped) != 0:\n",
    "    #     print('SOME RAW DATA NOT IN VOLTS! Skipped:', '; '.join(files_skipped))\n",
    "    dashtc_summaryout.clear_output(wait=True)\n",
    "    with dashtc_summaryout:\n",
    "        # itables.show(calib_summary, paging=False)\n",
    "        display(ITable(calib_summary, paging=False))\n",
    "    dashtc_fulldataout.clear_output(wait=True)\n",
    "    with dashtc_fulldataout:\n",
    "        # itables.show(calib_result_df)\n",
    "        display(ITable(calib_result_df))\n",
    "    # itables.show(calib_df.drop(columns=['frequency', 'psd']))\n",
    "\n",
    "    dashtc_datadict['Summary'] = calib_summary\n",
    "    dashtc_datadict['Full data'] = calib_result_df\n",
    "\n",
    "    update_gaincalib(gain_ini) #set thermal calibration\n",
    "\n",
    "\n",
    "@dashtc_output.capture()\n",
    "def dashtc_load_fromselection(change):\n",
    "    filebrowser_selected = dashtc_filebrowser.df.iloc[dashtc_filebrowser.selected_rows].merge(dash0_filedict['full'][['file', 'name']], on='file', how='left')\n",
    "    file_keys = {}\n",
    "    for i in filebrowser_selected.iterrows():\n",
    "        file_keys[i[1]['file']] = folderpath / i[1]['name']    \n",
    "    \n",
    "    dashtc_calculate_thermalcalib(file_keys)\n",
    "\n",
    "@dashtc_output.capture()\n",
    "def dashtc_load_fromdirectory(change):\n",
    "    file_keys = custom_filedialog(title='Choose thermal noise image files',\n",
    "                                  initialdir=folderpath,\n",
    "                                  file_ext = ['.ch15'],\n",
    "                                  channels=['Amplitude'],\n",
    "                                  flatten_chan=[],\n",
    "                                  img_dirs=['Forward']\n",
    "                                  )\n",
    "    \n",
    "    dashtc_calculate_thermalcalib(file_keys)\n",
    "    \n",
    "    \n",
    "\n",
    "@dashtc_output.capture()\n",
    "def dashtc_load_thermalcalib(change):\n",
    "    calib_folder_path = filedialog.askopenfilename(title=\"Open thermal calibration data\", \n",
    "                                                        defaultextension='.xlsx',\n",
    "                                                        initialdir=outputpath\n",
    "                                                       )\n",
    "    \n",
    "    calib_summary = pd.read_excel(calib_folder_path, sheet_name='summary')\n",
    "    calib_result_df = pd.read_excel(calib_folder_path, sheet_name='Sheet')\n",
    "    \n",
    "    dashtc_summaryout.clear_output(wait=True)\n",
    "    with dashtc_summaryout:\n",
    "        # itables.show(calib_summary, paging=False)\n",
    "        display(ITable(calib_summary, paging=False))\n",
    "    dashtc_fulldataout.clear_output(wait=True)\n",
    "    with dashtc_fulldataout:\n",
    "        # itables.show(calib_result_df)\n",
    "        display(ITable(calib_result_df))\n",
    "    dashtc_datadict['Summary'] = calib_summary\n",
    "    dashtc_datadict['Full data'] = calib_result_df\n",
    "\n",
    "    update_gaincalib(gain_ini) #set thermal calibration\n",
    "\n",
    "@dashtc_output.capture()\n",
    "def dashtc_save_thermalcalib(change):\n",
    "    save_folder_path = filedialog.asksaveasfilename(title=\"Save thermal calibration data\", \n",
    "                                                    defaultextension='.xlsx',\n",
    "                                                    initialdir=outputpath,\n",
    "                                                    initialfile='thermal_calibration'\n",
    "                                                   )\n",
    "    if save_folder_path != ():\n",
    "        imagedf_to_excel(dashtc_datadict['Full data'], save_folder_path, img_size=(250, 200))\n",
    "        with pd.ExcelWriter(save_folder_path, engine='openpyxl', mode='a') as writer:  \n",
    "            dashtc_datadict['Summary'].to_excel(writer, sheet_name='summary', index=False)\n",
    "        print('Thermal calibration data saved to:', save_folder_path)\n",
    "\n",
    "dashtc_loadfiles_button.on_click(dashtc_load_fromdirectory)\n",
    "dashtc_loadselection_button.on_click(dashtc_load_fromselection)\n",
    "dashtc_loadcali_button.on_click(dashtc_load_thermalcalib)\n",
    "dashtc_save_button.on_click(dashtc_save_thermalcalib)\n",
    "display(dashtc_box4)\n",
    "display(dashtc_results_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecfe6b8-f761-4d6a-88a4-180f650e4078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Obtain spring constant from Sader GCI method (requires internet) See https://sadermethod.org/\n",
    "from Sader_GCI_demo import SaderGCI_GetLeverList, SaderGCI_CalculateK\n",
    "\n",
    "cantilever_dict = SaderGCI_GetLeverList('p.sudersan', 'K76DyGCw')\n",
    "display(cantilever_dict)\n",
    "print(cantilever_dict['TAP150Al-G Budget Sensors'])\n",
    "# lever_num = cantilever_dict['AC160TS-R3 Olympus']\n",
    "\n",
    "# SaderGCI_CalculateK('p.sudersan', 'K76DyGCw', lever_num, #288, #5\n",
    "#                     calib_summary.at[('Resonance frequency', 10), 'mean']/1000, #in kHz\n",
    "#                     calib_summary.at[('Q factor', 10), 'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437248a4-1f8e-4743-b6eb-a5ad6c354031",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Force-distance method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f751fe-f052-4906-a579-47ac785c14bc",
   "metadata": {},
   "source": [
    "#### Normal force calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8109bc-933e-46a9-8d91-27750761a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibrate normal force and amplitude from spectroscopy curves\n",
    "\n",
    "\n",
    "\n",
    "dashsc_datadict = {}\n",
    "dashsc_tablewiddict = {}\n",
    "\n",
    "dashsc_loadfiles_button = widgets.Button(description='Load files')\n",
    "dashsc_loadselection_button = widgets.Button(description='LOAD', tooltip='Load selected files in file browser',\n",
    "                                             layout=widgets.Layout(height='auto'), style={\"button_height\": \"100px\", 'font_size':\"28px\"})\n",
    "dashsc_loadcali_button = widgets.Button(description='Load calibration')\n",
    "dashsc_removeselection_button = widgets.Button(description='Remove selection')\n",
    "dashsc_save_button = widgets.Button(description='Save')\n",
    "# dashsc_autosave_checkbox = widgets.Checkbox(value=True, description='Auto save', indent=False)\n",
    "dashsc_summaryout = widgets.Output()\n",
    "dashsc_fulldataout = widgets.Output()\n",
    "dashsc_filebrowserout = widgets.Output()\n",
    "dashsc_output = widgets.Output()\n",
    "\n",
    "dashsc_box1 = widgets.VBox([dashsc_loadfiles_button, dashsc_loadcali_button])\n",
    "dashsc_box2 = widgets.VBox([dashsc_removeselection_button, dashsc_save_button])\n",
    "dashsc_box3 = widgets.HBox([dashsc_box1, dashsc_box2, dashsc_loadselection_button])\n",
    "dashsc_results_tab = widgets.Tab()\n",
    "dashsc_results_tab.children = [dashsc_summaryout, dashsc_fulldataout, dashsc_filebrowserout, dashsc_output]\n",
    "dashsc_results_tab.titles = ['Summary', 'Full data', 'File browser', 'Debug']\n",
    "\n",
    "dashsc_filedf = dash0_create_summarytable(view_channels=['Normal force', 'Amplitude'], data_type='1D')\n",
    "dashsc_filedf_filtered = dash0_filedict['full'][dash0_filedict['full']['channel'] == 'Normal force']\n",
    "dashsc_filedf_merged = dashsc_filedf.merge(dashsc_filedf_filtered[['file', 'extension', 'name']], on='file', how='left')\n",
    "dashsc_filebrowser = ITable(dashsc_filedf_merged,  select=True)\n",
    "dashsc_filebrowserout.clear_output(wait=True)\n",
    "with dashsc_filebrowserout:\n",
    "    display(dashsc_filebrowser)\n",
    "\n",
    "@dashsc_output.capture()\n",
    "def dashsc_setcalibration():\n",
    "    set_calibdict_values(channel = 'Normal force', \n",
    "                         unit_kw = {'nN': {'factor': dashsc_datadict['Summary']['Mean'].loc['normal defl calib [nm/V]'] * \\\n",
    "                                           get_calibdict_value('Spring constant','N/m')['factor'], \n",
    "                                           'offset':0}\n",
    "                                   })\n",
    "    set_calibdict_values(channel = 'Normal deflection', \n",
    "                         unit_kw = {'nm': {'factor': dashsc_datadict['Summary']['Mean'].loc['normal defl calib [nm/V]'], 'offset':0},\n",
    "                                   })\n",
    "\n",
    "@dashsc_output.capture()\n",
    "def dashsc_update_summary(calib_spectro_df):\n",
    "    # calib_spectro_df = dashsc_datadict['Full data']\n",
    "    \n",
    "    calib_spectro_summary = pd.DataFrame({'Mean': calib_spectro_df[['normal defl calib [nm/V]', \n",
    "                                                                    'amplitude calib [nm/V]']].mean(),\n",
    "                                          'Standard Deviation': calib_spectro_df[['normal defl calib [nm/V]', \n",
    "                                                                                  'amplitude calib [nm/V]']].std()\n",
    "                                          })\n",
    "    dashsc_datadict['Summary'] = calib_spectro_summary\n",
    "    dashsc_summaryout.clear_output(wait=True)\n",
    "    with dashsc_summaryout:\n",
    "        # itables.show(calib_spectro_summary)\n",
    "        display(ITable(calib_spectro_summary, paging=False))    \n",
    "    \n",
    "@dashsc_output.capture()\n",
    "def dashsc_calculate_spectrocalib(file_keys):\n",
    "    # save = dashsc_autosave_checkbox.value\n",
    "    # k_cantilver = 4.67 #2.66637 #cantilever spring constant in N/m\n",
    "    # correction_factor = 1 # correction factor for static deflection calibration; Butt-Jaschke: 0.817, no correction: 1\n",
    "    \n",
    "    # file_paths = list(filedialog.askopenfilenames(title='Choose spectroscopy file', \n",
    "    #                                               initialdir=folderpath, filetypes=(('spectroscopy curves',['*.curves']),\n",
    "    #                                                                                 ('spectroscopy image',['*.stp']),\n",
    "    #                                                                                 ('spectroscopy solo curve',['*.cur','*.curve']),\n",
    "    #                                                                                )))\n",
    "    # file_paths = list(filedialog.askopenfilenames(title='Choose spectroscopy file', \n",
    "    #                                               initialdir=folderpath, filetypes=(('force curves',['*Normal force*']),\n",
    "    #                                                                                )))\n",
    "    # file_df =  dash0_filedict['full']\n",
    "    # file_keys = []\n",
    "    # for file_path_i in file_paths: #find the list of unique file keyword names\n",
    "    #     file_name_i = os.path.basename(file_path_i)\n",
    "    #     file_keys.append(file_df[file_df['name']==file_name_i]['file'].iloc[0])\n",
    "    \n",
    "    # file_keys = custom_filedialog(title='Choose force-distance curves',\n",
    "    #                               initialdir=folderpath,\n",
    "    #                               file_ext = ['.curves', '.cur'],\n",
    "    #                               channels=['Normal force', 'Amplitude'],\n",
    "    #                               flatten_chan=[],\n",
    "    #                               img_dirs=[]\n",
    "    #                               )\n",
    "    \n",
    "    files = list(dict.fromkeys(file_keys))\n",
    "    # files = ['interdigThiols_tipSi3nN_a_0003', 'interdigThiols_tipSi3nN_a_0005']\n",
    "    \n",
    "    unit_dict_cali = {'Normal force': 'V',\n",
    "                      'Normal deflection': 'V',\n",
    "                      'Amplitude': 'V',\n",
    "                      'True Amplitude': 'V',\n",
    "                      'Z': 'nm' #CHECK THIS, MAKE CONSISTENT WITH RAW DATA UNITS\n",
    "                     }\n",
    "    # chan = 'Normal force'\n",
    "    spec_dir = 'approach'\n",
    "    set_funcdict_kwargs(channel='Normal deflection',param='Snap-in distance',kwargs={'method':'minima'})\n",
    "    set_funcdict_kwargs(channel='Normal force',param='Stiffness',kwargs={'method':'best gradient', 'fit_order':2, \n",
    "                                                                         'percentile_range':(0, 50), 'filter_size': 30})\n",
    "    set_funcdict_kwargs(channel='True Amplitude',param='True Slope-amp',kwargs={'method':'minmax'})\n",
    "    set_funcdict_kwargs(channel='Amplitude',param='Slope-amp',kwargs={'method':'minmax'})\n",
    "    properties = ['Snap-in distance', 'Adhesion', 'Stiffness', 'Slope-amp', 'True Slope-amp']\n",
    "    \n",
    "    calib_spectro_dict = {'plot normf': [], 'plot amp': [], 'normal defl calib [nm/V]':[], \n",
    "                          'amplitude calib [nm/V]':[], 'file':[], 'curve num':[]}\n",
    "    for file_i in files:\n",
    "        filepath_i = file_keys[file_i] #folderpath / file_df.loc[(file_df.file==file_i)].iloc[0].loc['name']\n",
    "        print(file_i, filepath_i)\n",
    "        # filename_i = os.path.basename(filepath_i)\n",
    "        data_i = wsxm_readspectra(filepath_i, all_files=True, mute=True, extra_channels=True)\n",
    "        print(data_i.keys())\n",
    "        # for chan_dir in data_i[chan].keys():\n",
    "        curve_numlist = data_i['Normal force']['curves'].keys()\n",
    "        for curv_ind in curve_numlist:\n",
    "            if curv_ind == 'Average':\n",
    "                continue\n",
    "            #normal defl calibration\n",
    "            defl_data_i = data_i['Normal deflection']['curves'][curv_ind]['data']        \n",
    "            _, _ = wsxm_calcspectroparam(defl_data_i, 'Normal deflection', #calculate snapin first to get stiffness correctly\n",
    "                                         unit_dict=unit_dict_cali, properties=properties)\n",
    "            spectro_data_i = data_i['Normal force']['curves'][curv_ind]['data']\n",
    "            spectrodf_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_i, 'Normal force', \n",
    "                                                                unit_dict=unit_dict_cali, properties=properties)\n",
    "            if spectroparam_i['Stiffness']['value'] != 0:\n",
    "                defl_calib = 1/spectroparam_i['Stiffness']['value'] #cantilever deflection calibration in nm/V\n",
    "            else:\n",
    "                defl_calib = 0\n",
    "                print('Normal force slope is zero. Check: ', file_i)\n",
    "            # fig, ax = plt.subplots()\n",
    "            # sns.lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", hue=\"segment\", ax=ax)\n",
    "            # handles, labels = ax.get_legend_handles_labels()\n",
    "            # ax.legend(handles=handles, labels=labels) #remove legend title        \n",
    "            # ax.hlines(spectroparam_i['Adhesion']['zero'], spectrodf_i['x'].min(), \n",
    "            #            spectrodf_i['x'].max(), linestyles='dashed', colors='r')\n",
    "            # ax.plot(spectroparam_i['Stiffness']['x'], spectroparam_i['Stiffness']['y'],\n",
    "            #          'r', linestyle='dashed',linewidth=2)\n",
    "            fig = plotly_lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", color=\"segment\")\n",
    "            plotly_dashedlines(plot_type='hline',fig=fig, y=spectroparam_i['Adhesion']['zero'], line_width=2)\n",
    "            plotly_dashedlines(plot_type='line',fig=fig, x=spectroparam_i['Stiffness']['x'], \n",
    "                               y=spectroparam_i['Stiffness']['y'], line_width=2)\n",
    "            fig.update_layout(showlegend=False)\n",
    "            fig_i = fig2html(fig, plot_type='plotly')\n",
    "            # plt.close()\n",
    "            calib_spectro_dict['normal defl calib [nm/V]'].append(defl_calib)\n",
    "            calib_spectro_dict['plot normf'].append(fig_i)\n",
    "            \n",
    "            #amplitude calibration\n",
    "            if 'True Amplitude' in data_i.keys(): #FIX THIS!\n",
    "                # print('True Amplitude calibrated')\n",
    "                spectro_data_i = data_i['True Amplitude']['curves'][curv_ind]['data']\n",
    "                spectrodf_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_i, 'True Amplitude', \n",
    "                                                                    unit_dict=unit_dict_cali, properties=properties)\n",
    "                if spectroparam_i['True Slope-amp']['value'] != 0:\n",
    "                    amp_calib = 1/spectroparam_i['True Slope-amp']['value'] #amplitude calibration in nm/V\n",
    "                else:\n",
    "                    amp_calib = 0\n",
    "                    print('Amp slope is zero. Check: ', file_i)\n",
    "                fig = plotly_lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", color=\"segment\")\n",
    "                plotly_dashedlines(plot_type='line',fig=fig, x=spectroparam_i['True Slope-amp']['x'], \n",
    "                                   y=spectroparam_i['True Slope-amp']['y'], line_width=2)\n",
    "            else:\n",
    "                # print('Amplitude calibrated')\n",
    "                spectro_data_i = data_i['Amplitude']['curves'][curv_ind]['data']\n",
    "                spectrodf_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_i, 'Amplitude', \n",
    "                                                                    unit_dict=unit_dict_cali, properties=properties)\n",
    "                if spectroparam_i['Slope-amp']['value'] != 0:\n",
    "                    amp_calib = 1/spectroparam_i['Slope-amp']['value'] #amplitude calibration in nm/V\n",
    "                else:\n",
    "                    amp_calib = 0\n",
    "                    print('Amp slope is zero. Check: ', file_i)\n",
    "            # fig, ax = plt.subplots()\n",
    "            # sns.lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", hue=\"segment\", ax=ax)\n",
    "            # handles, labels = ax.get_legend_handles_labels()\n",
    "            # ax.legend(handles=handles, labels=labels) #remove legend title        \n",
    "            # ax.plot(spectroparam_i['Slope-amp']['x'], spectroparam_i['Slope-amp']['y'],\n",
    "            #          'r', linestyle='dashed',linewidth=2)\n",
    "                fig = plotly_lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", color=\"segment\")\n",
    "                plotly_dashedlines(plot_type='line',fig=fig, x=spectroparam_i['Slope-amp']['x'], \n",
    "                                   y=spectroparam_i['Slope-amp']['y'], line_width=2)\n",
    "            fig.update_layout(showlegend=False)\n",
    "            fig_i = fig2html(fig, plot_type='plotly')\n",
    "            \n",
    "            # plt.close()\n",
    "            calib_spectro_dict['amplitude calib [nm/V]'].append(amp_calib)\n",
    "            calib_spectro_dict['plot amp'].append(fig_i)\n",
    "            \n",
    "            calib_spectro_dict['file'].append(file_i)\n",
    "            calib_spectro_dict['curve num'].append(curv_ind)\n",
    "            \n",
    "    \n",
    "    calib_spectro_df = pd.DataFrame(calib_spectro_dict)\n",
    "    \n",
    "    # calib_spectro_summary = pd.DataFrame({'Mean': calib_spectro_df[['normal defl calib [nm/V]', \n",
    "    #                                                                 'amplitude calib [nm/V]']].mean(),\n",
    "    #                                       'Standard Deviation': calib_spectro_df[['normal defl calib [nm/V]', \n",
    "    #                                                                               'amplitude calib [nm/V]']].std()\n",
    "    #                                       })\n",
    "    # dashsc_datadict['Summary'] = calib_spectro_summary\n",
    "    # dashsc_summaryout.clear_output(wait=True)\n",
    "    # with dashsc_summaryout:\n",
    "    #     # itables.show(calib_spectro_summary)\n",
    "    #     display(ITable(calib_spectro_summary, paging=False))\n",
    "    dashsc_fulldataout.clear_output(wait=True)\n",
    "    with dashsc_fulldataout:\n",
    "        # itables.show(calib_spectro_df)\n",
    "        dashsc_tablewiddict['Full data'] = ITable(calib_spectro_df, select=True)\n",
    "        display(dashsc_tablewiddict['Full data'])\n",
    "    \n",
    "    \n",
    "    dashsc_datadict['Full data'] = calib_spectro_df\n",
    "\n",
    "    dashsc_update_summary(calib_spectro_df) #update summary\n",
    "\n",
    "    dashsc_setcalibration() #set calibration\n",
    "    # #save calibration data\n",
    "    # if save == True:\n",
    "    #     save_folder_path = filedialog.asksaveasfilename(title=\"Save spectroscopy calibration data\", \n",
    "    #                                                     defaultextension='.xlsx',\n",
    "    #                                                     initialdir=outputpath,\n",
    "    #                                                     initialfile='spectroscopy_calibration'\n",
    "    #                                                    )\n",
    "    #     if save_folder_path != ():\n",
    "    #         imagedf_to_excel(calib_spectro_df, save_folder_path, img_size=(250, 200))\n",
    "    #         with pd.ExcelWriter(save_folder_path, engine='openpyxl', mode='a') as writer:  \n",
    "    #             calib_spectro_summary.to_excel(writer, sheet_name='summary')\n",
    "    #         print('Spectroscopy calibration data saved to:', save_folder_path)\n",
    "\n",
    "\n",
    "@dashsc_output.capture()\n",
    "def dashsc_load_spectrocalib(change):\n",
    "    calib_folder_path = filedialog.askopenfilename(title=\"Open spectroscopy calibration data\", \n",
    "                                                        defaultextension='.xlsx',\n",
    "                                                        initialdir=outputpath\n",
    "                                                       )\n",
    "    \n",
    "    calib_summary = pd.read_excel(calib_folder_path, sheet_name='summary', index_col=0)\n",
    "    calib_result_df = pd.read_excel(calib_folder_path, sheet_name='Sheet')\n",
    "    \n",
    "    dashsc_summaryout.clear_output(wait=True)\n",
    "    with dashsc_summaryout:\n",
    "        # itables.show(calib_summary, paging=False)\n",
    "        display(ITable(calib_summary, paging=False))\n",
    "    dashsc_fulldataout.clear_output(wait=True)\n",
    "    with dashsc_fulldataout:\n",
    "        # itables.show(calib_result_df)\n",
    "        display(ITable(calib_result_df))\n",
    "    dashsc_datadict['Summary'] = calib_summary\n",
    "    dashsc_datadict['Full data'] = calib_result_df\n",
    "\n",
    "    dashsc_setcalibration() #set calibration\n",
    "\n",
    "@dashsc_output.capture()\n",
    "def dashsc_load_fromselection(change):\n",
    "    # filebrowser_selected = dashsc_filebrowser.df.iloc[dashsc_filebrowser.selected_rows].merge(dash0_filedict['full'][['file', 'name']], on='file', how='left')\n",
    "    filebrowser_selected = dashsc_filebrowser.df.iloc[dashsc_filebrowser.selected_rows]\n",
    "    file_keys = {}\n",
    "    for i in filebrowser_selected.iterrows():\n",
    "        file_keys[i[1]['file']] = folderpath / i[1]['name']    \n",
    "    \n",
    "    dashsc_calculate_spectrocalib(file_keys)\n",
    "\n",
    "@dashsc_output.capture()\n",
    "def dashsc_load_fromdirectory(change):\n",
    "    file_keys = custom_filedialog(title='Choose force-distance curves',\n",
    "                                  initialdir=folderpath,\n",
    "                                  file_ext = ['.curves', '.cur'],\n",
    "                                  channels=['Normal force', 'Amplitude'],\n",
    "                                  flatten_chan=[],\n",
    "                                  img_dirs=[]\n",
    "                                  )\n",
    "    \n",
    "    dashsc_calculate_spectrocalib(file_keys)\n",
    "\n",
    "@dashsc_output.capture()\n",
    "def dashsc_remove_selection(change):\n",
    "    calib_result_df_new = dashsc_tablewiddict['Full data'].df.drop(dashsc_tablewiddict['Full data'].selected_rows).reset_index(drop=True)\n",
    "    # dashsc_tablewiddict['Full data'].update(calib_result_df_new)\n",
    "    dashsc_fulldataout.clear_output(wait=True)\n",
    "    with dashsc_fulldataout:\n",
    "        # itables.show(calib_spectro_df)\n",
    "        dashsc_tablewiddict['Full data'] = ITable(calib_result_df_new, select=True)\n",
    "        display(dashsc_tablewiddict['Full data'])\n",
    "    dashsc_datadict['Full data'] = calib_result_df_new\n",
    "    \n",
    "    dashsc_update_summary(calib_result_df_new) #update summary\n",
    "\n",
    "@dashsc_output.capture()\n",
    "def dashsc_save_spectrocalib(change):\n",
    "    save_folder_path = filedialog.asksaveasfilename(title=\"Save spectroscopy calibration data\", \n",
    "                                                    defaultextension='.xlsx',\n",
    "                                                    initialdir=outputpath,\n",
    "                                                    initialfile='spectroscopy_calibration'\n",
    "                                                   )\n",
    "    if save_folder_path != ():\n",
    "        imagedf_to_excel(dashsc_datadict['Full data'], save_folder_path, img_size=(250, 200))\n",
    "        with pd.ExcelWriter(save_folder_path, engine='openpyxl', mode='a') as writer:  \n",
    "            dashsc_datadict['Summary'].to_excel(writer, sheet_name='summary')\n",
    "        print('Spectroscopy calibration data saved to:', save_folder_path)\n",
    "\n",
    "    \n",
    "dashsc_loadfiles_button.on_click(dashsc_load_fromdirectory)\n",
    "dashsc_loadselection_button.on_click(dashsc_load_fromselection)\n",
    "dashsc_loadcali_button.on_click(dashsc_load_spectrocalib)\n",
    "dashsc_removeselection_button.on_click(dashsc_remove_selection)\n",
    "dashsc_save_button.on_click(dashsc_save_spectrocalib)\n",
    "# display(dashsc_box1)\n",
    "display(dashsc_box3)\n",
    "display(dashsc_results_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6423e59c-57be-41ff-9f67-acc62c81b807",
   "metadata": {},
   "source": [
    "#### Amplitude calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811dcc1-2da2-44b9-b0cd-18ad6c32de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibrate normal force and amplitude from spectroscopy curves\n",
    "\n",
    "# k_cantilver = 1.63 #2.66637 #cantilever spring constant in N/m\n",
    "\n",
    "# file_paths = list(filedialog.askopenfilenames(title='Choose spectroscopy file', \n",
    "#                                               initialdir=folderpath, filetypes=(('spectroscopy curves',['*.curves']),\n",
    "#                                                                                 ('spectroscopy image',['*.stp']),\n",
    "#                                                                                 ('spectroscopy solo curve',['*.cur','*.curve']),\n",
    "#                                                                                )))\n",
    "file_paths = list(filedialog.askopenfilenames(title='Choose spectroscopy file', \n",
    "                                              initialdir=folderpath, filetypes=(('amplitude curves',['*Amplitude*']),\n",
    "                                                                               )))\n",
    "file_df =  dash0_filedict['full']\n",
    "file_keys = []\n",
    "for file_path_i in file_paths: #find the list of unique file keyword names\n",
    "    file_name_i = os.path.basename(file_path_i)\n",
    "    file_keys.append(file_df[file_df['name']==file_name_i]['file'].iloc[0])\n",
    "files = list(dict.fromkeys(file_keys))\n",
    "# files = ['interdigThiols_tipSi3nN_a_0003', 'interdigThiols_tipSi3nN_a_0005']\n",
    "\n",
    "unit_dict_cali = {'Normal force': 'V',\n",
    "                  'Normal deflection': 'V',\n",
    "                  'Amplitude': 'V',\n",
    "                  'True Amplitude': 'V',\n",
    "                  'Z': 'nm' #CHECK THIS, MAKE CONSISTENT WITH RAW DATA UNITS\n",
    "                 }\n",
    "# chan = 'Normal force'\n",
    "spec_dir = 'approach'\n",
    "set_funcdict_kwargs(channel='Normal force',param='Stiffness',kwargs={'method':'best gradient', 'fit_order':1, \n",
    "                                                                     'percentile_range':(0, 50), 'filter_size': 30})\n",
    "set_funcdict_kwargs(channel='True Amplitude',param='True Slope-amp',kwargs={'method':'minmax'})\n",
    "set_funcdict_kwargs(channel='Amplitude',param='Slope-amp',kwargs={'method':'minmax'})\n",
    "properties = ['Snap-in distance', 'Adhesion', 'Stiffness', 'Slope-amp', 'True Slope-amp']\n",
    "\n",
    "\n",
    "calib_spectro_dict = {'plot normf': [], 'plot amp': [], 'normal defl calib [nm/V]':[], \n",
    "                      'amplitude calib [nm/V]':[], 'file':[], 'curve num':[]}\n",
    "for file_i in files:\n",
    "    filepath_i = folderpath + '/' + file_df.loc[(file_df.file==file_i)].iloc[0].loc['name']\n",
    "    # filename_i = os.path.basename(filepath_i)\n",
    "    data_i = wsxm_readspectra(filepath_i, all_files=True, mute=True)\n",
    "    # for chan_dir in data_i[chan].keys():\n",
    "    curve_numlist = data_i['Normal force']['curves'].keys()\n",
    "    for curv_ind in curve_numlist:\n",
    "        if curv_ind == 'Average':\n",
    "            continue\n",
    "        #normal defl calibration\n",
    "        defl_data_i = data_i['Normal deflection']['curves'][curv_ind]['data']        \n",
    "        _, _ = wsxm_calcspectroparam(defl_data_i, 'Normal deflection', #calculate snapin first to get stiffness correctly\n",
    "                                     unit_dict=unit_dict_cali, properties=properties)\n",
    "        spectro_data_i = data_i['Normal force']['curves'][curv_ind]['data']\n",
    "        spectrodf_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_i, 'Normal force', \n",
    "                                                            unit_dict=unit_dict_cali, properties=properties)\n",
    "        if spectroparam_i['Stiffness']['value'] != 0:\n",
    "            defl_calib = 1/spectroparam_i['Stiffness']['value'] #cantilever deflection calibration in nm/V\n",
    "        else:\n",
    "            defl_calib = 0\n",
    "            print('Normal force slope is zero. Check: ', file_i)\n",
    "        # fig, ax = plt.subplots()\n",
    "        # sns.lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", hue=\"segment\", ax=ax)\n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "        # ax.legend(handles=handles, labels=labels) #remove legend title        \n",
    "        # ax.hlines(spectroparam_i['Adhesion']['zero'], spectrodf_i['x'].min(), \n",
    "        #            spectrodf_i['x'].max(), linestyles='dashed', colors='r')\n",
    "        # ax.plot(spectroparam_i['Stiffness']['x'], spectroparam_i['Stiffness']['y'],\n",
    "        #          'r', linestyle='dashed',linewidth=2)\n",
    "        fig = plotly_lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", color=\"segment\")\n",
    "        plotly_dashedlines(plot_type='hline',fig=fig, y=spectroparam_i['Adhesion']['zero'], line_width=2)\n",
    "        plotly_dashedlines(plot_type='line',fig=fig, x=spectroparam_i['Stiffness']['x'], \n",
    "                           y=spectroparam_i['Stiffness']['y'], line_width=2)\n",
    "        fig.update_layout(showlegend=False)\n",
    "        fig_i = fig2html(fig, plot_type='plotly')\n",
    "        # plt.close()\n",
    "        calib_spectro_dict['normal defl calib [nm/V]'].append(defl_calib)\n",
    "        calib_spectro_dict['plot normf'].append(fig_i)\n",
    "        \n",
    "        #amplitude calibration\n",
    "        if 'True Amplitude' in data_i.keys(): #FIX THIS!\n",
    "            # print('True Amplitude calibrated')\n",
    "            spectro_data_i = data_i['True Amplitude']['curves'][curv_ind]['data']\n",
    "            spectrodf_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_i, 'True Amplitude', \n",
    "                                                                unit_dict=unit_dict_cali, properties=properties)\n",
    "            if spectroparam_i['True Slope-amp']['value'] != 0:\n",
    "                amp_calib = 1/spectroparam_i['True Slope-amp']['value'] #amplitude calibration in nm/V\n",
    "            else:\n",
    "                amp_calib = 0\n",
    "                print('Amp slope is zero. Check: ', file_i)\n",
    "            fig = plotly_lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", color=\"segment\")\n",
    "            plotly_dashedlines(plot_type='line',fig=fig, x=spectroparam_i['True Slope-amp']['x'], \n",
    "                               y=spectroparam_i['True Slope-amp']['y'], line_width=2)\n",
    "        else:\n",
    "            # print('Amplitude calibrated')\n",
    "            spectro_data_i = data_i['Amplitude']['curves'][curv_ind]['data']\n",
    "            spectrodf_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_i, 'Amplitude', \n",
    "                                                                unit_dict=unit_dict_cali, properties=properties)\n",
    "            if spectroparam_i['Slope-amp']['value'] != 0:\n",
    "                amp_calib = 1/spectroparam_i['Slope-amp']['value'] #amplitude calibration in nm/V\n",
    "            else:\n",
    "                amp_calib = 0\n",
    "                print('Amp slope is zero. Check: ', file_i)\n",
    "        # fig, ax = plt.subplots()\n",
    "        # sns.lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", hue=\"segment\", ax=ax)\n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "        # ax.legend(handles=handles, labels=labels) #remove legend title        \n",
    "        # ax.plot(spectroparam_i['Slope-amp']['x'], spectroparam_i['Slope-amp']['y'],\n",
    "        #          'r', linestyle='dashed',linewidth=2)\n",
    "            fig = plotly_lineplot(data=spectrodf_i[spectrodf_i['segment'] == spec_dir], x=\"x\", y=\"y\", color=\"segment\")\n",
    "            plotly_dashedlines(plot_type='line',fig=fig, x=spectroparam_i['Slope-amp']['x'], \n",
    "                               y=spectroparam_i['Slope-amp']['y'], line_width=2)\n",
    "        fig.update_layout(showlegend=False)\n",
    "        fig_i = fig2html(fig, plot_type='plotly')\n",
    "        \n",
    "        # plt.close()\n",
    "        calib_spectro_dict['amplitude calib [nm/V]'].append(amp_calib)\n",
    "        calib_spectro_dict['plot amp'].append(fig_i)\n",
    "        \n",
    "        calib_spectro_dict['file'].append(file_i)\n",
    "        calib_spectro_dict['curve num'].append(curv_ind)\n",
    "        \n",
    "\n",
    "calib_spectro_df = pd.DataFrame(calib_spectro_dict)\n",
    "\n",
    "calib_spectro_summary = pd.DataFrame({'Mean': calib_spectro_df[['normal defl calib [nm/V]', \n",
    "                                                                'amplitude calib [nm/V]']].mean(),\n",
    "                                      'Standard Deviation': calib_spectro_df[['normal defl calib [nm/V]', \n",
    "                                                                              'amplitude calib [nm/V]']].std()\n",
    "                                      })\n",
    "#set calibration dictionary\n",
    "\n",
    "#UNCOMMENT TO MANUALLY SET SPRING CONSTANT VALUE (input in 'factor' and ignore 'offset')\n",
    "# set_calibdict_values(channel = 'Spring constant',\n",
    "#                      unit_kw = {'N/m': {'factor': k_cantilver, 'offset': 0}})\n",
    "\n",
    "#COMMENT IF YOU DONT WANT TO USE AMPLITUDE CALIBRATION FROM SPECTROSCOPY FIT\n",
    "set_calibdict_values(channel = 'Amplitude', \n",
    "                     unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['amplitude calib [nm/V]'], 'offset':0}\n",
    "                               })\n",
    "set_calibdict_values(channel = 'True Amplitude',\n",
    "                     unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['amplitude calib [nm/V]'], 'offset':0}\n",
    "                               })\n",
    "set_calibdict_values(channel = 'Amplitude-sample distance',\n",
    "                     unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['amplitude calib [nm/V]'], 'offset':0}\n",
    "                               })\n",
    "set_calibdict_values(channel = 'Amplitude dissipated',\n",
    "                     unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['amplitude calib [nm/V]'], 'offset':0}\n",
    "                               })\n",
    "\n",
    "# set_calibdict_values(channel = 'Normal force', \n",
    "#                      unit_kw = {'nN': {'factor': calib_spectro_summary['Mean'].loc['normal defl calib [nm/V]'] * \\\n",
    "#                                        get_calibdict_value('Spring constant','N/m')['factor'], \n",
    "#                                        'offset':0}\n",
    "#                                })\n",
    "# set_calibdict_values(channel = 'Normal deflection', \n",
    "#                      unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['normal defl calib [nm/V]'], 'offset':0},\n",
    "#                                })\n",
    "\n",
    "#update pizeo calibration\n",
    "# set_calibdict_values(channel = 'X', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "# set_calibdict_values(channel = 'Y', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "# set_calibdict_values(channel = 'Z', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "# set_calibdict_values(channel = 'Topography', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "\n",
    "# set_calibdict_values(channel = 'Excitation frequency', unit_kw = {'Hz': {'factor': 1, 'offset':0}})\n",
    "# CALIB_DICT['X']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Y']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Z']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Topography']['nm']['factor'] = 1\n",
    "\n",
    "# print(CALIB_DICT)\n",
    "# calib_spectro_summary.loc['Spring constant [N/m]'] = [get_calibdict_value('Spring constant','N/m')['factor'], 0]\n",
    "itables.show(calib_spectro_summary)\n",
    "itables.show(calib_spectro_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c5007-96d9-43c7-9f99-56fc28afeca4",
   "metadata": {},
   "source": [
    "### Cantilever frequency response analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526bf4e-2c14-4c5f-95d9-eaba42a36c2e",
   "metadata": {},
   "source": [
    "#### Circle and lorentzian fitting\n",
    "Find centre of the circle of the X-Y plot (lock-in output) as cordinates xc, yc. xc later used to offset the circle from spectroscopy data by setting it in EXTRA_CHANNEL_DICT parameter \"xc\" using set_extrachan_dict().\n",
    "Obtains Q factor, resonance frequency from Lorentzian fit of True Amplitude curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522a777-3f29-4454-9ddf-fc627e9f3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath_ini3 = filedialog.askopenfilename(title='Choose frequency scan xy file', \n",
    "                                                initialdir=folderpath, filetypes=(('curves',['*.cur']),\n",
    "                                                                                  ))\n",
    "# file_df =  dash0_filedict['full']\n",
    "# # file_keys = []\n",
    "# # for file_path_i in file_paths: #find the list of unique file keyword names\n",
    "# file_name_i = os.path.basename(file_path_i)\n",
    "# file_keys.append(file_df[file_df['name']==file_name_i]['file'].iloc[0])\n",
    "# files = list(dict.fromkeys(file_keys))\n",
    "\n",
    "\n",
    "# files_ini3 = 'tune_xy2'\n",
    "# filepath_ini3 = folderpath + '/' + file_df_spectro.loc[(file_df_spectro.file==files_ini3)].iloc[0].loc['name']\n",
    "# filepath_ini3 = '/home/pranav/Work/Data/Murcia/AFM2/20240527 thiol interdigielec old_ctd/tune_XY1.cur'\n",
    "spectro_data_ini3 = wsxm_readspectra(filepath_ini3, all_files=True, mute=True)\n",
    "color_list = px.colors.qualitative.Light24\n",
    "\n",
    "curv_ind = 1\n",
    "fit_range_circ = (0.45,0.7)\n",
    "fit_range_lorenz = (0.25,0.75)\n",
    "\n",
    "data_x3 = spectro_data_ini3['X-Y components']['curves'][curv_ind]['data']['X-Y components_1']['x']\n",
    "data_amp3 = spectro_data_ini3['X-Y components']['curves'][curv_ind]['data']['X-Y components_1']['y']\n",
    "data_phase3 = spectro_data_ini3['X-Y components']['curves'][curv_ind]['data']['X-Y components_2']['y']\n",
    "data_amptrue3 = np.sqrt(np.square(data_amp3) + np.square(data_phase3))\n",
    "data_phasetrue3 = np.arctan2(data_amp3, data_phase3)*180/np.pi\n",
    "ind_min = np.argmin(data_amp3)\n",
    "\n",
    "def circle(center, radius, theta_range):   \n",
    "    theta = np.linspace(theta_range[0], theta_range[1], 1000)\n",
    "    x = center[0] + radius * np.cos(theta)\n",
    "    y = center[1] + radius * np.sin(theta)\n",
    "    return x, y, theta\n",
    "\n",
    "\n",
    "# Define the function for the circle equation\n",
    "def circle_equation(xy, xc, yc, r):\n",
    "    x, y = xy\n",
    "    return (x - xc)**2 + (y - yc)**2 - r**2\n",
    "\n",
    "# Function to fit a circle to the data using curve_fit\n",
    "def fit_circle(x, y):\n",
    "    # Prepare the data for curve_fit\n",
    "    xy = np.vstack((x, y))\n",
    "\n",
    "    # Initial guess for the parameters [xc, yc, r]\n",
    "    x_m = np.mean(x)\n",
    "    y_m = np.mean(y)\n",
    "    r_initial = np.sqrt((x - x_m)**2 + (y - y_m)**2).mean()\n",
    "    initial_guess = [x_m, y_m, r_initial]\n",
    "\n",
    "    # Perform the curve fitting\n",
    "    params, _ = curve_fit(lambda xy, xc, yc, r: circle_equation(xy, xc, yc, r), xy, np.zeros_like(x), p0=initial_guess)\n",
    "    \n",
    "    # Extract the fitted parameters\n",
    "    xc, yc, r = params\n",
    "    return xc, yc, r\n",
    "    \n",
    "num_pts = len(data_amp3)\n",
    "fit_ind = [int(fit_range_circ[0]*num_pts), int(fit_range_circ[1]*num_pts)]\n",
    "x_points = data_phase3[fit_ind[0]:fit_ind[1]] #np.array([8, 10, 6, 7, 9])\n",
    "y_points = data_amp3[fit_ind[0]:fit_ind[1]] #np.array([4, 12, 9, 11, 7])\n",
    "# Fit the circle to the data\n",
    "xc, yc, rc = fit_circle(x_points, y_points)\n",
    "print(f'xc={xc}, yc={yc}, rc={rc}, r={r}')\n",
    "print(f'Amp res={data_amp3[ind_min]}, Phase res={data_phase3[ind_min]}, Freq res={data_x3[ind_min]}')\n",
    "print(f'Amptrue res={data_amptrue3[ind_min]}, Phasetrue res={data_phasetrue3[ind_min]}')\n",
    "set_extrachan_dict('Frequency shift', 'xc', xc) #update xc in EXTRA_CHAN_DICT\n",
    "\n",
    "\n",
    "\n",
    "fig4, ax4 = plt.subplots(1, 2, figsize=(12,5))\n",
    "ax4[0].axhline(y=0, color='w', linewidth='1', alpha=0.7)\n",
    "ax4[0].plot(data_x3, data_amp3, 'r')\n",
    "ax4[0].plot(data_x3, data_phase3, 'y')\n",
    "# ax4[0].plot(data_x3[ind_min], data_amp3[ind_min], 'ro')\n",
    "# ax4[0].plot(data_x3[ind_min], data_phase3[ind_min], 'yo')\n",
    "ax4[0].axhline(y=data_amp3[ind_min], color='w', linestyle='--', linewidth='1')\n",
    "ax4[0].axhline(y=data_phase3[ind_min], color='w', linestyle='--', linewidth='1')\n",
    "ax4[0].axvline(x=data_x3[ind_min], color='w', linestyle='--', linewidth='1')\n",
    "ax4[0].minorticks_on()\n",
    "ax4[0].grid(True, alpha=0.3, which='both')\n",
    "# plt.show()\n",
    "\n",
    "# files_ini4 = 'tune_amp2'\n",
    "# filepath_ini4 = folderpath + '/' + file_df_spectro.loc[(file_df_spectro.file==files_ini4)].iloc[0].loc['name']\n",
    "# # filepath_ini4 = '/home/pranav/Work/Data/Murcia/AFM2/20240527 thiol interdigielec old_ctd/tune_ampfreq1.cur'\n",
    "# spectro_data_ini4 = wsxm_readspectra(filepath_ini4, all_files=True, mute=True)\n",
    "# data_x4 = spectro_data_ini4['Amplitude']['curves'][curv_ind]['data']['Amplitude_1']['x']\n",
    "# data_amp4 = spectro_data_ini4['Amplitude']['curves'][curv_ind]['data']['Amplitude_1']['y']\n",
    "\n",
    "ax5 = ax4[1].twinx()\n",
    "# ax4[1].plot(data_x4, data_amp4, 'r.')\n",
    "ax4[1].plot(data_x3, data_amptrue3, 'r-')\n",
    "ax5.plot(data_x3, data_phasetrue3, 'y')\n",
    "ax5.axhline(y=data_phasetrue3[ind_min], color='w', linestyle='--', linewidth='1')\n",
    "ax5.axvline(x=data_x3[ind_min], color='w', linestyle='--', linewidth='1')\n",
    "ax4[1].minorticks_on()\n",
    "ax5.minorticks_on()\n",
    "ax4[1].grid(True, alpha=0.3, which='both')\n",
    "# plt.plot(data_x3[ind_min], data_amptrue3[ind_min], 'ro')\n",
    "\n",
    "# y_guess = 0 #psd_final.min()\n",
    "# f_guess = data_x3[ind_min]\n",
    "# w_guess = 2*np.abs(data_x3[(np.abs(data_amptrue3 - data_amptrue3.max()/2)).argmin()]-f_guess)\n",
    "# A_guess = np.pi*w_guess*data_amptrue3.max()/2\n",
    "# guess = [y_guess, f_guess, w_guess, A_guess] #y0,f0,w,A\n",
    "# # fit_range = [0.3, 0.7]\n",
    "num_pts = len(data_amp3)\n",
    "fit_ind = [int(fit_range_lorenz[0]*num_pts), int(fit_range_lorenz[1]*num_pts)]\n",
    "# # print(guess)\n",
    "# #fit square of amplitude to the Lorenztian curve\n",
    "# popt, pcov = curve_fit(ftf.lorentzian, data_x3[fit_ind[0]:fit_ind[1]], data_amptrue3[fit_ind[0]:fit_ind[1]]**2,\n",
    "#                        p0=guess, bounds=(0,np.inf))\n",
    "# #print(np.linalg.cond(pcov))\n",
    "# params = ['offset','resonance freq', 'fwhm', 'area']\n",
    "# fit_dict = dict(zip(params, popt))\n",
    "# fit_dict['Q factor'] = fit_dict['resonance freq']/fit_dict['fwhm']\n",
    "f_guess = data_x3[ind_min]\n",
    "F0_guess = 1 #psd_final.min()\n",
    "m_guess = 2/(2*np.pi*f_guess**2)\n",
    "# print(F0_guess/m_guess, m_guess)\n",
    "gamma_guess = np.abs(data_x3[(np.abs(data_amptrue3 - data_amptrue3.max()/2)).argmin()]-f_guess)\n",
    "# A_guess = np.pi*w_guess*data_amptrue3.max()/2\n",
    "guess = [f_guess, gamma_guess, F0_guess, m_guess]\n",
    "# print(guess)\n",
    "popt, pcov = curve_fit(ftf.harmonic_amplitude, data_x3[fit_ind[0]:fit_ind[1]], data_amptrue3[fit_ind[0]:fit_ind[1]],\n",
    "                       p0=guess, bounds=(0,np.inf))\n",
    "params = ['resonance freq', 'gamma', 'drive osci', 'mass osci']\n",
    "fit_dict = dict(zip(params, popt))\n",
    "fit_dict['Q factor'] = fit_dict['resonance freq']/(2*fit_dict['gamma'])\n",
    "print(fit_dict)\n",
    "#plot fit harmonic function\n",
    "f_min, f_max = data_x3.min(), data_x3.max()\n",
    "f_ext = 0.1*(f_max-f_min)\n",
    "fit_n = 8000\n",
    "freq_fit_range = np.linspace(f_min-f_ext, f_max+f_ext, fit_n)\n",
    "ax4[1].plot(data_x3[fit_ind[0]:fit_ind[1]], data_amptrue3[fit_ind[0]:fit_ind[1]], 'r.')\n",
    "ax4[1].plot(freq_fit_range, ftf.harmonic_amplitude(freq_fit_range, *popt), 'w:')\n",
    "plt.show()\n",
    "\n",
    "plt.axhline(y=0, color='w', linewidth='1', alpha=0.7)\n",
    "plt.axvline(x=0, color='w', linewidth='1', alpha=0.7)\n",
    "plt.plot(data_phase3, data_amp3, '-', color=color_list[0])\n",
    "plt.plot(data_phase3[ind_min], data_amp3[ind_min], 'o', color=color_list[0])\n",
    "\n",
    "r =  abs(min(data_amp3))/2 #np.mean(np.sqrt(data_amp[:pts_free]**2 + data_ph[:pts_free]**2))/2\n",
    "r0 = -r\n",
    "center = (0,r0)\n",
    "circ_x3, circ_y3, circ_theta3 = circle(center=center, radius=r, theta_range=(0, 2*np.pi))\n",
    "# plt.plot(circ_x3, circ_y3, ':', color=color_list[2])\n",
    "# plt.plot(*center, 'o', color=color_list[2])\n",
    "circ_x4, circ_y4, circ_theta4 = circle(center=(xc,yc), radius=rc, theta_range=(0, 2*np.pi))\n",
    "plt.plot(x_points, y_points, '.', color=color_list[0])\n",
    "plt.plot(circ_x4, circ_y4, ':', color=color_list[6])\n",
    "plt.plot(xc, yc, 'o', color=color_list[6])\n",
    "\n",
    "f0, gamma,  F0, m = popt\n",
    "omega0 = 2*np.pi*f0\n",
    "omega = 2*np.pi*freq_fit_range\n",
    "Re_fit = (F0 * (omega0**2 - omega**2)) / (m * ((omega0**2 - omega**2)**2 + (2 * gamma * omega)**2))\n",
    "Im_fit = -F0 * 2 * gamma * omega / (m * ((omega0**2 - omega**2)**2 + (2 * gamma * omega)**2))\n",
    "plt.plot(Re_fit+xc, Im_fit, ':w')\n",
    "# plt.gca().set_aspect('equal')\n",
    "plt.minorticks_on()\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de071011-39da-46bd-bce1-7714dd5d264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f0, w, A = fit_dict['resonance freq'], fit_dict['fwhm'], fit_dict['area']\n",
    "# f = freq_fit_range\n",
    "# print(f, f0, w, A)\n",
    "# Re_fit = (2 * A * (f0**2 - f**2)) / ((f0**2 - f**2)**2 + (w * f)**2)\n",
    "# Im_fit = -(2 * A * w * f) / ((f0**2 - f**2)**2 + (w * f)**2)\n",
    "# plt.plot(Re_fit, Im_fit)\n",
    "# plt.show()\n",
    "# Amp_fit = np.sqrt(Re_fit**2 + Im_fit**2)\n",
    "# plt.plot(f, Amp_fit)\n",
    "# plt.show() f0, gamma, F0, m\n",
    "f_guess = data_x3[ind_min]\n",
    "F0_guess = 1 #psd_final.min()\n",
    "m_guess = 2/(2*np.pi*f_guess**2)\n",
    "print(F0_guess/m_guess, m_guess)\n",
    "gamma_guess = np.abs(data_x3[(np.abs(data_amptrue3 - data_amptrue3.max()/2)).argmin()]-f_guess)\n",
    "A_guess = np.pi*w_guess*data_amptrue3.max()/2\n",
    "guess = [f_guess, gamma_guess, F0_guess, m_guess]\n",
    "print(guess)\n",
    "popt, pcov = curve_fit(ftf.harmonic_amplitude, data_x3[fit_ind[0]:fit_ind[1]], data_amptrue3[fit_ind[0]:fit_ind[1]],\n",
    "                       p0=guess, bounds=(0,np.inf))\n",
    "params = ['resonance freq', 'gamma', 'drive osci', 'mass osci']\n",
    "fit_dict = dict(zip(params, popt))\n",
    "fit_dict['Q factor'] = fit_dict['resonance freq']/(2*fit_dict['gamma'])\n",
    "plt.plot(data_x3[fit_ind[0]:fit_ind[1]], data_amptrue3[fit_ind[0]:fit_ind[1]], 'r.')\n",
    "plt.plot(freq_fit_range, ftf.harmonic_amplitude(freq_fit_range, *popt), 'w:')\n",
    "plt.show()\n",
    "print(fit_dict)\n",
    "\n",
    "f0, gamma,  F0, m = popt\n",
    "omega0 = 2*np.pi*f0\n",
    "omega = 2*np.pi*freq_fit_range\n",
    "Re_fit = (F0 * (omega0**2 - omega**2)) / (m * ((omega0**2 - omega**2)**2 + (2 * gamma * omega)**2))\n",
    "# Calculate imaginary part of X(omega)\n",
    "Im_fit = -F0 * 2 * gamma * omega / (m * ((omega0**2 - omega**2)**2 + (2 * gamma * omega)**2))\n",
    "plt.plot(data_phase3, data_amp3, '.r')\n",
    "plt.plot(Re_fit+xc, Im_fit, ':w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6c137-191b-4bce-a48d-06305e101ed8",
   "metadata": {},
   "source": [
    "#### Compare multiple frequency scan curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945b018-5278-4db1-bd45-8efef65cb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = ['tune_xy1', 'tune_xy2', 'tune_xy3', 'tune_xy4']\n",
    "file_paths = list(filedialog.askopenfilenames(title='Choose frequency scan xy file', \n",
    "                                              initialdir=folderpath, filetypes=(('curves',['*.cur']),\n",
    "                                                                               )))\n",
    "file_df =  dash0_filedict['full']\n",
    "file_keys = []\n",
    "for file_path_i in file_paths: #find the list of unique file keyword names\n",
    "    file_name_i = os.path.basename(file_path_i)\n",
    "    file_keys.append(file_df[file_df['name']==file_name_i]['file'].iloc[0])\n",
    "files = list(dict.fromkeys(file_keys))\n",
    "\n",
    "color_list = px.colors.qualitative.Light24\n",
    "curv_ind = 1\n",
    "fit_range = (0.48,0.7)\n",
    "\n",
    "# Define the function for the circle equation\n",
    "def circle_equation(xy, xc, yc, r):\n",
    "    x, y = xy\n",
    "    return (x - xc)**2 + (y - yc)**2 - r**2\n",
    "\n",
    "def circle(center, radius, theta_range):   \n",
    "    theta = np.linspace(theta_range[0], theta_range[1], 1000)\n",
    "    x = center[0] + radius * np.cos(theta)\n",
    "    y = center[1] + radius * np.sin(theta)\n",
    "    return x, y, theta\n",
    "\n",
    "# Function to fit a circle to the data using curve_fit\n",
    "def fit_circle(x, y):\n",
    "    # Prepare the data for curve_fit\n",
    "    xy = np.vstack((x, y))\n",
    "\n",
    "    # Initial guess for the parameters [xc, yc, r]\n",
    "    x_m = np.mean(x)\n",
    "    y_m = np.mean(y)\n",
    "    r_initial = np.sqrt((x - x_m)**2 + (y - y_m)**2).mean()\n",
    "    initial_guess = [x_m, y_m, r_initial]\n",
    "\n",
    "    # Perform the curve fitting\n",
    "    params, _ = curve_fit(lambda xy, xc, yc, r: circle_equation(xy, xc, yc, r), xy, np.zeros_like(x), p0=initial_guess)\n",
    "    \n",
    "    # Extract the fitted parameters\n",
    "    xc, yc, r = params\n",
    "    return xc, yc, r\n",
    "\n",
    "plt.axhline(y=0, color='w', linewidth='1', alpha=0.7)\n",
    "plt.axvline(x=0, color='w', linewidth='1', alpha=0.7)\n",
    "for i, files_ini_i in enumerate(files):\n",
    "    # filepath_ini_i = folderpath + '/' + file_df_spectro.loc[(file_df_spectro.file==files_ini_i)].iloc[0].loc['name']\n",
    "    filepath_ini_i = folderpath + '/' + file_df.loc[(file_df.file==files_ini_i)].iloc[0].loc['name']\n",
    "    # filepath_ini3 = '/home/pranav/Work/Data/Murcia/AFM2/20240527 thiol interdigielec old_ctd/tune_XY1.cur'\n",
    "    spectro_data_ini_i = wsxm_readspectra(filepath_ini_i, all_files=True, mute=True)\n",
    "    # data_x_i = spectro_data_ini3['X-Y components']['curves'][curv_ind]['data']['X-Y components_1']['x']\n",
    "    data_amp_i = spectro_data_ini_i['X-Y components']['curves'][curv_ind]['data']['X-Y components_1']['y']\n",
    "    data_phase_i = spectro_data_ini_i['X-Y components']['curves'][curv_ind]['data']['X-Y components_2']['y']\n",
    "    drive_amp_i = spectro_data_ini_i['X-Y components']['curves'][curv_ind]['header']['Amplitude [Dynamic settings]']\n",
    "    drive_freq_i = spectro_data_ini_i['X-Y components']['curves'][curv_ind]['header']['Resonance frequency [Dynamic settings]']\n",
    "    plt.plot(data_phase_i, data_amp_i, label=files_ini_i, color=color_list[i])\n",
    "    indres_i = np.argmin(data_amp_i)\n",
    "    plt.plot(data_phase_i[indres_i], data_amp_i[indres_i]/2, '*', color=color_list[i])\n",
    "    num_pts = len(data_amp_i)\n",
    "    fit_ind = [int(fit_range[0]*num_pts), int(fit_range[1]*num_pts)]\n",
    "    x_points = data_phase_i[fit_ind[0]:fit_ind[1]] #np.array([8, 10, 6, 7, 9])\n",
    "    y_points = data_amp_i[fit_ind[0]:fit_ind[1]] #np.array([4, 12, 9, 11, 7])\n",
    "    # Fit the circle to the data\n",
    "    xc, yc, rc = fit_circle(x_points, y_points)\n",
    "    # print(xc, yc, rc, data_amp_i[indres_i]/2, yc+rc, drive_amp_i, data_amp_i[indres_i], drive_freq_i)\n",
    "    circ_x_i, circ_y_i, circ_theta_i = circle(center=(xc,yc), radius=rc, theta_range=(0, 2*np.pi))\n",
    "    plt.plot(circ_x_i, circ_y_i, ':', color=color_list[i])\n",
    "    plt.plot(x_points, y_points, '.', color=color_list[i])\n",
    "    plt.plot(xc, yc, 'o', color=color_list[i])\n",
    "\n",
    "# plt.gca().set_aspect('equal')\n",
    "plt.minorticks_on()\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23c4d0-7331-42c8-adb3-c46c67991707",
   "metadata": {},
   "source": [
    "### Update other calibrations\n",
    "Use this to update piezo or frequency calibration factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4daa6-d692-4f15-86a3-db86fe5c6263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gain_ini = 10 #SET GAIN\n",
    "\n",
    "# unit_dict = {\n",
    "#     'X': 'nm', # 'Å', 'nm', 'µm' \n",
    "#     'Y': 'nm', # 'Å', 'nm', 'µm' \n",
    "#     'Z': 'nm', # 'Å', 'nm', 'µm' \n",
    "#     'Topography': 'nm', # 'Å', 'nm', 'µm' \n",
    "#     'Normal force': 'nN', # 'V', 'nN'\n",
    "#     'Normal deflection': 'nm', # 'V', 'nm'\n",
    "#     'Amplitude': 'V', # 'V', 'nm'\n",
    "#     'True Amplitude': 'nm', # 'V', 'nm'\n",
    "#     'Amplitude dissipated': 'nm',\n",
    "#     'Amplitude-sample distance': 'nm',\n",
    "#     'Excitation frequency': 'Hz', # 'V', 'Hz', 'kHz'\n",
    "#     'Frequency shift': 'Hz',\n",
    "#     'Phase': 'V', # 'V'\n",
    "#     'True Phase': '°', # 'V', '°',             \n",
    "#     'Sample deformation': 'nm',\n",
    "#     'Energy dissipated': 'aJ', #'V2', 'aJ'\n",
    "#     'Spring constant': 'N/m',\n",
    "#     'Resonance frequency': 'Hz',\n",
    "#     'Quality factor': '',\n",
    "#     'X-Y components': 'V',\n",
    "#     '2nd Feedback Out': 'V',\n",
    "#     'Lateral force': 'V',\n",
    "#             }\n",
    "\n",
    "# if unit_dict['Z'] != unit_dict['Normal deflection']:\n",
    "#     print(\"WARNING! Tip-sample distance won't be calculated correctly because Z and Normal deflection units don't match! Please check unit_dict\")\n",
    "\n",
    "\n",
    "#set calibration dictionary\n",
    "# def update_gaincalib(gain_value):\n",
    "#     calib_summary = dashtc_datadict['Summary'].set_index(['parameters', 'gain in']) #for easy access of values\n",
    "#     set_calibdict_values(channel = 'Amplitude', \n",
    "#                          unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}})\n",
    "#     set_calibdict_values(channel = 'True Amplitude',\n",
    "#                          unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}})\n",
    "#     set_calibdict_values(channel = 'Amplitude-sample distance',\n",
    "#                          unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}\n",
    "#                                    })\n",
    "#     set_calibdict_values(channel = 'Amplitude dissipated',\n",
    "#                          unit_kw = {'nm': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean'], 'offset':0}\n",
    "#                                    })\n",
    "#     set_calibdict_values(channel = 'Energy dissipated',\n",
    "#                          unit_kw = {'aJ': {'factor': calib_summary.at[('Amplitude calib', gain_value), 'mean']**2, 'offset':0}\n",
    "#                                    })\n",
    "    \n",
    "#     set_calibdict_values(channel = 'Spring constant',\n",
    "#                          unit_kw = {'N/m': {'factor': calib_summary.at[('Spring constant', gain_value), 'mean'], 'offset':0}})\n",
    "#     set_calibdict_values(channel = 'Resonance frequency',\n",
    "#                          unit_kw = {'Hz': {'factor': calib_summary.at[('Resonance frequency', gain_value), 'mean'], 'offset':0}})\n",
    "#     set_calibdict_values(channel = 'Quality factor',\n",
    "#                          unit_kw = {'': {'factor': calib_summary.at[('Q factor', gain_value), 'mean'], 'offset':0}})\n",
    "\n",
    "# CALIB_DICT['Amplitude']['nm']['factor'] = calib_summary['Mean'].loc['Amplitude calib']\n",
    "# CALIB_DICT['True Amplitude']['nm']['factor'] = calib_summary['Mean'].loc['Amplitude calib']\n",
    "\n",
    "#update pizeo calibration\n",
    "# set_calibdict_values(channel = 'X', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "# set_calibdict_values(channel = 'Y', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "# set_calibdict_values(channel = 'Z', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "# set_calibdict_values(channel = 'Topography', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "\n",
    "# set_calibdict_values(channel = 'Excitation frequency', unit_kw = {'Hz': {'factor': 1, 'offset':0}})\n",
    "# CALIB_DICT['X']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Y']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Z']['nm']['factor'] = 2\n",
    "# CALIB_DICT['Topography']['nm']['factor'] = 2\n",
    "\n",
    "\n",
    "#set calibration dictionary\n",
    "\n",
    "#UNCOMMENT TO MANUALLY SET SPRING CONSTANT VALUE (input in 'factor' and ignore 'offset')\n",
    "# set_calibdict_values(channel = 'Spring constant',\n",
    "#                      unit_kw = {'N/m': {'factor': k_cantilver, 'offset': 0}})\n",
    "\n",
    "#COMMENT IF YOU DONT WANT TO USE AMPLITUDE CALIBRATION FROM SPECTROSCOPY FIT\n",
    "# set_calibdict_values(channel = 'Amplitude', \n",
    "#                      unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['amplitude calib [nm/V]'], 'offset':0}\n",
    "#                                })\n",
    "# set_calibdict_values(channel = 'True Amplitude',\n",
    "#                      unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['amplitude calib [nm/V]'], 'offset':0}\n",
    "#                                })\n",
    "# set_calibdict_values(channel = 'Amplitude-sample distance',\n",
    "#                      unit_kw = {'nm': {'factor': calib_spectro_summary['Mean'].loc['amplitude calib [nm/V]'], 'offset':0}\n",
    "#                                })\n",
    "\n",
    "    # set_calibdict_values(channel = 'Normal force', \n",
    "    #                      unit_kw = {'nN': {'factor': dashsc_datadict['Summary']['Mean'].loc['normal defl calib [nm/V]'] * \\\n",
    "    #                                        get_calibdict_value('Spring constant','N/m')['factor'], \n",
    "    #                                        'offset':0}\n",
    "    #                                })\n",
    "    # set_calibdict_values(channel = 'Normal deflection', \n",
    "    #                      unit_kw = {'nm': {'factor': dashsc_datadict['Summary']['Mean'].loc['normal defl calib [nm/V]'], 'offset':0},\n",
    "    #                                })\n",
    "    \n",
    "#update pizeo calibration\n",
    "set_calibdict_values(channel = 'X', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "set_calibdict_values(channel = 'Y', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "set_calibdict_values(channel = 'Z', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "set_calibdict_values(channel = 'Topography', unit_kw = {'nm': {'factor': 1, 'offset':0}})\n",
    "\n",
    "#update excitation frequency calibration\n",
    "set_calibdict_values(channel = 'Excitation frequency', unit_kw = {'Hz': {'factor': 1, 'offset':0}})\n",
    "\n",
    "\n",
    "# update_gaincalib(gain_value=gain_ini)\n",
    "\n",
    "# CALIB_DICT['X']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Y']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Z']['nm']['factor'] = 1\n",
    "# CALIB_DICT['Topography']['nm']['factor'] = 1\n",
    "\n",
    "# print(CALIB_DICT)\n",
    "# calib_spectro_summary.loc['Spring constant [N/m]'] = [get_calibdict_value('Spring constant','N/m')['factor'], 0]\n",
    "\n",
    "#print all calibration factors\n",
    "print('CALIBRATION VALUES:')\n",
    "print('Gain', gain_ini)\n",
    "for key, val in unit_dict.items():\n",
    "    print(key, get_calibdict_value(key, val)['factor'], val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab777961-c51a-4dd5-a8f0-e9d369bcc0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import scipy.ndimage as ndimage\n",
    "files = ['calibrate_fd_osci0.01V_gain10_0053']\n",
    "file_df =  dash0_filedict['full']\n",
    "filepath_i = folderpath + '/' + file_df.loc[(file_df.file==files[0])].iloc[0].loc['name']\n",
    "    # filename_i = os.path.basename(filepath_i)\n",
    "data_i = wsxm_readspectra(filepath_i, all_files=True, mute=True)\n",
    "force_data = data_i['Normal force']['curves'][1]['data']\n",
    "# amp_data, _ = wsxm_calcspectroparam(spectro_data_i, 'True Amplitude', \n",
    "#                                     unit_dict=unit_dict_cali, properties=properties)\n",
    "segment = 'approach'\n",
    "fit_order=1\n",
    "filter_size = 30\n",
    "percentile_range = (0, 50)\n",
    "\n",
    "idx_min = np.argmin(force_data[segment]['y'])    \n",
    "data_x, data_y = force_data[segment]['x'][idx_min:], force_data[segment]['y'][idx_min:]\n",
    "\n",
    "data_y_grad = np.gradient(data_y, data_x)\n",
    "data_y_gradfilt = ndimage.median_filter(data_y_grad, size=filter_size)#, mode='nearest')\n",
    "median_slope = np.median(data_y_gradfilt)\n",
    "data_y_good = (data_y_gradfilt<=np.percentile(data_y_gradfilt, percentile_range[1])) & (data_y_gradfilt>=np.percentile(data_y_gradfilt, percentile_range[0]))\n",
    "#find largest chunk of consecutive data following above condition\n",
    "ind_good = np.argwhere(data_y_good==True).flatten()\n",
    "ind_chunk = np.argwhere((np.diff(ind_good)-1).astype(bool)==True).flatten()\n",
    "ind_chunk_all = np.insert(ind_chunk+1, 0, 0)\n",
    "ind_chunk_all = np.append(ind_chunk_all, len(ind_good))\n",
    "argmax = np.argmax(np.diff(ind_chunk_all))\n",
    "arg_range = ind_chunk_all[argmax], ind_chunk_all[argmax+1]-1\n",
    "ind_fitrange = slice(ind_good[arg_range[0]], ind_good[arg_range[-1]]+1)\n",
    "\n",
    "# p, res, rank, sing, rcond = np.polyfit(data_x, data_y, fit_order, full=True) #2nd order fit \n",
    "# print(p)\n",
    "if fit_order == 1:\n",
    "    p, res, rank, sing, rcond = np.polyfit(data_x[ind_fitrange], data_y[ind_fitrange], 1, full=True) #linear fit \n",
    "    poly2 = np.poly1d(p)\n",
    "elif fit_order == 2: #fit parabola with positive curvature\n",
    "    poly2d = lambda x, a, b, c: (a*x**2) + (b*x) + c\n",
    "    p, _ = curve_fit(poly2d, data_x[ind_fitrange], data_y[ind_fitrange], bounds=([0, -np.inf, -np.inf], [np.inf, np.inf, np.inf]))    \n",
    "    poly1 = np.poly1d(p)\n",
    "    x0, y0 = data_x[-1], poly1(data_x[-1])\n",
    "    p_tan = [2*p[0]*x0+p[1], y0-(p[1]*x0)-(2*p[0]*x0**2)] #tangent slope equation\n",
    "    poly2 = np.poly1d(p_tan)\n",
    "\n",
    "n_data = len(data_x)\n",
    "fit_x_all = np.linspace(data_x[0], data_x[-1], 100) #CHECK!!\n",
    "fit_y_all = poly2(fit_x_all)\n",
    "fitind_min = np.argmin(abs(fit_y_all-data_y.min()))\n",
    "fitind_max = np.argmin(abs(fit_y_all-data_y.max()))\n",
    "fit_x = fit_x_all[fitind_min:fitind_max]\n",
    "fit_y = fit_y_all[fitind_min:fitind_max]\n",
    "\n",
    "\n",
    "# p2 = [median_slope, data_y[-1]-(median_slope*data_x[-1])]\n",
    "# poly2 = np.poly1d(p2)\n",
    "\n",
    "plt.close()\n",
    "# plt.plot(force_data[segment]['x'], force_data[segment]['y'], 'r')\n",
    "plt.plot(data_x, data_y, 'r')\n",
    "# # plt.plot(data_x, data_y_filt, 'y')\n",
    "plt.plot(data_x[ind_fitrange], data_y[ind_fitrange], 'r.')\n",
    "plt.plot(fit_x, fit_y, 'w:')\n",
    "plt.plot(fit_x_all, poly1(fit_x_all), 'y:')\n",
    "# plt.plot(fit_x_all, poly2(fit_x_all), 'w:')\n",
    "# plt.plot(data_x, data_y_grad)\n",
    "# plt.plot(data_x, data_y_gradfilt)\n",
    "# plt.plot(data_x[ind_fitrange], data_y_gradfilt[ind_fitrange], 'r.')\n",
    "# plt.axhline(y=median_slope)\n",
    "# plt.plot(data_y)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(data_x, data_y_grad)\n",
    "plt.plot(data_x, data_y_gradfilt)\n",
    "plt.plot(data_x[ind_fitrange], data_y_gradfilt[ind_fitrange], 'r.')\n",
    "plt.axhline(y=median_slope)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610f26f-c67e-4ed6-910d-37959f8391e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y_good = (data_y_gradfilt<=np.percentile(data_y_gradfilt, 10)) & (data_y_gradfilt>=np.percentile(data_y_gradfilt, 0))\n",
    "ind_good = np.argwhere(data_y_good==True).flatten()\n",
    "ind_chunk = np.argwhere((np.diff(ind_good)-1).astype(bool)==True).flatten()\n",
    "ind_chunk_all = np.insert(ind_chunk+1, 0, 0)\n",
    "ind_chunk_all = np.append(ind_chunk_all, len(ind_good))\n",
    "argmax = np.argmax(np.diff(ind_chunk_all))\n",
    "arg_range = ind_chunk_all[argmax], ind_chunk_all[argmax+1]-1\n",
    "ind_range = slice(ind_good[arg_range[0]], ind_good[arg_range[-1]]+1)\n",
    "# data_y_good, data_y_good[ind_range], arg_range, ind_range, ind_good\n",
    "# np.percentile(data_y_gradfilt, 1)\n",
    "# print(t3)\n",
    "# data_y_gradfilt[t]\n",
    "# -p_tan[0]\n",
    "# data_y_good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f0d13-b69c-44b4-83dc-506c51ef8687",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FORCE-VOLUME ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09233da-5c27-48ce-9312-a46e1accc55e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92992239-6301-4489-b715-afb255c2543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load WSxM force-volume data file\n",
    "#filepath = 'data/20240202_laser_off_128pts_58lps_0002.f.dy.ch15'\n",
    "#filepath = 'data/interdigThiols_tipSi3nN_b_0026.f.dy.top'\n",
    "# filepath = 'data/interdigThiols_tipSi3nN_b_0026.fb.ch1.gsi' #ff,fb,bb,bf:1st letter=x dir,2nd letter=z dir\n",
    "#filepath = 'data/interdigThiols_tipSi3nN_b_0023_Excitation frequency.f.curves'\n",
    "\n",
    "filekey = 'interdigThiols_tipSi3nN_b_0026' #common part of file name\n",
    "# filekey = 'dynamicFVmode_pllon_thiolsonly_spot1_thiolinterdigielec_0029'\n",
    "# filekey = 'jumpingFVmode_pllon_glassonly_spot2_thiolinterdigielec_0036' #common part of file name\n",
    "# filekey = 'jumpingFVmode_pllon_thiolonly_spot2_thiolinterdigielec_0043'\n",
    "file_df =  dash0_filedict['full']\n",
    "filepath = folderpath + '/' + file_df.loc[(file_df.file==filekey)].iloc[0].loc['name']\n",
    "\n",
    "data_dict = wsxm_readforcevol(filepath, all_files=True, topo_only=False) #complete force volume data with all channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177c86e-564b-48b2-b372-2231e042280f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndimage\n",
    "tx, ty = 40,120\n",
    "change_factor = 3\n",
    "num_pts = 10\n",
    "filter_size = 15\n",
    "amp_data_y = data_dict['Amplitude']['Image Forward with Forward Ramps']['data']['ZZ'][:,ty,tx]\n",
    "amp_data_x = data_dict['Amplitude']['Image Forward with Forward Ramps']['data']['Z']\n",
    "n_data = len(amp_data_x)\n",
    "amp_data_y_filt = ndimage.median_filter(amp_data_y, size=filter_size) #filter\n",
    "amp_extrema = [np.mean(amp_data_y_filt[:num_pts]), np.mean(amp_data_y_filt[-num_pts:])]\n",
    "amp_min, amp_max = min(amp_extrema), max(amp_extrema)\n",
    "if amp_min == amp_extrema[0]:\n",
    "    ind_min = 0\n",
    "    ind_max = n_data\n",
    "else:\n",
    "    ind_min = n_data\n",
    "    ind_max = 0\n",
    "amp_dev = np.std(amp_data_y[:num_pts])\n",
    "amp_change = amp_max-amp_min\n",
    "ind_mid = np.argmin(abs(amp_data_y_filt-((amp_max+amp_min)/2)))\n",
    "amp_min_target = amp_min+(amp_dev*change_factor)\n",
    "amp_max_target = amp_max-(amp_dev*change_factor)\n",
    "if ind_mid > ind_min:\n",
    "    ind1 = ind_mid - np.argwhere(amp_data_y[ind_mid::-1]<amp_min_target)[0][0] \n",
    "    ind2 = ind_mid + np.argwhere(amp_data_y[ind_mid:]>amp_max_target)[0][0] \n",
    "else:\n",
    "    ind1 = ind_mid - np.argwhere(amp_data_y[ind_mid::-1]>amp_max_target)[0][0] \n",
    "    ind2 = ind_mid + np.argwhere(amp_data_y[ind_mid:]<amp_min_target)[0][0]\n",
    "ind_list = [ind1, ind2]\n",
    "ind_list.sort()\n",
    "print(ind_list, amp_extrema, amp_dev, ind_mid)\n",
    "# p, res, rank, sing, rcond = np.polyfit(amp_data_x[ind_list[0]:ind_list[1]], amp_data_y[ind_list[0]:ind_list[1]], 1, full=True)\n",
    "# slope = p[0]\n",
    "# poly = np.poly1d(p)\n",
    "\n",
    "# test_r = np.flip(data_dict['Amplitude']['Image Forward with Backward Ramps']['data']['ZZ'][:,ty,tx])\n",
    "# test_xr = np.flip(data_dict['Amplitude']['Image Forward with Backward Ramps']['data']['Z'])\n",
    "# t = np.array([3,2,3,1,5,1,6,4,2,6,1,2,3,7,7])\n",
    "# t_ind = np.argwhere(t<2)[0][0]\n",
    "# t[-1:t_ind:-1], t[:t_ind]\n",
    "plt.plot(amp_data_x, amp_data_y, 'r')\n",
    "plt.plot(amp_data_x, amp_data_y_filt, 'y:')\n",
    "plt.plot(amp_data_x[ind_mid], amp_data_y[ind_mid], 'yo')\n",
    "plt.plot(amp_data_x[ind_list[0]], amp_data_y[ind_list[0]], 'bo')\n",
    "plt.plot(amp_data_x[ind_list[1]], amp_data_y[ind_list[1]], 'go')\n",
    "plt.plot(amp_data_x[ind_list[0]:ind_list[1]+1], amp_data_y[ind_list[0]:ind_list[1]+1], 'b')\n",
    "# plt.plot(test_a, 'r')\n",
    "# plt.plot(test_r, 'b')\n",
    "plt.show()\n",
    "amp_data_x[ind_list[0]:ind_list[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ca35c-cde4-45f3-85ad-258a2ccce181",
   "metadata": {},
   "source": [
    "### Calculate properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e86b4a-4109-463d-9eb9-fdd46829fdc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties = ['Adhesion', 'Snap-in distance', 'Slope-amp'] #'Growth rate', 'Stiffness'\n",
    "# set_funcdict_kwargs(channel='Amplitude',param='Slope-amp',kwargs={'method':'fit'})\n",
    "set_funcdict_kwargs(channel='Amplitude',param='Slope-amp',kwargs={'method':'minmax', 'num_pts':10, \n",
    "                                                                  'change_factor':20, 'filter_size':15})\n",
    "set_funcdict_kwargs(channel='Normal deflection',param='Snap-in distance',kwargs={'method':'gradient', 'findmax': False, \n",
    "                                                                                 'zero': 'median', 'back_pts': 50})\n",
    "param_data_dict = calc_spectro_prop(data_dict, properties=properties)\n",
    "# param_list = list(param_data_dict.keys()) #all calculated parameter images eg. adhesion\n",
    "# param_list.insert(0,'Topography')\n",
    "param_list = ['Topography'] + properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3109a14-8def-47a9-b3e5-95ef6e95ca7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize dashboard variables\n",
    "Run this everytime channel unit calibration was changed in AFM CALIBRATION section. \n",
    "Here, maximum and minimum values of each channel are precalculated for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47e392-2903-4d9f-9e29-d18d17292eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prepare and initialize data for dashboards\n",
    "\n",
    "# spectro_x = 'd' #'x', 'd' Piezo position or tip sample distance for spectroscopy x axis plots\n",
    "\n",
    "chan_list = list(data_dict.keys())\n",
    "img_dir_list = ['Forward', 'Backward']\n",
    "chan_list.remove('Topography') #only include 3d data in channel list\n",
    "chan_list.sort()\n",
    "channel = chan_list[0] #'Excitation frequency', 'Normal force', 'Amplitude', 'Topography'\n",
    "img_dir = img_dir_list[0] #'Forward' # 'Forward', 'Backward'\n",
    "\n",
    "header_dict = data_dict[channel][f'Image {img_dir} with Forward Ramps']['header']\n",
    "x_num = int(header_dict['Number of rows [General Info]'])\n",
    "y_num = int(header_dict['Number of columns [General Info]'])\n",
    "z_num = int(header_dict['Number of points per ramp [General Info]'])\n",
    "\n",
    "\n",
    "img_data_ini = get_imgdata(data_dict[channel][f'Image {img_dir} with Forward Ramps'], channel, #x=x_ind, y=y_ind, z=z_ind, unit_chan=unit_dict[channel], \n",
    "                           unit_dict=unit_dict)\n",
    "x_data = img_data_ini['X'] #data_dict[channel][f'Image {img_dir} with Forward Ramps']['data']['X']\n",
    "y_data = img_data_ini['Y'] #data_dict[channel][f'Image {img_dir} with Forward Ramps']['data']['Y']\n",
    "z_data = img_data_ini['Z'] #data_dict[channel][f'Image {img_dir} with Forward Ramps']['data']['Z']\n",
    "\n",
    "#mins and maxs of x,y,z arrays\n",
    "xmin, xmax = x_data.min(), x_data.max()\n",
    "ymin, ymax = y_data.min(), y_data.max()\n",
    "zmin, zmax = z_data.min(), z_data.max()\n",
    "# #spectroscopy\n",
    "# spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir)\n",
    "# df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel)\n",
    "\n",
    "#calculate global channel mins and maxs\n",
    "chan_mins, chan_maxs = {}, {}\n",
    "for chan_i in data_dict.keys():\n",
    "    min_temp, max_temp = [], []\n",
    "    for dir_i in data_dict[chan_i].keys():\n",
    "        z_lab_i = 'Z' if chan_i == 'Topography' else 'ZZ'\n",
    "        # min_temp.append(data_dict[chan_i][dir_i]['data'][z_lab_i].min())\n",
    "        # max_temp.append(data_dict[chan_i][dir_i]['data'][z_lab_i].max())\n",
    "        img_data_i = get_imgdata(data_dict[chan_i][dir_i], chan_i, #x=x_ind, y=y_ind, z=z_ind, \n",
    "                                 unit_dict=unit_dict)#, unit_xyz='nm')\n",
    "        min_temp.append(img_data_i[z_lab_i].min())\n",
    "        max_temp.append(img_data_i[z_lab_i].max())\n",
    "    chan_mins[chan_i] = min(min_temp)\n",
    "    chan_maxs[chan_i] = max(max_temp)\n",
    "\n",
    "for param_i in param_data_dict.keys():\n",
    "    min_temp, max_temp = [], []\n",
    "    for dir_i in param_data_dict[param_i].keys():\n",
    "        # z_lab_i = 'Z' if chan_i == 'Topography' else 'ZZ'\n",
    "        img_data_i = get_imgdata(param_data_dict[param_i][dir_i], param_i, #x=x_ind, y=y_ind, z=z_ind, \n",
    "                                 unit_dict=unit_dict)#, unit_xyz='nm')\n",
    "        min_temp.append(img_data_i['Z'].min())\n",
    "        max_temp.append(img_data_i['Z'].max())\n",
    "    chan_mins[param_i] = min(min_temp)\n",
    "    chan_maxs[param_i] = max(max_temp)\n",
    "\n",
    "#create folder to save all related force volume data\n",
    "outputpath_forcevol = outputpath + '/Force volume/' + filekey\n",
    "os.makedirs(outputpath_forcevol, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578d487-cb26-48c3-9403-364aaa757eef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe7e96-d62d-45a1-82dc-15c7c7cfd370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flatten_chan = ['Topography'] #list of channels to apply flatten\n",
    "\n",
    "# dash1_fig = go.FigureWidget()\n",
    "specs = [[{} for _ in range(3)] for _ in range(3)]\n",
    "specs[1][0] = {\"secondary_y\": True}\n",
    "specs[2][0] = {\"secondary_y\": True}\n",
    "font_dict=dict(family='Arial',size=16)#,color='white')\n",
    "color_list = px.colors.qualitative.Plotly\n",
    "dash1_fig = plotly_subplots_init(rows=3, cols=3, specs=specs,font_dict=font_dict,\n",
    "                     #shared_xaxes=True, shared_yaxes=True,\n",
    "                     vertical_spacing=0.09, horizontal_spacing=0.07,width=1150, height=1000,\n",
    "                                margin=dict(t=50, b=0, l=0, r=0), column_titles=['','approach', 'retract'])  \n",
    "\n",
    "# dash1_fig.update_layout(#legend=dict(orientation=\"h\",yanchor=\"top\",y=-0.1,xanchor=\"center\",x=0.5, font_size=18),\n",
    "              # font=font_dict,  # font formatting\n",
    "              # plot_bgcolor='black',  # background color\n",
    "    # template='plotly_dark',\n",
    "              # barmode='overlay', #showlegend=False, \n",
    "              # width=1150, height=1000,\n",
    "              # title='', #template='plotly_white',  #\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"\n",
    "              # margin=dict(t=50, b=0, l=0, r=0))\n",
    "#share x,y axis between relevant 2D plots\n",
    "dash1_fig.update_layout({\"xaxis3\": {\"matches\": 'x2'},\n",
    "                         \"xaxis5\": {\"matches\": 'x2'},\n",
    "                         \"xaxis6\": {\"matches\": 'x2'},\n",
    "                         \"xaxis8\": {\"matches\": 'x'},\n",
    "                         \"xaxis9\": {\"matches\": 'x'},\n",
    "                         \"yaxis3\": {\"matches\": 'y2'},\n",
    "                         \"yaxis6\": {\"matches\": 'y2'},\n",
    "                         \"yaxis7\": {\"matches\": 'y2'},\n",
    "                        })\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # x and y-axis formatting\n",
    "        dash1_fig.update_yaxes(#showline=True if i==0 and j==1 else False,  # add line at x=0\n",
    "                               #showgrid=False,\n",
    "                               zeroline=True if i==1 and j==0 else False,\n",
    "                               # linecolor='white',  # line color\n",
    "                               #linewidth=2.4, # line size\n",
    "                               tickformat=\"~s\" if j>0  or (i==0 and j==0) else None, #ticklabel number format\n",
    "                               # tickcolor='white',\n",
    "                               showticklabels=False if j==1 else True,\n",
    "                               ticksuffix = \"    \" if j==2 else \"\",\n",
    "                               #ticks='outside',  # ticks outside axis\n",
    "                               mirror='ticks' if j>0  or (i==0 and j==0) else True,\n",
    "                               row=i+1, col=j+1)\n",
    "        dash1_fig.update_xaxes(#showline=True if i==0 and j==1 else False,#showline=True,\n",
    "                               #showgrid=False,\n",
    "                               zeroline=True if i==1 and j==0 else False,\n",
    "                               #linecolor='white',\n",
    "                               #linewidth=2.4,\n",
    "                               tickformat=\"~s\", #ticklabel number format\n",
    "                               #tickcolor='white',\n",
    "                               #ticks='outside',\n",
    "                               mirror='ticks' if j>0  or (i==0 and j==0) else True,\n",
    "                               row=i+1, col=j+1)\n",
    "dash1_fig.update_layout(yaxis4_tickfont_color=color_list[0])\n",
    "dash1_fig.update_layout(yaxis5_tickfont_color=color_list[1])\n",
    "dash1_fig.update_layout(yaxis8_tickfont_color=color_list[0])\n",
    "dash1_fig.update_layout(yaxis9_tickfont_color=color_list[1])\n",
    "#update border colors corresponding to x/y lines to help identify plot\n",
    "dash1_fig.update_xaxes(linecolor='blue', tickcolor='blue', row=1, col=2)\n",
    "dash1_fig.update_yaxes(linecolor='blue', tickcolor='blue', row=1, col=2)\n",
    "dash1_fig.update_xaxes(linecolor='blue', tickcolor='blue', row=1, col=3)\n",
    "dash1_fig.update_yaxes(linecolor='blue', tickcolor='blue', row=1, col=3)\n",
    "dash1_fig.update_xaxes(linecolor='red', tickcolor='red', row=2, col=2)\n",
    "dash1_fig.update_yaxes(linecolor='red', tickcolor='red', row=2, col=2)\n",
    "dash1_fig.update_xaxes(linecolor='red', tickcolor='red', row=2, col=3)\n",
    "dash1_fig.update_yaxes(linecolor='red', tickcolor='red', row=2, col=3)\n",
    "dash1_fig.update_xaxes(linecolor='green', tickcolor='green', row=3, col=2)\n",
    "dash1_fig.update_yaxes(linecolor='green', tickcolor='green', row=3, col=2)\n",
    "dash1_fig.update_xaxes(linecolor='green', tickcolor='green', row=3, col=3)\n",
    "dash1_fig.update_yaxes(linecolor='green', tickcolor='green', row=3, col=3)\n",
    "\n",
    "x_ind = np.argmin(abs(x_data-(xmin+xmax)/2))\n",
    "y_ind = np.argmin(abs(y_data-(ymin+ymax)/2))\n",
    "z_ind = 0\n",
    "x_pt_ini = x_data[x_ind]\n",
    "y_pt_ini = y_data[y_ind]\n",
    "# x_ind, y_ind, z_ind = 0, 0, 0\n",
    "img_data = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                       unit_dict=unit_dict)\n",
    "if 'Topography' in flatten_chan: #flatten channel\n",
    "        img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "# img_data = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "dash1_heatmap_top = plotly_heatmap(x=img_data['X'],\n",
    "                             y=img_data['Y'],\n",
    "                             z_mat=img_data['Z'], style='full', font_dict=font_dict)\n",
    "dash1_heatmap_top.data[0].coloraxis = 'coloraxis2'\n",
    "\n",
    "# img_data_a = data_dict[channel][f'Image {img_dir} with Forward Ramps']\n",
    "img_data_a = get_imgdata(data_dict[channel][f'Image {img_dir} with Forward Ramps'], channel, \n",
    "                         x=x_ind, y=y_ind, z=z_ind, unit_dict=unit_dict)\n",
    "# img_data_r = data_dict[channel][f'Image {img_dir} with Backward Ramps']\n",
    "img_data_r = get_imgdata(data_dict[channel][f'Image {img_dir} with Backward Ramps'], channel, \n",
    "                         x=x_ind, y=y_ind, z=z_ind, unit_dict=unit_dict)\n",
    "\n",
    "#XZ section images\n",
    "dash1_heatmap_xz_a = plotly_heatmap(x=img_data_a['X'],\n",
    "                             y=img_data_a['Z'],\n",
    "                             z_mat=img_data_a['XZ'], style='full', font_dict=font_dict) #approach\n",
    "dash1_heatmap_xz_a.data[0].coloraxis = 'coloraxis1'\n",
    "dash1_heatmap_xz_r = plotly_heatmap(x=img_data_r['X'],\n",
    "                             y=img_data_r['Z'],\n",
    "                             z_mat=img_data_r['XZ'], style='full', font_dict=font_dict) #retract\n",
    "dash1_heatmap_xz_r.data[0].coloraxis = 'coloraxis1'\n",
    "#YZ section images\n",
    "dash1_heatmap_yz_a = plotly_heatmap(x=img_data_a['Y'],\n",
    "                             y=img_data_a['Z'],\n",
    "                             z_mat=img_data_a['YZ'], style='full', font_dict=font_dict) #approach\n",
    "dash1_heatmap_yz_a.data[0].coloraxis = 'coloraxis1'\n",
    "dash1_heatmap_yz_r = plotly_heatmap(x=img_data_r['Y'],\n",
    "                             y=img_data_r['Z'],\n",
    "                             z_mat=img_data_r['YZ'], style='full', font_dict=font_dict) #retract\n",
    "dash1_heatmap_yz_r.data[0].coloraxis = 'coloraxis1'\n",
    "#XY section images\n",
    "dash1_heatmap_xy_a = plotly_heatmap(x=img_data_a['X'],\n",
    "                             y=img_data_a['Y'],\n",
    "                             z_mat=img_data_a['XY'], style='full', font_dict=font_dict) #approach\n",
    "dash1_heatmap_xy_a.data[0].coloraxis = 'coloraxis1'\n",
    "dash1_heatmap_xy_r = plotly_heatmap(x=img_data_r['X'],\n",
    "                             y=img_data_r['Y'],\n",
    "                             z_mat=img_data_r['XY'], style='full', font_dict=font_dict) #retract\n",
    "dash1_heatmap_xy_r.data[0].coloraxis = 'coloraxis1'\n",
    "\n",
    "\n",
    "#spectroscopy\n",
    "# defl_data = wsxm_getspectro(data_dict, 'Normal deflection', img_dir, x=x_pt_ini, y=y_pt_ini, unit_dict=unit_dict)\n",
    "spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt_ini, y=y_pt_ini, \n",
    "                               unit_dict=unit_dict, calc_d=True)\n",
    "df_spectro, _ = wsxm_calcspectroparam(spectro_data, channel, unit_dict=None, calc_params=False)\n",
    "line_spec = plotly_lineplot(data=df_spectro,  x=\"x\", y=\"y\", color=\"segment\", font_dict=font_dict)\n",
    "\n",
    "xx_v, yy_v = get_imgline(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'],\n",
    "                         'Topography', x=x_pt_ini, unit_dict=unit_dict)\n",
    "if 'Topography' in flatten_chan: #flatten channel\n",
    "        yy_v = tsf.flatten_line({'X':xx_v, 'Z':yy_v}, order=1)\n",
    "# line_top_x = ax[2][0].plot(xx,yy,color=color_list[0]) #vertical\n",
    "# ax_top_y = ax[2][0].twinx()\n",
    "xx_h, yy_h = get_imgline(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'],\n",
    "                         'Topography', y=y_pt_ini, unit_dict=unit_dict)\n",
    "if 'Topography' in flatten_chan: #flatten channel\n",
    "        yy_h = tsf.flatten_line({'X':xx_h, 'Z':yy_h}, order=1)\n",
    "\n",
    "df_topoline = pd.DataFrame({'x':np.append(xx_v, xx_h), 'y':np.append(yy_v, yy_h), \n",
    "                          'line': ['v']*len(xx_v)+['h']*len(xx_h)})\n",
    "line_topo = plotly_lineplot(data=df_topoline,  x=\"x\", y=\"y\", color=\"line\", font_dict=font_dict)\n",
    "\n",
    "#add data to subplots        \n",
    "dash1_fig.add_trace(dash1_heatmap_top.data[0], row=1, col=1) #data[0]\n",
    "dash1_fig.add_trace(dash1_heatmap_yz_a.data[0], row=1, col=2) #data[1]\n",
    "dash1_fig.add_trace(dash1_heatmap_yz_r.data[0], row=1, col=3) #data[2]\n",
    "dash1_fig.add_trace(dash1_heatmap_xz_a.data[0], row=2, col=2) #data[3]\n",
    "dash1_fig.add_trace(dash1_heatmap_xz_r.data[0], row=2, col=3) #data[4]\n",
    "dash1_fig.add_trace(dash1_heatmap_xy_a.data[0], row=3, col=2) #data[5]\n",
    "dash1_fig.add_trace(dash1_heatmap_xy_r.data[0], row=3, col=3) #data[6]\n",
    "dash1_fig.add_trace(line_spec.data[0], row=2, col=1) #data[7]\n",
    "dash1_fig.add_trace(line_spec.data[1], row=2, col=1, secondary_y=True) #data[8]\n",
    "dash1_fig.add_trace(line_topo.data[0], row=3, col=1) #data[9]\n",
    "dash1_fig.add_trace(line_topo.data[1], row=3, col=1, secondary_y=True) #data[10]\n",
    "\n",
    "dash1_fig.add_hline(y=y_pt_ini, line_color=\"red\", line_width=2,\n",
    "                    visible=True, row=1,col=1)\n",
    "dash1_fig.add_vline(x=x_pt_ini, line_color=\"blue\", line_width=2,\n",
    "                    visible=True, row=1,col=1)\n",
    "\n",
    "#further plot formatting/labelling\n",
    "dash1_fig.update_layout(yaxis4_title=f\"{channel} [{unit_dict[channel]}]\", \n",
    "                        yaxis4_title_font=font_dict,\n",
    "                        xaxis4_title = f\"{SPECT_DICT['x']} [{unit_dict['Z']}]\",\n",
    "                        xaxis4_title_font=font_dict,  \n",
    "                        xaxis4_title_standoff=2 #adjust gap between axis label axis line\n",
    "                       )\n",
    "dash1_fig.update_layout(yaxis8_title=f\"Topography [{unit_dict['Topography']}]\", \n",
    "                        yaxis8_title_font=font_dict)\n",
    "\n",
    "dash1_fig.update_layout({'legend1': dict(y=dash1_fig.layout.yaxis4.domain[1], x=dash1_fig.layout.xaxis4.domain[0],\n",
    "                                         bgcolor='rgba(0,0,0,0)', tracegroupgap=0,\n",
    "                                         xanchor=\"left\", yanchor=\"bottom\", orientation='h')}, showlegend=True)\n",
    "dash1_fig.update_traces(row=2, col=1, legend='legend1')\n",
    "dash1_fig.update_layout({'legend2': dict(y=dash1_fig.layout.yaxis8.domain[1], x=dash1_fig.layout.xaxis7.domain[0],\n",
    "                                         bgcolor='rgba(0,0,0,0)', tracegroupgap=0,\n",
    "                                     xanchor=\"left\", yanchor=\"bottom\", orientation='h')}, showlegend=True)\n",
    "dash1_fig.update_traces(row=3, col=1, legend='legend2')\n",
    "\n",
    "\n",
    "dash1_fig.update_layout(coloraxis1=dict(colorscale=cm_afmhot,#cmin=68500, cmax=69600,\n",
    "                                 colorbar=dict(len=0.6, x=1, y=0.5, thickness=15,\n",
    "                                               orientation='v', xanchor='center', \n",
    "                                               yanchor='middle')),\n",
    "                       coloraxis2=dict(colorscale=cm_afmhot,#cmin=-50, cmax=200,\n",
    "                                 colorbar=dict(len=0.26, x=0.14, y=1, thickness=10,\n",
    "                                              orientation='h',yanchor='bottom',\n",
    "                                               xanchor='center',thicknessmode=\"pixels\"#,tickformat=\"~s\" \n",
    "                                              )))\n",
    "\n",
    "# dash1_fig.layout.coloraxis2.cmin = 50\n",
    "# dash1_fig.layout.coloraxis2.cmax = 100\n",
    "\n",
    "#widgets\n",
    "dash1_slide_x = widgets.FloatSlider(value=x_pt_ini, min=xmin, max=xmax, step=(xmax-xmin)/x_num,\n",
    "                                    description='x', style={'handle_color':'blue'})\n",
    "dash1_slide_y = widgets.FloatSlider(value=y_pt_ini, min=ymin, max=ymax, step=(ymax-ymin)/y_num,\n",
    "                                    description='y', style={'handle_color':'red'})\n",
    "dash1_slide_z = widgets.FloatSlider(value=zmin, min=zmin, max=zmax, step=(zmax-zmin)/z_num,\n",
    "                                    description='z', style={'handle_color':'green'})\n",
    "dash1_slide_zrange = widgets.FloatSlider(value=zmax, min=zmin, max=zmax, step=(zmax-zmin)/z_num,\n",
    "                            description='z limit')\n",
    "dash1_slide_cb = widgets.FloatRangeSlider(value=[chan_mins[channel], chan_maxs[channel]], \n",
    "                                    min=chan_mins[channel], max=chan_maxs[channel], \n",
    "                                    step=(chan_maxs[channel]-chan_mins[channel])/100,\n",
    "                                    description='color',readout=True)\n",
    "dash1_chan_button = widgets.ToggleButtons(options=chan_list,\n",
    "                                          layout=widgets.Layout(width='200px'))\n",
    "dash1_imgdir_button = widgets.ToggleButtons(options=['Forward', 'Backward'], style={\"button_width\": \"75px\"})\n",
    "                                            # layout=widgets.Layout(width='200px'))\n",
    "dash1_param_dropdown = widgets.Dropdown(options=param_list,\n",
    "                                  value='Topography',disabled=False,\n",
    "                                       layout=widgets.Layout(width='200px'))\n",
    "dash1_spectrox_button = widgets.ToggleButtons(options=['x', 'd'], style={\"button_width\": \"20px\"})\n",
    "\n",
    "dash1_output = widgets.Output()\n",
    "dash1_figout = widgets.Output()\n",
    "dash1_box2 = widgets.VBox([dash1_slide_x, dash1_slide_y, dash1_slide_z])\n",
    "dash1_box1 = widgets.VBox([dash1_param_dropdown, dash1_imgdir_button, dash1_spectrox_button])\n",
    "dash1_box3 = widgets.VBox([dash1_slide_zrange, dash1_slide_cb])\n",
    "dash1_box4 = widgets.HBox([dash1_box1, dash1_chan_button, dash1_box2, dash1_box3])\n",
    "\n",
    "#update functions\n",
    "\n",
    "@dash1_output.capture()\n",
    "def dash1_update_x(change):\n",
    "    \n",
    "    x_pt = dash1_slide_x.value\n",
    "    y_pt = dash1_slide_y.value\n",
    "    img_dir = dash1_imgdir_button.value\n",
    "    channel = dash1_chan_button.value\n",
    "    channel_top = dash1_param_dropdown.value\n",
    "    spectro_x = dash1_spectrox_button.value\n",
    "    # vmin, vmax = dash1_slide_cb.value\n",
    "    \n",
    "    #update position lines\n",
    "    dash1_fig.layout.shapes = [{\n",
    "                         'line': {'color': 'red', 'width': 2},\n",
    "                         'type': 'line',\n",
    "                         'visible': True,\n",
    "                         'x0': 0,\n",
    "                         'x1': 1,\n",
    "                         'xref': 'x domain',\n",
    "                         'y0': y_pt,\n",
    "                         'y1': y_pt,\n",
    "                         'yref': 'y'\n",
    "                     },\n",
    "                     {\n",
    "                         'line': {'color': 'blue', 'width': 2},\n",
    "                         'type': 'line',\n",
    "                         'visible': True,\n",
    "                         'x0': x_pt,\n",
    "                         'x1': x_pt,\n",
    "                         'xref': 'x',\n",
    "                         'y0': 0,\n",
    "                         'y1': 1,\n",
    "                         'yref': 'y domain'\n",
    "                     }]\n",
    "    \n",
    "    img_data_a = get_imgdata(data_dict[channel][f'Image {img_dir} with Forward Ramps'], channel, \n",
    "                             x=x_pt, unit_dict=unit_dict)\n",
    "    img_data_r = get_imgdata(data_dict[channel][f'Image {img_dir} with Backward Ramps'], channel, \n",
    "                             x=x_pt, unit_dict=unit_dict)\n",
    "\n",
    "    # img_data_a = data_dict[channel][f'Image {img_dir} with Forward Ramps']\n",
    "    # img_data_r = data_dict[channel][f'Image {img_dir} with Backward Ramps']\n",
    "    \n",
    "    # x_ind_a = np.argmin(abs(img_data_a['data']['X']-x_pt))\n",
    "    # x_ind_r = np.argmin(abs(img_data_r['data']['X']-x_pt))\n",
    "    \n",
    "    dash1_fig.data[1].z = img_data_a['YZ']#[:,:,x_ind_a]\n",
    "    dash1_fig.data[2].z = img_data_r['YZ']#[:,:,x_ind_r]\n",
    "    # defl_data = wsxm_getspectro(data_dict, 'Normal deflection', img_dir=img_dir, x= x_pt, y=y_pt, unit_dict=unit_dict)\n",
    "    spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x= x_pt, y=y_pt, \n",
    "                                   unit_dict=unit_dict, calc_d=True)\n",
    "    # df_spectro, _ = wsxm_calcspectroparam(spectro_data, channel, unit_dict=unit_dict, calc_params=False)\n",
    "    for fig_data in [dash1_fig.data[7], dash1_fig.data[8]]:\n",
    "        fig_data.x = spectro_data[fig_data.name][spectro_x] \n",
    "        fig_data.y = spectro_data[fig_data.name]['y']\n",
    "        # fig_data.x = df_spectro[df_spectro['segment']==fig_data.name]['x']\n",
    "        # fig_data.y = df_spectro[df_spectro['segment']==fig_data.name]['y']\n",
    "\n",
    "    if channel_top == 'Topography':\n",
    "        xx_v, yy_v = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], \n",
    "                                 'Topography', x=y_pt, unit_dict=unit_dict)\n",
    "    else:\n",
    "        # for key, val in FUNC_DICT.items():\n",
    "        #     if channel_top in val.keys():\n",
    "        #         channel_unit = key\n",
    "        #         break\n",
    "        xx_v, yy_v = get_imgline(param_data_dict[channel_top][img_dir], channel_top, \n",
    "                                 x=x_pt, unit_dict=unit_dict)\n",
    "    \n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        yy_v = tsf.flatten_line({'X':xx_v, 'Z':yy_v}, order=1)\n",
    "    \n",
    "    for fig_data in [dash1_fig.data[9], dash1_fig.data[10]]:\n",
    "        if fig_data.name == 'v':\n",
    "            fig_data.x = xx_v\n",
    "            fig_data.y = yy_v\n",
    "            # break\n",
    "\n",
    "\n",
    "@dash1_output.capture()\n",
    "def dash1_update_y(change):\n",
    "    x_pt = dash1_slide_x.value\n",
    "    y_pt = dash1_slide_y.value\n",
    "    img_dir = dash1_imgdir_button.value\n",
    "    channel = dash1_chan_button.value\n",
    "    channel_top = dash1_param_dropdown.value\n",
    "    spectro_x = dash1_spectrox_button.value\n",
    "    # vmin, vmax = dash1_slide_cb.value\n",
    "    \n",
    "    #update position lines\n",
    "    dash1_fig.layout.shapes = [{\n",
    "                         'line': {'color': 'red', 'width': 2},\n",
    "                         'type': 'line',\n",
    "                         'visible': True,\n",
    "                         'x0': 0,\n",
    "                         'x1': 1,\n",
    "                         'xref': 'x domain',\n",
    "                         'y0': y_pt,\n",
    "                         'y1': y_pt,\n",
    "                         'yref': 'y'\n",
    "                     },\n",
    "                     {\n",
    "                         'line': {'color': 'blue', 'width': 2},\n",
    "                         'type': 'line',\n",
    "                         'visible': True,\n",
    "                         'x0': x_pt,\n",
    "                         'x1': x_pt,\n",
    "                         'xref': 'x',\n",
    "                         'y0': 0,\n",
    "                         'y1': 1,\n",
    "                         'yref': 'y domain'\n",
    "                     }]\n",
    "    \n",
    "    # img_data_a = data_dict[channel][f'Image {img_dir} with Forward Ramps']\n",
    "    # img_data_r = data_dict[channel][f'Image {img_dir} with Backward Ramps']\n",
    "    img_data_a = get_imgdata(data_dict[channel][f'Image {img_dir} with Forward Ramps'], channel, \n",
    "                             y=y_pt, unit_dict=unit_dict)\n",
    "    img_data_r = get_imgdata(data_dict[channel][f'Image {img_dir} with Backward Ramps'], channel, \n",
    "                             y=y_pt, unit_dict=unit_dict)\n",
    "    \n",
    "    # y_ind_a = np.argmin(abs(img_data_a['data']['Y']-y_pt))\n",
    "    # y_ind_r = np.argmin(abs(img_data_r['data']['Y']-y_pt))\n",
    "    \n",
    "    dash1_fig.data[3].z = img_data_a['XZ']#[:,y_ind_a,:]\n",
    "    dash1_fig.data[4].z = img_data_r['XZ']#[:,y_ind_r,:]\n",
    "\n",
    "    # defl_data = wsxm_getspectro(data_dict, 'Normal deflection', img_dir=img_dir, x= x_pt, y=y_pt, unit_dict=unit_dict)\n",
    "    spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x= x_pt, y=y_pt, \n",
    "                                   unit_dict=unit_dict, calc_d=True)\n",
    "    # df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel, unit='V')\n",
    "    # for fig_data in [dash1_fig.data[7], dash1_fig.data[8]]:\n",
    "    #     fig_data.x = spectro_data[fig_data.name]['x'] \n",
    "    #     fig_data.y = spectro_data[fig_data.name]['y']\n",
    "    # df_spectro, _ = wsxm_calcspectroparam(spectro_data, channel, unit_dict=unit_dict, calc_params=False)\n",
    "    for fig_data in [dash1_fig.data[7], dash1_fig.data[8]]:\n",
    "        fig_data.x = spectro_data[fig_data.name][spectro_x] \n",
    "        fig_data.y = spectro_data[fig_data.name]['y']\n",
    "        # fig_data.x = df_spectro[df_spectro['segment']==fig_data.name]['x']\n",
    "        # fig_data.y = df_spectro[df_spectro['segment']==fig_data.name]['y']\n",
    "        \n",
    "    if channel_top == 'Topography':\n",
    "        xx_h, yy_h = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], \n",
    "                                 'Topography', y=y_pt, unit_dict=unit_dict)\n",
    "    else:\n",
    "        # for key, val in FUNC_DICT.items():\n",
    "        #     if channel_top in val.keys():\n",
    "        #         channel_unit = key\n",
    "        #         break\n",
    "        xx_h, yy_h = get_imgline(param_data_dict[channel_top][img_dir], channel_top, \n",
    "                                 y=y_pt, unit_dict=unit_dict)\n",
    "        # xx_h, yy_h = get_imgline(param_data_dict[channel_top][img_dir], y=y_pt)\n",
    "    \n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        yy_h = tsf.flatten_line({'X':xx_h, 'Z':yy_h}, order=1)\n",
    "        \n",
    "    for fig_data in [dash1_fig.data[9], dash1_fig.data[10]]:\n",
    "        if fig_data.name == 'h':\n",
    "            fig_data.x = xx_h\n",
    "            fig_data.y = yy_h\n",
    "\n",
    "\n",
    "@dash1_output.capture()\n",
    "def dash1_update_z(change):\n",
    "    img_dir = dash1_imgdir_button.value\n",
    "    channel = dash1_chan_button.value\n",
    "    z_pt = dash1_slide_z.value\n",
    "    # vmin, vmax = dash1_slide_cb.value\n",
    "    \n",
    "    # img_data_a = data_dict[channel][f'Image {img_dir} with Forward Ramps']\n",
    "    # img_data_r = data_dict[channel][f'Image {img_dir} with Backward Ramps']\n",
    "    img_data_a = get_imgdata(data_dict[channel][f'Image {img_dir} with Forward Ramps'], channel, \n",
    "                             z=z_pt, unit_dict=unit_dict)\n",
    "    img_data_r = get_imgdata(data_dict[channel][f'Image {img_dir} with Backward Ramps'], channel, \n",
    "                             z=z_pt, unit_dict=unit_dict)\n",
    "    \n",
    "    # z_ind_a = np.argmin(abs(img_data_a['data']['Z']-z_pt))\n",
    "    # z_ind_r = np.argmin(abs(img_data_r['data']['Z']-z_pt))\n",
    "    \n",
    "    dash1_fig.data[5].z = img_data_a['XY']#[z_ind_a,:,:]\n",
    "    dash1_fig.data[6].z = img_data_r['XY']#[z_ind_r,:,:]\n",
    "    \n",
    "@dash1_output.capture()\n",
    "def dash1_update_zrange(change):\n",
    "    z_new = change.new\n",
    "    dash1_fig.update_layout(yaxis2_range=[zmin, z_new])\n",
    "    dash1_fig.update_layout(yaxis3_range=[zmin, z_new])\n",
    "    dash1_fig.update_layout(yaxis6_range=[zmin, z_new])\n",
    "    dash1_fig.update_layout(yaxis7_range=[zmin, z_new])\n",
    "    dash1_fig.update_layout(xaxis4_range=[zmin, z_new])\n",
    "\n",
    "@dash1_output.capture()\n",
    "def dash1_update_param(change):\n",
    "    img_dir = dash1_imgdir_button.value\n",
    "    channel_top = dash1_param_dropdown.value\n",
    "    x_pt = dash1_slide_x.value\n",
    "    y_pt = dash1_slide_y.value\n",
    "    if channel_top == 'Topography':\n",
    "        img_data = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                               unit_dict=unit_dict)\n",
    "        # img_data = data_dict[channel_top][f'Image {img_dir} with Forward Ramps']\n",
    "        # xx_v, yy_v = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], x=y_pt)\n",
    "        # xx_h, yy_h = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], y=y_pt)\n",
    "        xx_v, yy_v = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], \n",
    "                                 'Topography', x=x_pt, unit_dict=unit_dict)\n",
    "        xx_h, yy_h = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], \n",
    "                                 'Topography', y=y_pt, unit_dict=unit_dict)\n",
    "        unit_text = unit_dict[channel_top] #unit name\n",
    "    else:\n",
    "        # img_data = param_data_dict[channel_top][img_dir]\n",
    "        # for key, val in FUNC_DICT.items():\n",
    "        #     if channel_top in val.keys():\n",
    "        #         channel_unit = key\n",
    "        #         break\n",
    "        img_data = get_imgdata(param_data_dict[channel_top][img_dir], channel_top,\n",
    "                               unit_dict=unit_dict)\n",
    "        xx_v, yy_v = get_imgline(param_data_dict[channel_top][img_dir], \n",
    "                                 channel_top, x=x_pt, unit_dict=unit_dict)\n",
    "        xx_h, yy_h = get_imgline(param_data_dict[channel_top][img_dir], \n",
    "                                 channel_top, y=y_pt, unit_dict=unit_dict)\n",
    "        # xx_h, yy_h = get_imgline(param_data_dict[channel_top][img_dir], y=y_pt)\n",
    "        # xx_v, yy_v = get_imgline(param_data_dict[channel_top][img_dir], x=x_pt)\n",
    "        unit_text = parse_paramunit(channel_top, unit_dict, evaluate=False) #unit name\n",
    "    \n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "        yy_v = tsf.flatten_line({'X':xx_v, 'Z':yy_v}, order=1)\n",
    "        yy_h = tsf.flatten_line({'X':xx_h, 'Z':yy_h}, order=1)\n",
    "        \n",
    "    dash1_fig.data[0].z = img_data['Z']\n",
    "    \n",
    "    vmin = np.percentile(img_data['Z'], 1, method='midpoint')\n",
    "    vmax = np.percentile(img_data['Z'], 99, method='midpoint')\n",
    "    dash1_fig.layout.coloraxis2.cmin=vmin\n",
    "    dash1_fig.layout.coloraxis2.cmax=vmax\n",
    "    \n",
    "    for fig_data in [dash1_fig.data[9], dash1_fig.data[10]]:\n",
    "        if fig_data.name == 'h':\n",
    "            fig_data.x = xx_h\n",
    "            fig_data.y = yy_h\n",
    "        elif fig_data.name == 'v':\n",
    "            fig_data.x = xx_v\n",
    "            fig_data.y = yy_v\n",
    "    \n",
    "    dash1_fig.update_layout(yaxis8_title_text=f\"{channel_top} [{unit_text}]\")\n",
    "\n",
    "@dash1_output.capture()\n",
    "def dash1_update_imgdir(change):\n",
    "    dash1_update_param(None)\n",
    "    dash1_update_chan(None)\n",
    "\n",
    "@dash1_output.capture()\n",
    "def dash1_update_chan(change):\n",
    "    channel = dash1_chan_button.value\n",
    "    img_dir = dash1_imgdir_button.value\n",
    "    x_pt = dash1_slide_x.value\n",
    "    y_pt = dash1_slide_y.value\n",
    "    z_pt = dash1_slide_z.value\n",
    "    vmin, vmax = chan_mins[channel], chan_maxs[channel]\n",
    "    spectro_x = dash1_spectrox_button.value\n",
    "    \n",
    "    dash1_fig.layout.coloraxis1.cmin=vmin\n",
    "    dash1_fig.layout.coloraxis1.cmax=vmax\n",
    "    \n",
    "    #update position lines\n",
    "    dash1_fig.layout.shapes = [{\n",
    "                         'line': {'color': 'red', 'width': 2},\n",
    "                         'type': 'line',\n",
    "                         'visible': True,\n",
    "                         'x0': 0,\n",
    "                         'x1': 1,\n",
    "                         'xref': 'x domain',\n",
    "                         'y0': y_pt,\n",
    "                         'y1': y_pt,\n",
    "                         'yref': 'y'\n",
    "                     },\n",
    "                     {\n",
    "                         'line': {'color': 'blue', 'width': 2},\n",
    "                         'type': 'line',\n",
    "                         'visible': True,\n",
    "                         'x0': x_pt,\n",
    "                         'x1': x_pt,\n",
    "                         'xref': 'x',\n",
    "                         'y0': 0,\n",
    "                         'y1': 1,\n",
    "                         'yref': 'y domain'\n",
    "                     }]\n",
    "    \n",
    "    # img_data_a = data_dict[channel][f'Image {img_dir} with Forward Ramps']\n",
    "    # img_data_r = data_dict[channel][f'Image {img_dir} with Backward Ramps']\n",
    "    img_data_a = get_imgdata(data_dict[channel][f'Image {img_dir} with Forward Ramps'], channel, \n",
    "                             x=x_pt, y=y_pt, z=z_pt, unit_dict=unit_dict)\n",
    "    img_data_r = get_imgdata(data_dict[channel][f'Image {img_dir} with Backward Ramps'], channel, \n",
    "                             x=x_pt, y=y_pt, z=z_pt, unit_dict=unit_dict)\n",
    "    \n",
    "    # x_ind_a = np.argmin(abs(img_data_a['data']['X']-x_pt))\n",
    "    # x_ind_r = np.argmin(abs(img_data_r['data']['X']-x_pt))\n",
    "    \n",
    "    dash1_fig.data[1].z = img_data_a['YZ']#[:,:,x_ind_a]\n",
    "    dash1_fig.data[2].z = img_data_r['YZ']#[:,:,x_ind_r]\n",
    "    \n",
    "    # y_ind_a = np.argmin(abs(img_data_a['data']['Y']-y_pt))\n",
    "    # y_ind_r = np.argmin(abs(img_data_r['data']['Y']-y_pt))\n",
    "    \n",
    "    dash1_fig.data[3].z = img_data_a['XZ']#[:,y_ind_a,:]\n",
    "    dash1_fig.data[4].z = img_data_r['XZ']#[:,y_ind_r,:]\n",
    "    \n",
    "    # z_ind_a = np.argmin(abs(img_data_a['data']['Z']-z_pt))\n",
    "    # z_ind_r = np.argmin(abs(img_data_r['data']['Z']-z_pt))\n",
    "    \n",
    "    dash1_fig.data[5].z = img_data_a['XY']#[z_ind_a,:,:]\n",
    "    dash1_fig.data[6].z = img_data_r['XY']#[z_ind_r,:,:]\n",
    "    \n",
    "    # defl_data = wsxm_getspectro(data_dict, 'Normal deflection', img_dir=img_dir, x= x_pt, y=y_pt, unit_dict=unit_dict)\n",
    "    spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x= x_pt, y=y_pt, \n",
    "                                   unit_dict=unit_dict, calc_d=True)\n",
    "    # for fig_data in [dash1_fig.data[7], dash1_fig.data[8]]:\n",
    "    #     fig_data.x = spectro_data[fig_data.name]['x'] \n",
    "    #     fig_data.y = spectro_data[fig_data.name]['y']\n",
    "    # df_spectro, _ = wsxm_calcspectroparam(spectro_data, channel, unit_dict=unit_dict, calc_params=False)\n",
    "    for fig_data in [dash1_fig.data[7], dash1_fig.data[8]]:\n",
    "        fig_data.x = spectro_data[fig_data.name][spectro_x] \n",
    "        fig_data.y = spectro_data[fig_data.name]['y']\n",
    "        # fig_data.x = df_spectro[df_spectro['segment']==fig_data.name]['x']\n",
    "        # fig_data.y = df_spectro[df_spectro['segment']==fig_data.name]['y']\n",
    "    \n",
    "    dash1_fig.update_layout(yaxis4_title_text=f\"{channel} [{unit_dict[channel]}]\")\n",
    "    dash1_fig.update_layout(xaxis4_title_text=f\"{SPECT_DICT[spectro_x]} [{unit_dict['Z']}]\")\n",
    "\n",
    "    #reinitialize colorbar to new values of channel(works somehow)\n",
    "    dash1_slide_cb.unobserve(dash1_update_colorbar, 'value')\n",
    "    dash1_slide_cb.index = (0,0)\n",
    "    dash1_slide_cb.min, dash1_slide_cb.max = -1e100, 1e100 #to avoid error of min, max classh from previous value\n",
    "    dash1_slide_cb.step = (chan_maxs[channel]-chan_mins[channel])/100\n",
    "    dash1_slide_cb.value = (chan_mins[channel], chan_maxs[channel])\n",
    "    # dash1_slide_cb.min, dash1_slide_cb.max = chan_mins[channel], chan_maxs[channel]\n",
    "    dash1_slide_cb.observe(dash1_update_colorbar, 'value')\n",
    "\n",
    "@dash1_output.capture()\n",
    "def dash1_update_colorbar(change):\n",
    "    channel = dash1_chan_button.value\n",
    "    img_dir = dash1_imgdir_button.value\n",
    "    x_pt = dash1_slide_x.value\n",
    "    y_pt = dash1_slide_y.value\n",
    "    z_pt = dash1_slide_z.value\n",
    "    vmin, vmax = change.new    \n",
    "       \n",
    "    if dash1_slide_cb.min != chan_mins[channel] or  dash1_slide_cb.max != chan_maxs[channel]:\n",
    "        #slider reset to channel values\n",
    "        dash1_slide_cb.unobserve(dash1_update_colorbar, 'value')\n",
    "        dash1_slide_cb.min, dash1_slide_cb.max = -1e100, 1e100 #to avoid error of min, max classh from previous value\n",
    "        dash1_slide_cb.min, dash1_slide_cb.max = chan_mins[channel], chan_maxs[channel]\n",
    "        dash1_slide_cb.step = (chan_maxs[channel]-chan_mins[channel])/100\n",
    "        dash1_slide_cb.value = (chan_mins[channel], chan_maxs[channel])\n",
    "        dash1_slide_cb.observe(dash1_update_colorbar, 'value')\n",
    "        vmin, vmax = chan_mins[channel], chan_maxs[channel]\n",
    "    else:\n",
    "        dash1_fig.layout.coloraxis1.cmin=vmin\n",
    "        dash1_fig.layout.coloraxis1.cmax=vmax\n",
    "\n",
    "#update x,y cordinates by clicking inside the plot\n",
    "@dash1_output.capture()\n",
    "def dash1_onclick(trace, points, selector):\n",
    "    if len(points.point_inds) != 0:\n",
    "        x_pt = points.xs[0]\n",
    "        y_pt=points.ys[0]\n",
    "        \n",
    "        #update position lines\n",
    "        dash1_fig.layout.shapes = [{\n",
    "                             'line': {'color': 'red', 'width': 2},\n",
    "                             'type': 'line',\n",
    "                             'visible': True,\n",
    "                             'x0': 0,\n",
    "                             'x1': 1,\n",
    "                             'xref': 'x domain',\n",
    "                             'y0': y_pt,\n",
    "                             'y1': y_pt,\n",
    "                             'yref': 'y'\n",
    "                         },\n",
    "                         {\n",
    "                             'line': {'color': 'blue', 'width': 2},\n",
    "                             'type': 'line',\n",
    "                             'visible': True,\n",
    "                             'x0': x_pt,\n",
    "                             'x1': x_pt,\n",
    "                             'xref': 'x',\n",
    "                             'y0': 0,\n",
    "                             'y1': 1,\n",
    "                             'yref': 'y domain'\n",
    "                         }]\n",
    "        dash1_slide_x.unobserve(dash1_update_x, 'value')\n",
    "        dash1_slide_y.unobserve(dash1_update_y, 'value')\n",
    "        dash1_slide_x.value = x_pt\n",
    "        dash1_slide_y.value = y_pt\n",
    "        dash1_slide_x.observe(dash1_update_x, 'value')\n",
    "        dash1_slide_y.observe(dash1_update_y, 'value')\n",
    "    \n",
    "dash1_slide_x.observe(dash1_update_x, 'value')\n",
    "dash1_slide_y.observe(dash1_update_y, 'value')\n",
    "dash1_slide_z.observe(dash1_update_z, 'value')\n",
    "dash1_slide_zrange.observe(dash1_update_zrange, 'value')\n",
    "dash1_param_dropdown.observe(dash1_update_param, 'value')\n",
    "dash1_imgdir_button.observe(dash1_update_imgdir, 'value')\n",
    "dash1_chan_button.observe(dash1_update_chan, 'value')\n",
    "dash1_slide_cb.observe(dash1_update_colorbar, 'value')\n",
    "dash1_spectrox_button.observe(dash1_update_chan, 'value')\n",
    "dash1_fig.data[0].on_click(dash1_onclick)\n",
    "\n",
    "with dash1_figout:\n",
    "    display(dash1_fig)\n",
    "display(dash1_box4)\n",
    "display(widgets.HBox([dash1_figout])) #to make figure horizontally scrollable\n",
    "display(dash1_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80432855-3dd6-4b81-9e1f-40ec60162628",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compare spectroscopy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508de0c8-edf4-41f4-9660-20e76a3e8392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#close dashboard-2 figure if already open\n",
    "# for fignum_i in plt.get_fignums():\n",
    "#     figlab_i = plt.figure(fignum_i).get_label()\n",
    "#     if figlab_i == 'dash2':\n",
    "#         plt.close(figlab_i) \n",
    "    \n",
    "# fig2, ax2 = plt.subplots(1,2, figsize=(10.5,4), num='dash2',layout='constrained')\n",
    "# ax2_spec = [ax2[1], ax2[1].twinx(), ax2[1].twinx()]\n",
    "# ax2_spec[-1].spines['right'].set_position(('axes', 1.3))\n",
    "# fig2.canvas.header_visible = False\n",
    "# fig2.canvas.toolbar_position = 'bottom'\n",
    "dash2_corr_cols = ['Amplitude', 'Phase', 'Normal force', 'Excitation frequency'] #'True Amplitude', 'True Phase',\n",
    "dash2_color_var = 'curve number' #'curve number', 'segment' select which parameters should be coloured in corr plot\n",
    "flatten_chan = ['Topography'] #list of channels to apply flatten\n",
    "# choose the figure font\n",
    "font_dict=dict(family='Arial', size=18)#, color='white') # font of spectro plot\n",
    "font_dict_b=dict(family='Arial', size=12) #font of corr plot\n",
    "color_list = px.colors.qualitative.Plotly\n",
    "dash2_figdict = {'a': '', 'b': '', 'c': ''} \n",
    "\n",
    "#topography\n",
    "# dash2_figa = go.FigureWidget()\n",
    "img_data = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                       unit_dict=unit_dict)\n",
    "if 'Topography' in flatten_chan: #flatten channel\n",
    "    img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "# img_data = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "dash2_figa = plotly_heatmap(x=img_data['X'],\n",
    "                            y=img_data['Y'],\n",
    "                            z_mat=img_data['Z'], style='full', font_dict=font_dict)\n",
    "dash2_figa.data[0].coloraxis = 'coloraxis1'\n",
    "# dash2_figdict['a'].add_trace(dash2_figa.data[0])\n",
    "dash2_figdict['a'] = go.FigureWidget(dash2_figa)\n",
    "\n",
    "\n",
    "dash2_figdict['a'].update_layout(coloraxis1=dict(colorscale=cm_afmhot,#cmin=68500, cmax=69600,\n",
    "                                 colorbar=dict(#len=0.6, x=0.65, y=1, \n",
    "                                               thickness=15, #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                 )),\n",
    "                                 xaxis = dict(range=[xmin,xmax]),\n",
    "                                 yaxis = dict(range=[ymin,ymax]),\n",
    "                                 # font=font_dict,  # font formatting\n",
    "                                 # template='plotly_dark',\n",
    "                                  # plot_bgcolor='black',  # background color\n",
    "                                  height=500, width=600, title_text=\"\",\n",
    "                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "                                  showlegend=False)\n",
    "dash2_figdict['a'].update_layout(title={'text': f\"{'Topography'} [{unit_dict['Topography']}]\",'y':0.95,'x':0.5,\n",
    "                                        'xanchor': 'center','yanchor': 'top','font':font_dict})\n",
    "                                 \n",
    "# dash2_figdict['b'].update_layout(font=font_dict,  # font formatting\n",
    "#                                  template='plotly_dark',\n",
    "#                                  plot_bgcolor='black',  # background color\n",
    "#                                  height=500, width=1000, title_text=\"\",\n",
    "#                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "#                                  showlegend=False)\n",
    "\n",
    "dash2_figb_axdict = {} #dictionary of y axis\n",
    "dash2_figb_tracedict = {'calc':[]} #dictionary of index in FigureWidget.data for each plotted lines (other than vline/hline)\n",
    "\n",
    "dash2_figdict['b'] = plotly_multiyplot_initax(fig=None, yvars=[chan_list[0]], yax_dict=dash2_figb_axdict,\n",
    "                                              unit_dict=unit_dict, font_dict=font_dict, height=500, width=1000, ypos=0.05)\n",
    "# dash2_figdict['c'] = plotly_pairplot_initax(fig=None, num=len(chan_list), font_dict=font_dict)\n",
    "\n",
    "\n",
    "vmin, vmax = img_data['Z'].min(), img_data['Z'].max()\n",
    "curve_numall = []\n",
    "for xpt_i in img_data['X']:\n",
    "    for ypt_i in img_data['Y']:\n",
    "        curv_ind = f'x={xpt_i:.2f};y={ypt_i:.2f}'\n",
    "        curve_numall.append(curv_ind)\n",
    "\n",
    "#position lines on topo\n",
    "# dash2_figdict['a'].add_hline(y=ymin, line_color=\"red\", line_width=2,\n",
    "#                      visible=True, row=1,col=1)\n",
    "# dash2_figdict['a'].add_vline(x=xmin, line_color=\"blue\", line_width=2,\n",
    "#                      visible=True, row=1,col=1)\n",
    "xpt_len = 0.05*(xmax-xmin)\n",
    "ypt_len = 0.05*(ymax-ymin)\n",
    "x_pt_ini = x_data[np.argmin(abs(x_data-(xmin+xmax)/2))]\n",
    "y_pt_ini = y_data[np.argmin(abs(y_data-(ymin+ymax)/2))]\n",
    "dash2_figdict['a'].add_shape(type=\"line\",\n",
    "    x0=x_pt_ini, y0=y_pt_ini-ypt_len, x1=x_pt_ini, y1=y_pt_ini+ypt_len,\n",
    "    line=dict(color=color_list[0],width=2))\n",
    "dash2_figdict['a'].add_shape(type=\"line\",\n",
    "    x0=x_pt_ini-xpt_len, y0=y_pt_ini, x1=x_pt_ini+xpt_len, y1=y_pt_ini,\n",
    "    line=dict(color=color_list[0],width=2))\n",
    "# xx, yy, zz = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'])\n",
    "# vmin, vmax = zz.min(), zz.max()\n",
    "# pmesh_top2 = ax2[0].pcolormesh(xx,yy,zz, cmap='afmhot',vmin=chan_mins['Topography'],\n",
    "#                                 vmax=chan_maxs['Topography'])\n",
    "# cb_top2 = plt.colorbar(pmesh_top2, ax=ax2[0])\n",
    "\n",
    "#spectroscopy\n",
    "# dash2_figb = go.FigureWidget()\n",
    "# spec_dir = 'approach'\n",
    "# color_list = sns.color_palette()\n",
    "# spec_line2 = {}\n",
    "# for i, channel in enumerate(chan_list):\n",
    "#     spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir)\n",
    "#     df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel, unit='V')\n",
    "#     df_spectro['channel'] = channel\n",
    "#     df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "#     spec_line2[channel] = sns.lineplot(data=df_spectro_filt, x=\"x\", y=\"y\", ax=ax2_spec[i], color=color_list[i])\n",
    "#     ax2_spec[i].set_ylabel(channel)\n",
    "#     ax2_spec[i].yaxis.label.set_color(color_list[i])\n",
    "#     ax2_spec[i].tick_params(axis='y', colors=color_list[i]) \n",
    "\n",
    "# ax2_spec[0].set_xlabel('Z')\n",
    "\n",
    "#position lines on topo\n",
    "# line_h2 = ax2[0].axhline(ymin, xmin, xmax, linestyle='solid', color='r')\n",
    "# line_v2 = ax2[0].axvline(xmin, ymin, ymax, linestyle='solid', color='r')\n",
    "# plt.tight_layout()\n",
    "\n",
    "#widgets\n",
    "dash2_slide_x = widgets.IntSlider(value=x_pt_ini, min=xmin, max=xmax, step=(xmax-xmin)/x_num,\n",
    "                            description='x', layout=widgets.Layout(width='300px'))\n",
    "dash2_slide_y = widgets.IntSlider(value=y_pt_ini, min=ymin, max=ymax, step=(ymax-ymin)/y_num,\n",
    "                            description='y', layout=widgets.Layout(width='300px'))\n",
    "# dash2_slide_zrange = widgets.IntSlider(value=zmax, min=zmin, max=zmax, step=(zmax-zmin)/z_num,\n",
    "#                             description='z limit', layout=widgets.Layout(width='300px'))\n",
    "dash2_slide_cb = widgets.FloatRangeSlider(value=[vmin, vmax], min=vmin, max=vmax,\n",
    "                                     step=(vmax-vmin)/100, description='color',readout=True,\n",
    "                                         layout=widgets.Layout(width='300px'))\n",
    "# specdir_button2 = widgets.ToggleButtons(options=['approach', 'retract'], #CHANGE TO MULTIPLE SELECT!\n",
    "#                                     # description='Channel:',\n",
    "#                                      disabled=False)\n",
    "dash2_imgdir_button = widgets.ToggleButtons(options=['Forward', 'Backward'], style={\"button_width\": \"70px\"})\n",
    "                                            # layout=widgets.Layout(width='175px'),\n",
    "                                    # description='Channel:',\n",
    "                                     # disabled=False)\n",
    "dash2_spectrox_button = widgets.ToggleButtons(options=['x', 'd'], style={\"button_width\": \"20px\"})\n",
    "dash2_param_dropdown = widgets.Dropdown(options=param_list,\n",
    "                                        layout=widgets.Layout(width='175px'),\n",
    "                                  value='Topography',disabled=False)\n",
    "\n",
    "dash2_curve_toggle = widgets.ToggleButton(\n",
    "                                            value=False,\n",
    "                                            description='Hold points',\n",
    "                                            disabled=False,\n",
    "                                            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                                            # tooltip='Description',\n",
    "                                            #icon='check', # (FontAwesome names without the `fa-` prefix)\n",
    "    layout=widgets.Layout(width='175px'),\n",
    "                                        )\n",
    "#widgets\n",
    "# dash4_output = widgets.Output()\n",
    "dash2_chan_select = widgets.SelectMultiple(options=chan_list, value=[chan_list[0]])\n",
    "dash2_chan_box = widgets.VBox([widgets.Label('channels'), dash2_chan_select])\n",
    "# dash4_file_select = widgets.SelectMultiple(options=files_spectro, value=[files_spectro[0]])\n",
    "# dash4_file_box = widgets.VBox([widgets.Label('files'), dash4_file_select])\n",
    "curv_init = f'x={xmin:.2f};y={ymin:.2f}'\n",
    "dash2_curvnum_select = widgets.SelectMultiple(options=[curv_init], value=[curv_init])\n",
    "dash4_curvnum_box = widgets.VBox([widgets.Label('points'), dash2_curvnum_select])\n",
    "dash2_specdir_select = widgets.SelectMultiple(options=['approach', 'retract'], value=['approach'])\n",
    "dash2_specdir_box = widgets.VBox([widgets.Label('direction'), dash2_specdir_select])\n",
    "dash2_grid_toggle = widgets.ToggleButton(value=False, description='Show grid', button_style='')\n",
    "dash2_param_toggle = widgets.ToggleButton(value=False, description='Show calc', button_style='')\n",
    "dash2_plotupdate_check = widgets.Checkbox(value=False, description='Update corrplot')\n",
    "dash2_save_button = widgets.Button(description='Save')\n",
    "dash2_save_text = widgets.Text(value='', placeholder='File name to save')\n",
    "\n",
    "# dash2_unit_dropdown = {}\n",
    "# for chan_i in chan_list:\n",
    "#     chan_units_i = list(CALIB_DICT[chan_i].keys())\n",
    "#     dash2_unit_dropdown[chan_i] = widgets.Dropdown(options=chan_units_i,value=chan_units_i[0],\n",
    "#                                                   layout=widgets.Layout(width='50px'))\n",
    "# dash2_unit_box = widgets.VBox([widgets.Label('unit')]+list(dash2_unit_dropdown.values()), \n",
    "#                               layout=widgets.Layout(width='100px'))\n",
    "\n",
    "dash2_output = widgets.Output()\n",
    "dash2_box1 = widgets.VBox([dash2_slide_x, dash2_slide_y, dash2_slide_cb, dash2_plotupdate_check, \n",
    "                           widgets.HBox([dash2_save_text, dash2_save_button])],\n",
    "                         layout=widgets.Layout(width='500px'))\n",
    "dash2_box2 = widgets.VBox([dash2_param_dropdown, dash2_imgdir_button, dash2_spectrox_button, dash2_curve_toggle, \n",
    "                           widgets.HBox([dash2_param_toggle, dash2_grid_toggle])])#, layout=widgets.Layout(width='300px'))\n",
    "dash2_box3 = widgets.HBox([dash2_box2, dash2_box1, dash2_chan_box, dash2_specdir_box, dash4_curvnum_box])\n",
    "#output widgets to display table/figures\n",
    "# dash4_tableout = widgets.Output()\n",
    "dash2_figaout = widgets.Output()\n",
    "dash2_figbout = widgets.Output()\n",
    "dash2_figcout = widgets.Output()\n",
    "dash2_tableout = widgets.Output()\n",
    "dash2_box4 = widgets.HBox([dash2_figaout, dash2_figbout])\n",
    "dash2_fig_tab = widgets.Tab()\n",
    "dash2_fig_tab.children = [dash2_box4, dash2_tableout, dash2_figcout, dash2_output]\n",
    "dash2_fig_tab.titles = ['spectroscopy plot', 'statistics', 'correlation plots', 'debug']\n",
    "\n",
    "# dash2_figb_tracedict = {} #dictionary of traces used in statistics plot\n",
    "# plotly_multiyplot_initax(fig, yvars, yax_dict)\n",
    "\n",
    "with dash2_figaout:\n",
    "    display(dash2_figdict['a'])\n",
    "\n",
    "# curve_numall = []\n",
    "# spectro_data_long = {}\n",
    "# spectrodf_filt_list = []\n",
    "# spectroparam_dict = {} \n",
    "\n",
    "dash2_datadict = {} #UNCOMMENT THIS!\n",
    "\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_data(change):\n",
    "    chan_selected = dash2_chan_select.value\n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    spec_dir = dash2_specdir_select.value\n",
    "    curv_selected = dash2_curvnum_select.value\n",
    "    # files_spectro_filt = dash4_file_select.value\n",
    "    # img_dir = dash2_imgdir_button.value\n",
    "    # curve_numlist = dash2_curvnum_select.value\n",
    "    # curve_numall = []\n",
    "    # spectro_data_long = {}\n",
    "    spectrodf_filt_list = []\n",
    "    spectroparam_dict = {} \n",
    "    # curve_dict = {}\n",
    "    paramval_dict = {'channel':[], 'direction':[], 'curve number':[], 'x_pt':[], 'y_pt':[], 'parameter':[], 'value':[]}\n",
    "    # zmin, zmax = np.inf, -np.inf\n",
    "    # for i, file_i in enumerate(files_spectro_filt):\n",
    "    #     filepath_i = folderpath + '/' + file_df_spectro.loc[(file_df_spectro.file==file_i)].iloc[0].loc['name']\n",
    "    #     spectro_data_i = wsxm_readspectra(filepath_i, all_files=True, mute=True)\n",
    "    #     spectro_data_long[file_i] = {'file': []}\n",
    "    #     spectroparam_dict[file_i] = {}\n",
    "    for img_dir_i in [img_dir]:#img_dir_list:\n",
    "        for curv_ind in curv_selected:#curve_numall: #curve_numlist:\n",
    "            for chan_i in FUNC_DICT.keys(): #read channels in the same order as FUNC_DICT\n",
    "                if chan_i in chan_list:\n",
    "            # for chan_i in chan_list:#chan_selected:#chan_list:#spectro_data_i.keys():\n",
    "                # curve_numlist = list(spectro_data_i[chan_i]['curves'].keys()) #number of curves\n",
    "                # curve_numall += curve_numlist\n",
    "                # spectro_data_long[file_i]['file'] = []\n",
    "                # spectro_data_long['curve number'] = []\n",
    "                # spectro_data_long['segment'] = []\n",
    "                # spectro_data_long[chan_i] = []\n",
    "                    if chan_i not in spectroparam_dict.keys():\n",
    "                        spectroparam_dict[chan_i] = {}\n",
    "                # for img_dir_i in [img_dir]:#img_dir_list:\n",
    "                    if img_dir_i not in spectroparam_dict[chan_i].keys():\n",
    "                        spectroparam_dict[chan_i][img_dir_i] = {}\n",
    "                    # for curv_ind in curv_selected:#curve_numall: #curve_numlist:\n",
    "                        #spectroscopy\n",
    "                    # print(curv_ind)\n",
    "                    x_pt = float(curv_ind.split(';')[0].split('=')[1])#curve_dict[curv_ind]['x_pt']\n",
    "                    y_pt = float(curv_ind.split(';')[1].split('=')[1])#curve_dict[curv_ind]['y_pt']\n",
    "\n",
    "                    spectro_data_chani = wsxm_getspectro(data_dict, channel=chan_i, img_dir=img_dir_i, x=x_pt, y=y_pt, \n",
    "                                                         unit_dict=unit_dict, calc_d=True)\n",
    "                    spectrodf_filt_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_chani, chan_i, properties=properties,\n",
    "                                                                             calc_params=True, unit_dict=None)\n",
    "\n",
    "                    # spectro_data_chani = wsxm_getspectro(data_dict, channel=chan_i, img_dir=img_dir_i, \n",
    "                    #                                      x=x_pt, y=y_pt)\n",
    "                    # unit_i = dash2_unit_dropdown[chan_i].value\n",
    "                    #THIS CAN BE OPTIMIZED! PARAMETERS WERE ALREADY CALCULATED IN THE BEGINNING\n",
    "                    # spectrodf_filt_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_chani, chan_i, unit=unit_i, \n",
    "                    #                                                          properties=properties)\n",
    "                    # spectro_data_chani = spectro_data_i[chan_i]['curves'][curv_ind]['data']\n",
    "                    # unit_i = dash4_unit_dropdown[chan_i].value\n",
    "                    # spectrodf_filt_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_chani, chan_i, unit=unit_i) #CHECK CALIBRATION EVERYWHERE! TODO!\n",
    "                    spectroparam_dict[chan_i][img_dir_i][curv_ind] = spectroparam_i\n",
    "\n",
    "                    zero_shift_i = spectroparam_i['Adhesion']['zero'] if chan_i == 'Normal force' else 0\n",
    "                    spectrodf_filt_i.loc[:,'y'] = spectrodf_filt_i.loc[:,'y']-zero_shift_i\n",
    "                    spectrodf_filt_i.insert(0,'channel',chan_i)\n",
    "                    spectrodf_filt_i.insert(0,'direction',img_dir_i)\n",
    "                    spectrodf_filt_i.insert(0,'curve number',curv_ind)\n",
    "                    spectrodf_filt_i.insert(0,'x_pt',x_pt)\n",
    "                    spectrodf_filt_i.insert(0,'y_pt',y_pt)\n",
    "                    spectrodf_filt_list.append(spectrodf_filt_i)\n",
    "\n",
    "                    #collect data for pair plot and statistics for all channels\n",
    "                    # spectro_data_long[file_i]['file'] += [file_i]*len(spectrodf_filt_i['y'])\n",
    "                    # spectro_data_long['curve number'] += [curv_ind]*len(spectrodf_filt_i['y'])\n",
    "                    # spectro_data_long['segment'] += spectrodf_filt_i['segment'].to_list()\n",
    "                    # spectro_data_long[chan_i] += spectrodf_filt_i['y'].to_list()\n",
    "\n",
    "                    #collected calculated parameters for all channels\n",
    "                    for param_i, param_dict_i in spectroparam_i.items():\n",
    "                        # paramval_dict['file'].append(file_i)\n",
    "                        paramval_dict['channel'].append(chan_i)\n",
    "                        paramval_dict['direction'].append(img_dir_i)\n",
    "                        paramval_dict['curve number'].append(curv_ind)\n",
    "                        paramval_dict['x_pt'].append(x_pt)\n",
    "                        paramval_dict['y_pt'].append(y_pt)\n",
    "                        paramval_dict['parameter'].append(param_i)\n",
    "                        paramval_dict['value'].append(param_dict_i['value'])\n",
    "                \n",
    "    # curvnum_old = list(dash2_curvnum_select.value)\n",
    "    # dash2_curvnum_select.unobserve(dash2_update_allplots, 'value')\n",
    "    # dash2_curvnum_select.options = list(dict.fromkeys(curve_numlist))\n",
    "    # dash2_curvnum_select.index = (0,) #used to fix bug, now widget value can be updated after options update\n",
    "    # if all(ind in curve_numlist for ind in curvnum_old) == False:\n",
    "    #     dash2_curvnum_select.value = (curve_numlist[0],)\n",
    "    # else:\n",
    "    #     dash2_curvnum_select.value = tuple(curvnum_old)\n",
    "    # dash2_curvnum_select.observe(dash2_update_allplots, 'value')            \n",
    "\n",
    "    dash2_datadict['full'] = pd.concat(spectrodf_filt_list)\n",
    "    dash2_datadict['long'] = dash2_datadict['full'].pivot(columns='channel', \n",
    "                                                          index=['direction', 'curve number', 'segment', 'x'],\n",
    "                                                          values='y').reset_index()    \n",
    "    dash2_datadict['paramdict'] = spectroparam_dict\n",
    "    \n",
    "    #statistics of spectroscopy calculated parameters\n",
    "    paramval_groupcols = ['channel', 'direction', 'parameter']\n",
    "    paramval_df = pd.DataFrame(paramval_dict)\n",
    "    paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "    paramval_summary = paramval_grouped['value'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    dash2_datadict['param'] = paramval_df.drop(columns=['curve number'])\n",
    "    dash2_datadict['summary'] = paramval_summary\n",
    "    \n",
    "    #statistics of spectroscopy calculated parameters\n",
    "#     paramval_groupcols = ['channel', 'parameter']\n",
    "#     paramval_df = pd.DataFrame(paramval_dict)\n",
    "#     paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "#     paramval_summary = paramval_grouped['value'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "#     dash2_datadict['param'] = paramval_df\n",
    "#     dash2_datadict['summary'] = paramval_summary\n",
    "    \n",
    "    # plotly_pairplot_initax(fig=dash4_figdict['b'], num=len(dash4_datadict['full']['channel'].unique()))\n",
    "    \n",
    "    dash2_tableout.clear_output()\n",
    "    with dash2_tableout:\n",
    "        itables.show(dash2_datadict['summary'])\n",
    "        itables.show(dash2_datadict['param'])\n",
    "\n",
    "\n",
    "\n",
    "#update functions\n",
    "@dash2_output.capture()\n",
    "def dash2_update_plot(change):\n",
    "    # files_selected = dash4_file_select.value\n",
    "    chan_selected = list(dash2_chan_select.value)\n",
    "    # chan_selected.sort()\n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    spec_dir = dash2_specdir_select.value\n",
    "    curv_ind = dash2_curvnum_select.value\n",
    "    calc_show = dash2_param_toggle.value\n",
    "    spectro_x = dash2_spectrox_button.value\n",
    "    \n",
    "    spectrodf_full = dash2_datadict['full']\n",
    "    spectro_longdf = dash2_datadict['long'] #pd.DataFrame(dash4_datadict['long'][list(dash4_file_select.value)[0]])\n",
    "    spectroparam_dict = dash2_datadict['paramdict']\n",
    "    spectrodf_filt = spectrodf_full[(spectrodf_full['channel'].isin(chan_selected)) & (spectrodf_full['direction']==img_dir) &\n",
    "                                   (spectrodf_full['segment'].isin(spec_dir)) & (spectrodf_full['curve number'].isin(curv_ind))]\n",
    "    spectrolong_filt = spectro_longdf[(spectro_longdf['direction']==img_dir) & (spectro_longdf['segment'].isin(spec_dir)) & \n",
    "                                      (spectro_longdf['curve number'].isin(curv_ind))]\n",
    "    #update spectroscopy plot\n",
    "    plotly_multiyplot(fig=dash2_figdict['b'], yax_dict= dash2_figb_axdict, data=spectrodf_filt, \n",
    "                      multiy_col='channel', yvars=chan_selected, x=spectro_x, y=\"y\", line_group=\"curve number\", \n",
    "                      color='curve number' if dash2_curve_toggle.value==True else None,#if dash2_curve_toggle==True\n",
    "                      #symbol='curve number', hover_name=\"curve number\", \n",
    "                      line_dash=\"segment\", font_dict=font_dict)\n",
    "    dash2_update_grid(None)\n",
    "    dash2_figdict['b'].update_layout(xaxis_title_text=f\"{SPECT_DICT[spectro_x]} [{unit_dict['Z']}]\")\n",
    "    \n",
    "    dash2_figdict['b'].layout.shapes = []\n",
    "    dash2_figb_tracedict['calc'] = []\n",
    "    # for file_i in files_selected:\n",
    "    for chan_i in chan_selected:\n",
    "        for curv_i in curv_ind:\n",
    "            try:\n",
    "                spectroparam_i = spectroparam_dict[chan_i][img_dir][curv_i]\n",
    "            except:\n",
    "                print('ERROR', chan_i, curv_i)\n",
    "                continue\n",
    "            zero_shift_i = spectroparam_i['Adhesion']['zero'] if chan_i == 'Normal force' else 0\n",
    "            for param_i, param_dict_i in spectroparam_i.items():\n",
    "                #plot parameter calculation lines, fits. Only plot if parameter calculated for selected segment\n",
    "                if param_dict_i['segment'] in spec_dir: #CHECK THIS!                            \n",
    "                    if FUNC_DICT[chan_i][param_i]['plot type'] == 'line': #CHECK THIS!\n",
    "                        if len(param_dict_i['y']) != 0:\n",
    "                            plotly_dashedlines(plot_type='line', fig=dash2_figdict['b'], \n",
    "                                               x=param_dict_i[spectro_x], y=param_dict_i['y']-zero_shift_i,\n",
    "                                               yaxis=dash2_figb_axdict[chan_i], visible=calc_show, line_width=3)\n",
    "                            # dash2_figdict['b'].add_trace(go.Scatter(x=param_dict_i['x'], y=param_dict_i['y']-zero_shift_i,\n",
    "                            #                                         mode='lines', yaxis=dash2_figb_axdict[chan_i],\n",
    "                            #                                         line_dash=\"dash\", line_color=\"white\", line_width=3,\n",
    "                            #                                        visible=calc_show))\n",
    "                            dash2_figb_tracedict['calc'].append(len(dash2_figdict['b'].data)-1)\n",
    "                    else:\n",
    "                        for paramtype_i, ptype_i in FUNC_DICT[chan_i][param_i]['plot type'].items(): #WONT WORK WITH 'd' as X-AXIS!\n",
    "                            plotly_dashedlines(plot_type=ptype_i, fig=dash2_figdict['b'], \n",
    "                                               x=param_dict_i[paramtype_i], y=param_dict_i[paramtype_i]-zero_shift_i,\n",
    "                                               yaxis=dash2_figb_axdict[chan_i], visible=calc_show, line_width=3)\n",
    "                            # if ptype_i == 'hline':\n",
    "                            #     dash2_figdict['b'].add_hline(y=param_dict_i[paramtype_i]-zero_shift_i,\n",
    "                            #                                  yref=dash2_figb_axdict[chan_i],secondary_y=True,\n",
    "                            #                                  line_dash=\"dash\", line_color=\"white\", line_width=3,\n",
    "                            #                                 visible=calc_show)\n",
    "                            # elif ptype_i == 'vline': #ADD OTHER PLOT TYPES HERE TODO!\n",
    "                            #     dash2_figdict['b'].add_vline(x=param_dict_i[paramtype_i],\n",
    "                            #                                  line_dash=\"dash\", line_color=\"white\", line_width=3,\n",
    "                            #                                 visible=calc_show)\n",
    "    \n",
    "    dash2_figbout.clear_output(wait=True)\n",
    "    with dash2_figbout: \n",
    "        display(dash2_figdict['b'])  \n",
    "     \n",
    "    #don't update statistics plot if only channel or specro specific widget values changed\n",
    "    if change in ['all']:\n",
    "        # long_cols = list(spectrolong_filt.columns)\n",
    "        # # long_cols.remove('file')\n",
    "        # long_cols.remove('direction')\n",
    "        # long_cols.remove('curve number')\n",
    "        # long_cols.remove('segment')\n",
    "        # long_cols.remove('x')\n",
    "        # long_cols.sort()\n",
    "        # itables.show(spectrolong_filt)\n",
    "        # dash2_figdict['c'] = plotly_pairplot(fig=dash2_figdict['c'], data=spectrolong_filt, cols = long_cols, \n",
    "        #                 hue='curve number', diag_kind = 'hist', font_dict=font_dict)\n",
    "        long_cols = []\n",
    "        for long_col_i in dash2_corr_cols: #check if dash2_corr_cols exists in spectrolong_filt, only take those that do exist\n",
    "            if long_col_i in spectrolong_filt.columns:\n",
    "                long_cols.append(long_col_i)\n",
    "        if dash2_plotupdate_check.value == True:\n",
    "            dash2_figdict['c'] = seaborn_pairplot(spectrolong_filt, cols=long_cols, hue=dash2_color_var,\n",
    "                                                  diag_kind='kde', plot_kws=dict(s=10, linewidth=0.0), font_dict=font_dict_b)\n",
    "\n",
    "\n",
    "            dash2_figcout.clear_output(wait=True)\n",
    "            with dash2_figcout:\n",
    "                display(dash2_figdict['c'])\n",
    "            # dash2_figdict['c'] = go.FigureWidget(dash2_figc)\n",
    "            plt.close('all')\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_plotchan(change):\n",
    "    chan_selected = dash2_chan_select.value\n",
    "    plotly_multiyplot_initax(fig=dash2_figdict['b'], yvars=chan_selected, yax_dict=dash2_figb_axdict,\n",
    "                             unit_dict=unit_dict, font_dict=font_dict, ypos=0.05)\n",
    "    if change == 'all':\n",
    "        # dash2_update_data(None)\n",
    "        dash2_update_plot('all')\n",
    "    else:\n",
    "        # dash2_update_data(None)\n",
    "        dash2_update_plot('chan')\n",
    "        \n",
    "@dash2_output.capture()\n",
    "def dash2_update_x(change):\n",
    "    # print('update x', change.new)\n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    spec_dir = dash2_specdir_select.value\n",
    "    x_pt = x_data[np.argmin(abs(x_data-dash2_slide_x.value))]\n",
    "    y_pt = y_data[np.argmin(abs(y_data-dash2_slide_y.value))]\n",
    "    \n",
    "    #update position lines\n",
    "    # dash2_figdict['a'].layout.shapes = [{\n",
    "    #                      'line': {'color': 'red', 'width': 2},\n",
    "    #                      'type': 'line',\n",
    "    #                      'visible': True,\n",
    "    #                      'x0': 0,\n",
    "    #                      'x1': 1,\n",
    "    #                      'xref': 'x domain',\n",
    "    #                      'y0': y_pt,\n",
    "    #                      'y1': y_pt,\n",
    "    #                      'yref': 'y'\n",
    "    #                  },\n",
    "    #                  {\n",
    "    #                      'line': {'color': 'blue', 'width': 2},\n",
    "    #                      'type': 'line',\n",
    "    #                      'visible': True,\n",
    "    #                      'x0': x_pt,\n",
    "    #                      'x1': x_pt,\n",
    "    #                      'xref': 'x',\n",
    "    #                      'y0': 0,\n",
    "    #                      'y1': 1,\n",
    "    #                      'yref': 'y domain'\n",
    "    #                  }]\n",
    "    dash2_figdict['a'].layout.shapes = [{'line': {'color': color_list[0], 'width': 2}, 'type': 'line', \n",
    "                                             'x0': x_pt, 'x1': x_pt, 'y0': y_pt-ypt_len, 'y1': y_pt+ypt_len},\n",
    "                                            {'line': {'color': color_list[0], 'width': 2}, 'type': 'line', \n",
    "                                             'x0': x_pt-xpt_len, 'x1': x_pt+xpt_len, 'y0': y_pt, 'y1': y_pt}]\n",
    "        \n",
    "    curv_ind = f'x={x_pt:.2f};y={y_pt:.2f}'\n",
    "    dash2_curvnum_select.unobserve(dash2_update_curvselect, 'value')\n",
    "    if curv_ind not in dash2_curvnum_select.options:\n",
    "        if dash2_curve_toggle.value == True:\n",
    "            dash2_curvnum_select.options += (curv_ind,)\n",
    "        else:\n",
    "            dash2_curvnum_select.options = [curv_ind]\n",
    "    dash2_curvnum_select.value = [curv_ind]\n",
    "    dash2_curvnum_select.observe(dash2_update_curvselect, 'value')\n",
    "    \n",
    "    dash2_update_data(None)\n",
    "    dash2_update_plot('all')\n",
    "    \n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    # for i, channel in enumerate(chan_list):\n",
    "    #     spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "    #     df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel, unit='V')\n",
    "    #     df_spectro['channel'] = channel\n",
    "    #     df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "    #     spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "    #     ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    # line_v2.set_xdata([x_pt]) #vertical line on topo\n",
    "    # fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_y(change):\n",
    "    # print('update y', change.new)\n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    spec_dir = dash2_specdir_select.value\n",
    "    x_pt = x_data[np.argmin(abs(x_data-dash2_slide_x.value))]\n",
    "    y_pt = y_data[np.argmin(abs(y_data-dash2_slide_y.value))]\n",
    "    \n",
    "    #update position lines\n",
    "    # dash2_figdict['a'].layout.shapes = [{\n",
    "    #                      'line': {'color': 'red', 'width': 2},\n",
    "    #                      'type': 'line',\n",
    "    #                      'visible': True,\n",
    "    #                      'x0': 0,\n",
    "    #                      'x1': 1,\n",
    "    #                      'xref': 'x domain',\n",
    "    #                      'y0': y_pt,\n",
    "    #                      'y1': y_pt,\n",
    "    #                      'yref': 'y'\n",
    "    #                  },\n",
    "    #                  {\n",
    "    #                      'line': {'color': 'blue', 'width': 2},\n",
    "    #                      'type': 'line',\n",
    "    #                      'visible': True,\n",
    "    #                      'x0': x_pt,\n",
    "    #                      'x1': x_pt,\n",
    "    #                      'xref': 'x',\n",
    "    #                      'y0': 0,\n",
    "    #                      'y1': 1,\n",
    "    #                      'yref': 'y domain'\n",
    "    #                  }]\n",
    "    dash2_figdict['a'].layout.shapes = [{'line': {'color': color_list[0], 'width': 2}, 'type': 'line', \n",
    "                                             'x0': x_pt, 'x1': x_pt, 'y0': y_pt-ypt_len, 'y1': y_pt+ypt_len},\n",
    "                                            {'line': {'color': color_list[0], 'width': 2}, 'type': 'line', \n",
    "                                             'x0': x_pt-xpt_len, 'x1': x_pt+xpt_len, 'y0': y_pt, 'y1': y_pt}]\n",
    "        \n",
    "    curv_ind = f'x={x_pt:.2f};y={y_pt:.2f}'\n",
    "    dash2_curvnum_select.unobserve(dash2_update_curvselect, 'value') \n",
    "    if curv_ind not in dash2_curvnum_select.options:\n",
    "        if dash2_curve_toggle.value == True:\n",
    "            dash2_curvnum_select.options += (curv_ind,)\n",
    "        else:\n",
    "            dash2_curvnum_select.options = [curv_ind]\n",
    "    dash2_curvnum_select.value = [curv_ind]\n",
    "    dash2_curvnum_select.observe(dash2_update_curvselect, 'value') \n",
    "    \n",
    "    dash2_update_data(None)\n",
    "    dash2_update_plot('all')\n",
    "    \n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    # for i, channel in enumerate(chan_list):\n",
    "    #     spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "    #     df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel, unit='V')\n",
    "    #     df_spectro['channel'] = channel\n",
    "    #     df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "    #     spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "    #     ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    # line_h2.set_ydata([y_pt]) #horizontal line on topo\n",
    "    # fig2.canvas.draw()\n",
    "\n",
    "# @dash2_output.capture()\n",
    "# def dash2_update_zrange(change):\n",
    "#     z_new = change.new\n",
    "#     dash2_figdict['b'].update_layout(xaxis_range=[zmin, z_new])\n",
    "    # z_new = change.new\n",
    "    # for i, channel in enumerate(chan_list):\n",
    "    #     ax2_spec[i].set_xlim(zmin, z_new)\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_param(change):\n",
    "    # img_dir = imgdir_button2.value\n",
    "    # if change.new == 'Topography':\n",
    "    #     xx, yy, zz = get_imgdata(data_dict[change.new][f'Image {img_dir} with Forward Ramps'])\n",
    "    # else:\n",
    "    #     xx, yy, zz = get_imgdata(param_data_dict[change.new][imgdir_button2.value])\n",
    "    # pmesh_top2.set_array(zz)\n",
    "    # vmin, vmax = zz.min(), zz.max()\n",
    "    # pmesh_top2.set_clim(vmin, vmax)\n",
    "    # cb_top2.mappable.set_clim(vmin, vmax)\n",
    "    # fig2.canvas.draw()\n",
    "    \n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    channel_top = dash2_param_dropdown.value\n",
    "    x_pt = x_data[np.argmin(abs(x_data-dash2_slide_x.value))]\n",
    "    y_pt = y_data[np.argmin(abs(y_data-dash2_slide_y.value))]\n",
    "    if channel_top == 'Topography':\n",
    "        img_data = get_imgdata(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], channel_top,\n",
    "                               unit_dict=unit_dict)\n",
    "        unit_text = unit_dict[channel_top]\n",
    "        # img_data = data_dict[channel_top][f'Image {img_dir} with Forward Ramps']\n",
    "        # xx_v, yy_v = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], x=y_pt)\n",
    "        # xx_h, yy_h = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], y=y_pt)\n",
    "    else:\n",
    "        img_data = get_imgdata(param_data_dict[channel_top][img_dir], channel_top,\n",
    "                               unit_dict=unit_dict)\n",
    "        unit_text = parse_paramunit(channel_top, unit_dict, evaluate=False)\n",
    "        # img_data = param_data_dict[channel_top][img_dir]\n",
    "        # xx_h, yy_h = get_imgline(param_data_dict[channel_top][img_dir], y=y_pt)\n",
    "        # xx_v, yy_v = get_imgline(param_data_dict[channel_top][img_dir], x=x_pt)\n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "\n",
    "    dash2_figdict['a'].data[0].z = img_data['Z']\n",
    "    dash2_figdict['a'].update_layout(title_text = f\"{channel_top} [{unit_text}]\")\n",
    "    \n",
    "    vmin, vmax = img_data['Z'].min(), img_data['Z'].max()\n",
    "    vmin_good = np.percentile(img_data['Z'], 1, method='midpoint')\n",
    "    vmax_good = np.percentile(img_data['Z'], 99, method='midpoint')\n",
    "    dash2_figdict['a'].layout.coloraxis.cmin=vmin_good\n",
    "    dash2_figdict['a'].layout.coloraxis.cmax=vmax_good\n",
    "\n",
    "    #reinitialize colorbar to new values of channel(works somehow)\n",
    "    dash2_slide_cb.unobserve(dash2_update_colorbar, 'value')\n",
    "    dash2_slide_cb.min, dash2_slide_cb.max = -1e100, 1e100 #to avoid error of min, max classh from previous value\n",
    "    dash2_slide_cb.step = (vmax_good-vmin_good)/100\n",
    "    dash2_slide_cb.value = (vmin_good, vmax_good)\n",
    "    # slide_cb.min, slide_cb.max = chan_mins[channel], chan_maxs[channel]\n",
    "    dash2_slide_cb.observe(dash2_update_colorbar, 'value')\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_imgdir(change):\n",
    "    # img_dir = change.new\n",
    "    # x_pt = slide_x2.value\n",
    "    # y_pt = slide_y2.value\n",
    "    # spec_dir = specdir_button2.value\n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    spec_dir = dash2_specdir_select.value\n",
    "    channel_top = dash2_param_dropdown.value\n",
    "    x_pt = x_data[np.argmin(abs(x_data-dash2_slide_x.value))]\n",
    "    y_pt = y_data[np.argmin(abs(y_data-dash2_slide_y.value))]\n",
    "    chan_selected = dash2_chan_select.value\n",
    "    vmin, vmax = dash2_slide_cb.value\n",
    "    \n",
    "    # if param_dropdown2.value == 'Topography':\n",
    "    #     xx, yy, zz = get_imgdata(data_dict[param_dropdown2.value][f'Image {img_dir} with Forward Ramps'])\n",
    "    # else:\n",
    "    #     xx, yy, zz = get_imgdata(param_data_dict[param_dropdown2.value][img_dir])\n",
    "    # pmesh_top2.set_array(zz)\n",
    "    # pmesh_top2.set_clim(vmin,vmax)\n",
    "    \n",
    "    if channel_top == 'Topography':\n",
    "        img_data = get_imgdata(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], channel_top,\n",
    "                               unit_dict=unit_dict)\n",
    "        # img_data = data_dict[channel_top][f'Image {img_dir} with Forward Ramps']\n",
    "        # xx_v, yy_v = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], x=y_pt)\n",
    "        # xx_h, yy_h = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], y=y_pt)\n",
    "    else:\n",
    "        img_data = get_imgdata(param_data_dict[channel_top][img_dir], channel_top,\n",
    "                               unit_dict=unit_dict)\n",
    "        # img_data = param_data_dict[channel_top][img_dir]\n",
    "        # xx_h, yy_h = get_imgline(param_data_dict[channel_top][img_dir], y=y_pt)\n",
    "        # xx_v, yy_v = get_imgline(param_data_dict[channel_top][img_dir], x=x_pt)\n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "    \n",
    "    dash2_figdict['a'].data[0].z = img_data['Z']\n",
    "    \n",
    "    dash2_update_data(None)\n",
    "    dash2_update_plot('all')\n",
    "        \n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    # for i, channel in enumerate(chan_list):\n",
    "    #     spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "    #     df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel, unit='V')\n",
    "    #     df_spectro['channel'] = channel\n",
    "    #     df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "    #     spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "    #     ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    # fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_specdir(change):\n",
    "    # img_dir = imgdir_button2.value\n",
    "    # x_pt = slide_x2.value\n",
    "    # y_pt = slide_y2.value\n",
    "    # spec_dir = change.new\n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    spec_dir = dash2_specdir_select.value\n",
    "    x_pt = x_data[np.argmin(abs(x_data-dash2_slide_x.value))]\n",
    "    y_pt = y_data[np.argmin(abs(y_data-dash2_slide_y.value))]\n",
    "\n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    # for i, channel in enumerate(chan_list):\n",
    "    #     spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "    #     df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel, unit='V')\n",
    "    #     df_spectro['channel'] = channel\n",
    "    #     df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "    #     spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "    #     ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    # fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_colorbar(change):\n",
    "    vmin, vmax = change.new\n",
    "    img_dir = dash2_imgdir_button.value\n",
    "    channel_top = dash2_param_dropdown.value\n",
    "    if channel_top == 'Topography':\n",
    "        img_data = get_imgdata(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], channel_top,\n",
    "                               unit_dict=unit_dict)\n",
    "        # img_data = data_dict[channel_top][f'Image {img_dir} with Forward Ramps']\n",
    "        # xx_v, yy_v = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], x=y_pt)\n",
    "        # xx_h, yy_h = get_imgline(data_dict[channel_top][f'Image {img_dir} with Forward Ramps'], y=y_pt)\n",
    "    else:\n",
    "        img_data = get_imgdata(param_data_dict[channel_top][img_dir], channel_top,\n",
    "                               unit_dict=unit_dict)\n",
    "        # img_data = param_data_dict[channel_top][img_dir]\n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "    # zz = img_data['data']['Z']\n",
    "    # print(dash2_slide_cb.min,img_data['data']['Z'].min(),dash2_slide_cb.max,img_data['data']['Z'].max())\n",
    "    # vmin, vmax = img_data['Z'].min(), img_data['Z'].max()\n",
    "    if dash2_slide_cb.min != img_data['Z'].min() or  dash2_slide_cb.max != img_data['Z'].max():\n",
    "        #slider reset to channel values        \n",
    "        vmin_good = np.percentile(img_data['Z'], 1, method='midpoint')\n",
    "        vmax_good = np.percentile(img_data['Z'], 99, method='midpoint')\n",
    "        dash2_slide_cb.unobserve(dash2_update_colorbar, 'value')\n",
    "        dash2_slide_cb.min, dash2_slide_cb.max = -1e100, 1e100 #to avoid error of min, max classh from previous value\n",
    "        dash2_slide_cb.min, dash2_slide_cb.max = img_data['Z'].min(), img_data['Z'].max()\n",
    "        dash2_slide_cb.step = (vmax_good - vmin_good)/100\n",
    "        dash2_slide_cb.value = (vmin_good, vmax_good)\n",
    "        dash2_slide_cb.observe(dash2_update_colorbar, 'value')\n",
    "    else:\n",
    "        dash2_figdict['a'].layout.coloraxis1.cmin=vmin\n",
    "        dash2_figdict['a'].layout.coloraxis1.cmax=vmax\n",
    "        # pmesh_top2.set_clim(vmin, vmax)\n",
    "        # cb_top2.mappable.set_clim(vmin, vmax)\n",
    "        # fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_allplots(change):\n",
    "    # dash2_update_data(None)\n",
    "    dash2_update_plot('all')\n",
    "    \n",
    "@dash2_output.capture()\n",
    "def dash2_update_units(change):\n",
    "    dash2_update_data(None)\n",
    "    dash2_update_plot('all')\n",
    "    \n",
    "@dash2_output.capture()\n",
    "def dash2_update_curvselect(change):\n",
    "    curv_ind_list = dash2_curvnum_select.value\n",
    "    shape_list = []\n",
    "    for i, curv_ind in enumerate(curv_ind_list):\n",
    "        x_pt = float(curv_ind.split(';')[0].split('=')[1])#curve_dict[curv_ind]['x_pt']\n",
    "        y_pt = float(curv_ind.split(';')[1].split('=')[1])#curve_dict[curv_ind]['y_pt']\n",
    "        # print(curv_ind, x_pt, y_pt)\n",
    "        shape_list += [{'line': {'color': color_list[i], 'width': 2}, 'type': 'line', \n",
    "                            'x0': x_pt, 'x1': x_pt, 'y0': y_pt-ypt_len, 'y1': y_pt+ypt_len},\n",
    "                           {'line': {'color': color_list[i], 'width': 2}, 'type': 'line', \n",
    "                            'x0': x_pt-xpt_len, 'x1': x_pt+xpt_len, 'y0': y_pt, 'y1': y_pt}]\n",
    "    \n",
    "    #update position lines\n",
    "    # dash2_figdict['a'].layout.shapes = [{\n",
    "    #                      'line': {'color': 'red', 'width': 2},\n",
    "    #                      'type': 'line',\n",
    "    #                      'visible': True,\n",
    "    #                      'x0': 0,\n",
    "    #                      'x1': 1,\n",
    "    #                      'xref': 'x domain',\n",
    "    #                      'y0': y_pt,\n",
    "    #                      'y1': y_pt,\n",
    "    #                      'yref': 'y'\n",
    "    #                  },\n",
    "    #                  {\n",
    "    #                      'line': {'color': 'blue', 'width': 2},\n",
    "    #                      'type': 'line',\n",
    "    #                      'visible': True,\n",
    "    #                      'x0': x_pt,\n",
    "    #                      'x1': x_pt,\n",
    "    #                      'xref': 'x',\n",
    "    #                      'y0': 0,\n",
    "    #                      'y1': 1,\n",
    "    #                      'yref': 'y domain'\n",
    "    #                  }]\n",
    "    \n",
    "    # print(shape_list)\n",
    "    dash2_figdict['a'].layout.shapes = shape_list\n",
    "    dash2_update_data(None)\n",
    "    dash2_update_plot('all')\n",
    "    # dash2_slide_x.unobserve(dash2_update_x, 'value')\n",
    "    # dash2_slide_y.unobserve(dash2_update_y, 'value')\n",
    "    # dash2_slide_x.value = x_data[np.argmin(abs(x_data-x_pt))]       \n",
    "    # dash2_slide_y.value = y_data[np.argmin(abs(y_data-y_pt))]\n",
    "    # dash2_slide_x.observe(dash2_update_x, 'value')\n",
    "    # dash2_slide_y.observe(dash2_update_y, 'value')\n",
    "    # if x_pt == 0.0 or y_pt == 0.0:\n",
    "    #     dash2_update_plot('all')\n",
    "\n",
    "    \n",
    "@dash2_output.capture()\n",
    "def dash2_update_plotcalc(change):\n",
    "    calc_show = change.new #dash4_param_toggle.value\n",
    "    for i, data in enumerate(dash2_figdict['b'].data):\n",
    "        if i in dash2_figb_tracedict['calc']:\n",
    "            dash2_figdict['b'].data[i].visible = calc_show\n",
    "    \n",
    "    for i, shape in enumerate(dash2_figdict['b'].layout.shapes):\n",
    "        dash2_figdict['b'].layout.shapes[i].visible = calc_show\n",
    "        \n",
    "@dash2_output.capture()\n",
    "def dash2_update_grid(change):\n",
    "    if dash2_grid_toggle.value == True:\n",
    "        dash2_figdict['b'].update_layout(yaxis_showgrid=True, yaxis_zeroline=True,\n",
    "                                         xaxis_showgrid=True, xaxis_zeroline=True)\n",
    "                                        \n",
    "        # dash4_figdict['a'].layout.plot_bgcolor=None\n",
    "    else:\n",
    "        dash2_figdict['b'].update_layout(yaxis_showgrid=False, yaxis_zeroline=False,\n",
    "                                         xaxis_showgrid=False, xaxis_zeroline=False)\n",
    "        \n",
    "#update x,y cordinates by clicking inside the plot\n",
    "@dash2_output.capture()\n",
    "def dash2_onclick(trace, points, selector):\n",
    "    # print('test', points, trace, selector)\n",
    "    if len(points.point_inds) != 0:\n",
    "        x_pt = points.xs[0]\n",
    "        y_pt = points.ys[0]\n",
    "        \n",
    "        #update position lines\n",
    "        # dash2_figdict['a'].layout.shapes = [{\n",
    "        #                      'line': {'color': 'red', 'width': 2},\n",
    "        #                      'type': 'line',\n",
    "        #                      'visible': True,\n",
    "        #                      'x0': 0,\n",
    "        #                      'x1': 1,\n",
    "        #                      'xref': 'x domain',\n",
    "        #                      'y0': y_pt,\n",
    "        #                      'y1': y_pt,\n",
    "        #                      'yref': 'y'\n",
    "        #                  },\n",
    "        #                  {\n",
    "        #                      'line': {'color': 'blue', 'width': 2},\n",
    "        #                      'type': 'line',\n",
    "        #                      'visible': True,\n",
    "        #                      'x0': x_pt,\n",
    "        #                      'x1': x_pt,\n",
    "        #                      'xref': 'x',\n",
    "        #                      'y0': 0,\n",
    "        #                      'y1': 1,\n",
    "        #                      'yref': 'y domain'\n",
    "        #                  }]\n",
    "        \n",
    "        \n",
    "        curv_ind = f'x={x_pt:.2f};y={y_pt:.2f}'\n",
    "        dash2_curvnum_select.unobserve(dash2_update_curvselect, 'value')\n",
    "        if curv_ind not in dash2_curvnum_select.options:\n",
    "            if dash2_curve_toggle.value == True:\n",
    "                dash2_curvnum_select.options += (curv_ind,)\n",
    "                dash2_curvnum_select.value = dash2_curvnum_select.options #+= (curv_ind,)\n",
    "                shape_list = []\n",
    "                for i, curv_ind in enumerate(dash2_curvnum_select.value):\n",
    "                    x_pt = float(curv_ind.split(';')[0].split('=')[1])#curve_dict[curv_ind]['x_pt']\n",
    "                    y_pt = float(curv_ind.split(';')[1].split('=')[1])#curve_dict[curv_ind]['y_pt']\n",
    "                    # print(curv_ind, x_pt, y_pt)\n",
    "                    shape_list += [{'line': {'color': color_list[i], 'width': 2}, 'type': 'line', \n",
    "                                        'x0': x_pt, 'x1': x_pt, 'y0': y_pt-ypt_len, 'y1': y_pt+ypt_len},\n",
    "                                       {'line': {'color': color_list[i], 'width': 2}, 'type': 'line', \n",
    "                                        'x0': x_pt-xpt_len, 'x1': x_pt+xpt_len, 'y0': y_pt, 'y1': y_pt}]\n",
    "                dash2_figdict['a'].layout.shapes = shape_list\n",
    "                \n",
    "            else:\n",
    "                dash2_curvnum_select.options = [curv_ind]\n",
    "                dash2_curvnum_select.value = [curv_ind]\n",
    "                dash2_figdict['a'].layout.shapes = [{'line': {'color': color_list[0], 'width': 2}, 'type': 'line', \n",
    "                                                     'x0': x_pt, 'x1': x_pt, 'y0': y_pt-ypt_len, 'y1': y_pt+ypt_len},\n",
    "                                                    {'line': {'color': color_list[0], 'width': 2}, 'type': 'line', \n",
    "                                                     'x0': x_pt-xpt_len, 'x1': x_pt+xpt_len, 'y0': y_pt, 'y1': y_pt}]\n",
    "        dash2_curvnum_select.observe(dash2_update_curvselect, 'value') \n",
    "        \n",
    "        dash2_update_data(None)\n",
    "        dash2_update_plot('all')\n",
    "        \n",
    "        # dash2_slide_x.unobserve(dash2_update_x,'value') #unobserve_all()#(dash2_update_x, 'value')\n",
    "        # dash2_slide_y.unobserve(dash2_update_y, 'value') #(dash2_update_y, 'value')\n",
    "        # dash2_slide_x.value = x_data[np.argmin(abs(x_data-x_pt))]       \n",
    "        # dash2_slide_y.value = y_data[np.argmin(abs(y_data-y_pt))]\n",
    "        # dash2_slide_x.observe(dash2_update_x, 'value')\n",
    "        # dash2_slide_y.observe(dash2_update_y, 'value')\n",
    "        \n",
    "        \n",
    "        \n",
    "    # if event.inaxes == ax2[0]:\n",
    "    #     slide_x2.value = event.xdata\n",
    "    #     slide_y2.value = event.ydata\n",
    "@dash2_output.capture()\n",
    "def dash2_save_click(change):\n",
    "    if dash2_save_text.value == '':\n",
    "        name_prefix = 'results'\n",
    "    else:\n",
    "        name_prefix = f'{dash2_save_text.value}'\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    dash2_outfilepath = f'{outputpath_forcevol}/{name_prefix}' #COMPLETE THIS! ALSO SAVE PLOTS!\n",
    "    name_suffix = f'{filekey}_{timestamp}'\n",
    "    \n",
    "    with pd.ExcelWriter(f'{dash2_outfilepath}_data_{name_suffix}.xlsx', mode=\"w\", engine=\"openpyxl\") as writer:\n",
    "        dash2_datadict['long'].to_excel(writer, sheet_name=\"Data\")\n",
    "    with pd.ExcelWriter(f'{dash2_outfilepath}_data_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "        dash2_datadict['param'].to_excel(writer, sheet_name=\"Parameter data\")\n",
    "    with pd.ExcelWriter(f'{dash2_outfilepath}_data_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "        dash2_datadict['summary'].to_excel(writer, sheet_name=\"Statistics\")\n",
    "    \n",
    "    combined_image = merge_plotly_figures([dash2_figdict['a'], dash2_figdict['b']], [2])\n",
    "    combined_image.save(f'{dash2_outfilepath}_spectroplot_{name_suffix}.png')\n",
    "    if dash2_plotupdate_check.value == True:\n",
    "        dash2_figdict['c'].savefig(f'{dash2_outfilepath}_correlationplot_{name_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    # dash2_figdict['a'].write_image(f'{dash2_outfilepath}_spectroplot.png')\n",
    "    # dash2_figdict['b'].write_image(f'{dash2_outfilepath}_correlationplot.png')\n",
    "    # dash4_update_data('save')\n",
    "    \n",
    "# @dash2_output.capture()\n",
    "# def response(change):\n",
    "#     print(change)\n",
    "     \n",
    "dash2_slide_x.observe(dash2_update_x, 'value')\n",
    "dash2_slide_y.observe(dash2_update_y, 'value')\n",
    "# dash2_slide_zrange.observe(dash2_update_zrange, 'value')\n",
    "dash2_slide_cb.observe(dash2_update_colorbar,'value')\n",
    "dash2_param_dropdown.observe(dash2_update_param, 'value')\n",
    "dash2_imgdir_button.observe(dash2_update_imgdir, 'value')\n",
    "dash2_specdir_select.observe(dash2_update_allplots, 'value')\n",
    "dash2_curvnum_select.observe(dash2_update_curvselect, 'value') \n",
    "dash2_figdict['a'].data[0].on_click(dash2_onclick)\n",
    "\n",
    "dash2_chan_select.observe(dash2_update_plotchan, 'value')\n",
    "\n",
    "dash2_spectrox_button.observe(dash2_update_plotchan, 'value')\n",
    "dash2_param_toggle.observe(dash2_update_plotcalc, 'value')\n",
    "dash2_grid_toggle.observe(dash2_update_grid, 'value')\n",
    "dash2_plotupdate_check.observe(dash2_update_allplots, 'value')\n",
    "# for dash2_dropi in dash2_unit_dropdown.values():\n",
    "#     dash2_dropi.observe(dash2_update_units, 'value')\n",
    "dash2_save_button.on_click(dash2_save_click)\n",
    "\n",
    "\n",
    "dash2_update_data(None)\n",
    "dash2_update_plotchan('all')\n",
    "# display(dash2_box1)\n",
    "# display(dash2_box2)\n",
    "display(dash2_box3)\n",
    "display(dash2_fig_tab)\n",
    "# display(dash2_box4)\n",
    "# display(dash2_figcout)\n",
    "# display(dash2_figdict['a'])\n",
    "# display(dash2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b97db-b10d-4e46-8adc-8f936651ef44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndimage\n",
    "test = data_dict['Amplitude'][f'Image {img_dir} with Forward Ramps']['data']\n",
    "# test2 = data_dict['Normal force'][f'Image {img_dir} with Forward Ramps']['data']\n",
    "# x_ind, y_ind = 64, 50\n",
    "x_ind, y_ind = 1,1\n",
    "# thresh=0.01 #fraction of total points\n",
    "filter_size=20\n",
    "# back_pts = 10\n",
    "# method = 'fit' #average, fit\n",
    "# max_percentile = 9\n",
    "change_factor = 20\n",
    "std_pts = 10\n",
    "test_x, test_y = test['Z'], test['ZZ'][:,y_ind,x_ind]\n",
    "# test_y_filt = ndimage.median_filter(test_y, size=filter_size) #filter\n",
    "amp_min, amp_max = np.mean(test_y[:std_pts]), np.mean(test_y[-std_pts:])\n",
    "amp_dev = np.std(test_y[:std_pts])\n",
    "ind1 = np.argmin(abs(test_y-(amp_min+(amp_dev*change_factor))))\n",
    "ind2 = np.argmin(abs(test_y-(amp_max-(amp_dev*change_factor))))\n",
    "ind_list = [ind1, ind2]\n",
    "ind_list.sort()\n",
    "# test2_x, test2_y = test2['Z'], test2['ZZ'][:,y_ind,x_ind]\n",
    "\n",
    "test_y_sobel = ndimage.sobel(test_y) #sobel transform\n",
    "# #this method works well when the jump in points is very fast, no points in between.\n",
    "n_data = len(test_x)\n",
    "# tol_ind = int(filter_size/4) #int(thresh*n_data) #tolerance\n",
    "# ind_max = np.argmax(test_y_sobel)\n",
    "# ind_min = np.argmin(test_y_sobel[:ind_max])\n",
    "# ind_min = np.argmin(test_y)\n",
    "# # # amp_sobel = test_y_filt_sobel\n",
    "# test_sobel = ndimage.sobel(test_y[ind_min:]) #sobel transform\n",
    "# # # amp_sobel = ndimage.sobel(test_y) #sobel transform\n",
    "# # # amp_sobel = ndimage.sobel(test_y_filt) #sobel transform\n",
    "# # # ind_max = np.argmax(amp_sobel)\n",
    "# ind_maxs = np.where(test_sobel>=np.percentile(test_sobel,max_percentile))[0]\n",
    "# print(ind_maxs)\n",
    "# # ind_maxs = np.arange(ind_maxs.min(), ind_maxs.max()+1,1)\n",
    "# # # testmin_x, testmin_y = test_x[ind_max], test_y[ind_max]\n",
    "# # # testmin_x, testmin_y = test_x[ind_maxs].mean(), test_y[ind_maxs].mean()\n",
    "# # # slope_avg = -amp_sobel[ind_maxs].mean()\n",
    "# # # # poly = np.poly1d([-amp_sobel[ind_max], testmin_y-(-amp_sobel[ind_max]*testmin_x)])\n",
    "# # # poly = np.poly1d([slope_avg, testmin_y-(slope_avg*testmin_x)])\n",
    "# if method == 'average' or len(ind_maxs)==1:\n",
    "#     slope_avg = -test_sobel[ind_maxs].mean()\n",
    "#     testmin_y = test_y[-1]#test_y[ind_min+ind_maxs].max()\n",
    "#     testmin_x = test_x[-1]#test_x[ind_min+np.argmin(abs(test_y[ind_min+ind_maxs]-testmin_y))]\n",
    "#     print(testmin_x, testmin_y)\n",
    "#     poly1 = np.poly1d([slope_avg, testmin_y-(slope_avg*testmin_x)])\n",
    "#     p2, res, rank, sing, rcond = np.polyfit(test_x[ind_min:], test_y[ind_min:], 1, full=True)\n",
    "#     poly2 = np.poly1d(p2)\n",
    "# elif method == 'fit':\n",
    "#     p1, res, rank, sing, rcond = np.polyfit(test_x[ind_min+ind_maxs], test_y[ind_min+ind_maxs], 1, full=True)\n",
    "#     poly1 = np.poly1d(p1)\n",
    "#     p2, res, rank, sing, rcond = np.polyfit(test_x[ind_min:], test_y[ind_min:], 2, full=True)    \n",
    "#     poly2 = np.poly1d(p2)\n",
    "#     test_x0, test_y0 = test_x[-1], poly2(test_x[-1])\n",
    "#     p2_tan = [2*p2[0]*test_x0+p2[1], test_y0-(p2[1]*test_x0)-(2*p2[0]*test_x0**2)]\n",
    "#     poly3 = np.poly1d(p2_tan)\n",
    "    # print(p2, p2_tan)\n",
    "\n",
    "# fit_x_all = np.linspace(test_x[0], test_x[-1], n_data*10)\n",
    "# fit_y_all = poly1(fit_x_all)\n",
    "# fit_y_all2 = poly2(fit_x_all)\n",
    "# fit_y_all3 = poly3(fit_x_all)\n",
    "# fitind_min = np.argmin(abs(fit_y_all-test_y.min()))\n",
    "# fitind_max = np.argmin(abs(fit_y_all-test_y.max()))\n",
    "# fit_x = fit_x_all[fitind_min:fitind_max]\n",
    "# fit_y = fit_y_all[fitind_min:fitind_max]\n",
    "# fit_y2 = fit_y_all2[fitind_min:fitind_max]\n",
    "# fit_y3 = fit_y_all3[fitind_min:fitind_max]\n",
    "plt.plot(test_x, test_y,'r.')\n",
    "# plt.plot(test_x, test_y_filt,'g:')\n",
    "plt.plot(test_x, [test_y[ind_list[0]]]*n_data, ':b')\n",
    "plt.plot(test_x, [test_y[ind_list[1]]]*n_data, ':b')\n",
    "# plt.plot(test_x, test_y_sobel,'y')\n",
    "# plt.plot(test_x[ind_min], test_y[ind_min], 'wo')\n",
    "# plt.plot(test_x[ind_min:ind_min-back_pts:-1].mean(), test_y[ind_min:ind_min-back_pts:-1].mean(),'bo')\n",
    "# plt.plot(test_x[ind_min+1], test_y[ind_min+1],'go')\n",
    "# plt.vlines(x=test2_x[ind_min], ymin=-0.1, ymax=0.1, color='y')\n",
    "# plt.vlines(x=test_x[ind_max], ymin=-0.1, ymax=0.1, color='r')\n",
    "# plt.plot(test_x[:ind_min+tol_ind], amp_sobel,'b')\n",
    "# plt.plot(test_x[ind_min:], test_sobel,'b')\n",
    "# plt.plot(test_x, test_y_filt,'y')\n",
    "# # plt.plot(test_x[ind_min-3:ind_min+3], poly(test_x[ind_min-3:ind_min+3]),'g')\n",
    "# plt.plot(fit_x, fit_y,'y')\n",
    "# plt.plot(fit_x, fit_y2,'g')\n",
    "# plt.plot(fit_x, fit_y3,'b')\n",
    "# plt.xlim(0,15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead33dcc-c052-4cd4-9122-b3828c2d83ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(px.colors)\n",
    "# px.colors.qualitative.swatches()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d5bfb-a2be-4fc3-9d34-7772ea35b400",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compare image segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f105226-a800-4e3b-bbd7-1c20ac8bdcdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dir = 'Forward' #initial image direction\n",
    "n_clusters = 3 #number of clusters\n",
    "nbins = 100 #number of bins for histograms\n",
    "cp_min = 1 #min percentile range of data shown in plots\n",
    "cp_max = 99 #max percentile range of data showm in plots\n",
    "spectro_hist_type = 'histogram' #'histogram', 'line' choose histogram type for spectro hist plot\n",
    "spectro_hist_cols = ['Amplitude', 'Excitation frequency',  'Normal force'] #'Normal deflection', 'Phase', 'True Amplitude', 'True Phase'\n",
    "flatten_chan = ['Topography'] #list of channels to apply flatten\n",
    "\n",
    "# choose the figure font\n",
    "font_dict=dict(family='Arial', size=18)#, color='white')\n",
    "font_dict_b=dict(family='Arial', size=12) #font for corr plot\n",
    "color_list = px.colors.qualitative.Plotly\n",
    "dash3_figdict = {'a': '', 'b': '', 'c': '', 'd': '', 'e': ''} \n",
    "\n",
    "#topography\n",
    "# dash2_figa = go.FigureWidget()\n",
    "img_data = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                       unit_dict=unit_dict)\n",
    "if 'Topography' in flatten_chan: #flatten channel\n",
    "    img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "# img_data = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "dash3_figa = plotly_heatmap(x=img_data['X'],\n",
    "                            y=img_data['Y'],\n",
    "                            z_mat=img_data['Z'], style='full', font_dict=font_dict)\n",
    "dash3_figa.data[0].coloraxis = 'coloraxis1'\n",
    "# dash2_figdict['a'].add_trace(dash2_figa.data[0])\n",
    "dash3_figdict['a'] = go.FigureWidget(dash3_figa)\n",
    "\n",
    "\n",
    "dash3_figdict['a'].update_layout(coloraxis1=dict(colorscale=cm_afmhot,#cmin=68500, cmax=69600,\n",
    "                                 colorbar=dict(#len=0.6, x=0.65, y=1, \n",
    "                                               thickness=15, #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                 )),\n",
    "                                 xaxis = dict(range=[xmin,xmax]),\n",
    "                                 yaxis = dict(range=[ymin,ymax]),\n",
    "                                 # font=font_dict,  # font formatting\n",
    "                                 # template='plotly_dark',\n",
    "                                  # plot_bgcolor='black',  # background color\n",
    "                                  height=500, width=600, title_text=\"\",\n",
    "                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "                                  showlegend=False)\n",
    "# dash2_figdict['b'].update_layout(font=font_dict,  # font formatting\n",
    "#                                  template='plotly_dark',\n",
    "#                                  plot_bgcolor='black',  # background color\n",
    "#                                  height=500, width=1000, title_text=\"\",\n",
    "#                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "#                                  showlegend=False)\n",
    "\n",
    "# dash2_figb_axdict = {} #dictionary of y axis\n",
    "# dash2_figb_tracedict = {'calc':[]} #dictionary of index in FigureWidget.data for each plotted lines (other than vline/hline)\n",
    "\n",
    "labels_selected = list(range(n_clusters))\n",
    "label_data = tsf.segment_kmeans(img_data, n_clusters)\n",
    "colorscale = create_discrete_colorscale(n_clusters, color_list)\n",
    "dash3_figb = plotly_heatmap(x=img_data['X'],\n",
    "                            y=img_data['Y'], #color = colorscale,\n",
    "                            z_mat=label_data, style='full', font_dict=font_dict, opacity=0.7)\n",
    "# dash3_figb.data[0].coloraxis = 'coloraxis'\n",
    "# dash3_figb.data[0].colorscale = [[0,'red'], [1,'blue']]#color_list[:n_clusters]]\n",
    "dash3_figb.data[0].colorbar = dict(#len=0.6, x=0.65, y=1, \n",
    "                                     #tick0=0,\n",
    "                                     dtick=1,\n",
    "                                    # tickvals=[0,1,2,3],\n",
    "                                     # ticktext=[0,1,2],\n",
    "                                     thickness=15, #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                 )\n",
    "dash3_figb.data[0].coloraxis = 'coloraxis2'\n",
    "# dash2_figdict['a'].add_trace(dash2_figa.data[0])\n",
    "dash3_figdict['b'] = go.FigureWidget(dash3_figa)\n",
    "# dash3_figdict['b'].add_trace(dash3_figa.data[0])\n",
    "dash3_figdict['b'].add_trace(dash3_figb.data[0])\n",
    "# dash3_figdict['b'].add_traces(dash3_figb)\n",
    "\n",
    "dash3_figdict['b'].update_layout(coloraxis1=dict(colorscale=cm_afmhot, showscale=False),\n",
    "                                 coloraxis2=dict(colorscale=colorscale,\n",
    "                                                 colorbar=dict(dtick=1,thickness=15)\n",
    "                                                ),\n",
    "                                 xaxis = dict(range=[xmin,xmax]),\n",
    "                                 yaxis = dict(range=[ymin,ymax]),\n",
    "                                 # font=font_dict,  # font formatting\n",
    "                                 # template='plotly_dark',\n",
    "                                  # plot_bgcolor='black',  # background color\n",
    "                                  height=500, width=600, title_text=\"\",\n",
    "                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "                                  showlegend=False)\n",
    "\n",
    "dash3_figdict['c'] = go.FigureWidget()\n",
    "# dash3_figdict['e'] = plotly_pairplot_initax(fig=None, num=len(param_list), font_dict=font_dict)\n",
    "\n",
    "# dash3_figdict['c'] = plotly_subplots_init(rows=len(param_list),cols=2, width=1000, height=450*len(param_list), \n",
    "#                                           font_dict=font_dict, horizontal_spacing=0.1, \n",
    "#                                           subplot_titles = np.concatenate([[key, ''] for key in  param_list]))\n",
    "\n",
    "#widgets\n",
    "dash3_imgdir_button = widgets.ToggleButtons(options=['Forward', 'Backward'])\n",
    "dash3_mainchan_dropdown = widgets.Dropdown(options=param_list, value='Topography',\n",
    "                                           layout=widgets.Layout(width='200px'))\n",
    "dash3_chan_select = widgets.SelectMultiple(options=param_list, value=param_list,\n",
    "                                          description='params')\n",
    "dash3_label_select = widgets.SelectMultiple(options=labels_selected, value=labels_selected,\n",
    "                                          description='labels')\n",
    "dash3_histupdate_check = widgets.Checkbox(value=False, description='Update histograms')\n",
    "dash3_save_button = widgets.Button(description='Save')\n",
    "dash3_save_text = widgets.Text(value='', placeholder='File name to save')\n",
    "dash3_output = widgets.Output()\n",
    "dash3_box1 = widgets.VBox([dash3_imgdir_button, dash3_mainchan_dropdown, dash3_histupdate_check,\n",
    "                          widgets.HBox([dash3_save_text, dash3_save_button])])\n",
    "dash3_box2 = widgets.HBox([dash3_box1, dash3_label_select, dash3_chan_select])\n",
    "dash3_figaout = widgets.Output()\n",
    "dash3_figbout = widgets.Output()\n",
    "dash3_figcout = widgets.Output()\n",
    "dash3_figdout = widgets.Output()\n",
    "dash3_figeout = widgets.Output()\n",
    "dash3_tableout = widgets.Output()\n",
    "dash3_figbox = widgets.HBox([dash3_figaout, dash3_figbout])\n",
    "dash3_fig_tab = widgets.Tab()\n",
    "dash3_fig_tab.children = [dash3_figbox, dash3_tableout, dash3_figcout, dash3_figeout, dash3_figdout, dash3_output]\n",
    "dash3_fig_tab.titles = ['segmentation', 'summary', 'histograms', 'correlation plots', 'spectro histograms', 'debug']\n",
    "\n",
    "dash3_datadict = {}\n",
    "\n",
    "@dash3_output.capture()\n",
    "def dash3_plot_update(change):\n",
    "    global label_data\n",
    "    img_dir = dash3_imgdir_button.value\n",
    "    channel_top = dash3_mainchan_dropdown.value\n",
    "    if channel_top == 'Topography':        \n",
    "        img_data = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                                         unit_dict=unit_dict)\n",
    "        # img_data = data_dict[channel_top][f'Image {img_dir} with Forward Ramps']\n",
    "    else:\n",
    "        img_data = get_imgdata(param_data_dict[channel_top][img_dir], channel_top, unit_dict=unit_dict)\n",
    "        # img_data = param_data_dict[channel_top][img_dir]\n",
    "    \n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "    dash3_figdict['a'].data[0].z = img_data['Z']\n",
    "    \n",
    "    vmin = np.percentile(img_data['Z'], 1, method='midpoint')\n",
    "    vmax = np.percentile(img_data['Z'], 99, method='midpoint')\n",
    "    dash3_figdict['a'].layout.coloraxis1.cmin=vmin\n",
    "    dash3_figdict['a'].layout.coloraxis1.cmax=vmax\n",
    "    \n",
    "    label_data = tsf.segment_kmeans(img_data, n_clusters)\n",
    "    # colorscale = create_discrete_colorscale(n_clusters, color_list)\n",
    "    dash3_figb = plotly_heatmap(x=img_data['X'],\n",
    "                                y=img_data['Y'], #color = colorscale,\n",
    "                                z_mat=label_data, style='full', font_dict=font_dict)\n",
    "    # dash3_figb.data[0].coloraxis = 'coloraxis'\n",
    "    # dash3_figb.data[0].colorscale = [[0,'red'], [1,'blue']]#color_list[:n_clusters]]\n",
    "    dash3_figb.data[0].colorbar = dict(#len=0.6, x=0.65, y=1, \n",
    "                                         #tick0=0,\n",
    "                                         dtick=1,\n",
    "                                        # tickvals=[0,1,2,3],\n",
    "                                         # ticktext=[0,1,2],\n",
    "                                         thickness=15, #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                     )\n",
    "    dash3_figb.data[0].coloraxis = 'coloraxis2'\n",
    "    # dash2_figdict['a'].add_trace(dash2_figa.data[0])\n",
    "    # dash3_figdict['b'] = go.FigureWidget(dash3_figa)\n",
    "    # dash3_figdict['b'].add_trace(dash3_figa.data[0])\n",
    "    dash3_figdict['b'].data[0].z = img_data['Z']\n",
    "    dash3_figdict['b'].layout.coloraxis1.cmin=vmin\n",
    "    dash3_figdict['b'].layout.coloraxis1.cmax=vmax\n",
    "    dash3_figdict['b'].data[1].z = dash3_figb.data[0].z\n",
    "    \n",
    "    dash3_histplot_update(None)\n",
    "\n",
    "@dash3_output.capture()\n",
    "def dash3_histplot_update(change):\n",
    "    dash3_update_summary(None) #update summary table\n",
    "    if dash3_histupdate_check.value == True:\n",
    "        img_dir = dash3_imgdir_button.value\n",
    "        labels_selected = dash3_label_select.value\n",
    "        param_selected = dash3_chan_select.value\n",
    "        # paramval_dict = {'parameter':[], 'direction':[], 'label':[], 'value mean':[], 'value median':[], 'value std':[]}\n",
    "        # dash3_figdict['c'].data = []\n",
    "        # dash3_figdict['c'].data = []\n",
    "        #TODO: OPTIMIZE. AVOID RECREATING FIGUREWIDGET EVERYTIME!\n",
    "        dash3_figdict['c'] = plotly_subplots_init(rows=len(param_selected),cols=2, width=1000, height=450*len(param_selected),\n",
    "                                                  fig=dash3_figdict['c'], font_dict=font_dict, \n",
    "                                                  horizontal_spacing=0.1, vertical_spacing=75/(450*len(param_selected)), \n",
    "                                                  subplot_titles = np.concatenate([[key, ''] for key in  param_selected]))\n",
    "        dash3_figdict['c'].update_annotations(font=font_dict)\n",
    "        for i in range(1, len(param_selected)): #share x_y axis of images\n",
    "            dash3_figdict['c'].update_layout({f\"xaxis{(2*i)+1}\": {\"matches\": 'x'},\n",
    "                                              f\"yaxis{(2*i)+1}\": {\"matches\": 'y'}})\n",
    "        # i = 1\n",
    "        # labels_selected\n",
    "        colors_selected = [color_list[k] for k in labels_selected]\n",
    "        \n",
    "        param_data_long = {}\n",
    "        for i, key in enumerate(param_selected):\n",
    "            if key == 'Topography':\n",
    "                img_data_i = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                                         unit_dict=unit_dict)\n",
    "                unit_text = unit_dict[key] #unit name\n",
    "            else:\n",
    "                img_data_i = get_imgdata(param_data_dict[key][img_dir], key, unit_dict=unit_dict)\n",
    "                unit_text = parse_paramunit(key, unit_dict, evaluate=False)\n",
    "            \n",
    "            if key in flatten_chan: #flatten channel\n",
    "                img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "            param_data_long[key] = img_data_i['Z'].flatten()\n",
    "            # if key == 'Topography':\n",
    "            #     img_data_i = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "            # else:\n",
    "            #     img_data_i = param_data_dict[key][img_dir]\n",
    "            dash3_figdict['c'].update_layout({f'xaxis{2*(i+1)}': dict(title_text=f\"{key} [{unit_text}]\", \n",
    "                                                                      title_font=font_dict, title_standoff=5)})\n",
    "            dash3_figc_hm_i = plotly_heatmap(x=img_data_i['X'],\n",
    "                                            y=img_data_i['Y'],\n",
    "                                            z_mat=img_data_i['Z'], style='full', font_dict=font_dict)\n",
    "            dash3_figc_hm_i.data[0].coloraxis = f'coloraxis{i+1}'\n",
    "            # if len(dash3_figdict['c'].data) < 2*len(param_selected):\n",
    "            dash3_figdict['c'].add_trace(dash3_figc_hm_i.data[0], row=i+1, col=1) #data[0]\n",
    "            # else:\n",
    "            #     dash3_figdict['c'].data[2*(i-1)].z = dash3_figc_hm_i.data[0].z\n",
    "            # data_clustered_i = {'label':[], 'value':[]}\n",
    "            vmin = np.percentile(img_data_i['Z'],cp_min)\n",
    "            vmax = np.percentile(img_data_i['Z'],cp_max)\n",
    "            # val_list = []\n",
    "            vmin_list, vmax_list = [], []\n",
    "            for j, lab_j in enumerate(labels_selected):\n",
    "                val_j = img_data_i['Z'][label_data==lab_j].flatten()\n",
    "                vmin_j = np.percentile(val_j,cp_min)\n",
    "                vmax_j = np.percentile(val_j,cp_max)\n",
    "                # vmin_list.append(vmin_j)\n",
    "                # vmax_list.append(vmax_j)\n",
    "                # val_list.append(val_j)\n",
    "                # value_list.append(val_j)\n",
    "                # label_list.append([j]*len(val_j))\n",
    "                dash3_figc_hist_i = go.Histogram(x=val_j, marker=dict(color=colors_selected[j]), \n",
    "                                                 xbins=dict(start=vmin_j,end=vmax_j,size=(vmax_j-vmin_j)/nbins),#nbinsx=nbins,\n",
    "                                                 name=lab_j, opacity=0.8,showlegend=False)#) if i==0 else False)\n",
    "                dash3_figdict['c'].add_trace(dash3_figc_hist_i, row=i+1, col=2)\n",
    "\n",
    "                # paramval_dict['parameter'].append(key)\n",
    "                # paramval_dict['direction'].append(img_dir)\n",
    "                # paramval_dict['label'].append(lab_j)\n",
    "                # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "                # paramval_dict['value median'].append(np.median(val_j))\n",
    "                # paramval_dict['value std'].append(np.std(val_j))\n",
    "            # data_clustered_i = {'label': np.concatenate(label_list), 'value': np.concatenate(value_list)}\n",
    "            # dash3_figc_hist_i = px.histogram(data_clustered_i, color='label', nbins=100)#df, x=\"total_bill\", color=\"sex\")\n",
    "            # for j, _ in enumerate(labels_selected):\n",
    "                # dash3_figdict['c'].add_trace(dash3_figc_hist_i.data[j], row=i, col=2) #data[0]\n",
    "                # dash3_figdict['c'].add_trace(dash3_figc_hist_i.data[1], row=i, col=2) #data[0]\n",
    "            # val_all = np.concatenate(val_list)\n",
    "            # vmin = np.percentile(val_all,1)\n",
    "            # vmax = np.percentile(val_all,99)\n",
    "            dash3_figdict['c'].update_layout({f'coloraxis{i+1}': dict(colorscale=cm_afmhot, showscale=False,cmin=vmin, cmax=vmax,\n",
    "                                                                    # colorbar=dict(len=0.26, x=0.25, y=0.25*(i), thickness=10,\n",
    "                                                                    #               orientation='h',yanchor='bottom',\n",
    "                                                                    #               xanchor='center',thicknessmode=\"pixels\" #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                                                    # )\n",
    "                                                                   )},\n",
    "                                            )\n",
    "            # dash3_figdict['c'].layout[f'xaxis{i*2}'].range=[min(vmin_list), max(vmax_list)]\n",
    "            # i += 1\n",
    "\n",
    "        dash3_figcout.clear_output(wait=True)\n",
    "        with dash3_figcout:\n",
    "            display(dash3_figdict['c']) \n",
    "\n",
    "        param_data_long['label'] = label_data.flatten()  \n",
    "        param_data_longdf = pd.DataFrame(param_data_long)\n",
    "        param_data_longdf = param_data_longdf[param_data_longdf['label'].isin(labels_selected)].reset_index(drop=True)\n",
    "        # dash3_fig3 = plotly_pairplot(data=param_data_longdf, cols = param_selected, \n",
    "        #                              hue='label', diag_kind = 'hist', font_dict=font_dict, line_style='markers')\n",
    "        dash3_figdict['e'] = seaborn_pairplot(param_data_longdf, cols=param_selected, hue='label', palette = colors_selected,\n",
    "                                              diag_kind='kde', plot_kws=dict(s=10, linewidth=0.0), font_dict=font_dict_b)\n",
    "        for i, param_i in enumerate(param_selected):\n",
    "            vmin = np.percentile(param_data_longdf[param_i],cp_min)\n",
    "            vmax = np.percentile(param_data_longdf[param_i],cp_max)\n",
    "            dash3_figdict['e'].axes[i].set_xlim((vmin,vmax))\n",
    "            dash3_figdict['e'].axes[i*len(param_selected)].set_ylim((vmin,vmax))\n",
    "        # dash3_figdict['e'] = fig2html(dash3_fig3, plot_type='plotly', width=1200, height=1200, pad=0.1)\n",
    "        # dash3_figdict['e'] = dash3_fig3.to_image(format=\"png\")\n",
    "        dash3_figeout.clear_output(wait=True)\n",
    "        with dash3_figeout:\n",
    "            display(dash3_figdict['e'])\n",
    "        plt.close('all')\n",
    "            \n",
    "        #statistics of spectroscopy calculated parameters\n",
    "        # paramval_groupcols = ['channel', 'parameter', 'file']\n",
    "        # paramval_df = pd.DataFrame(paramval_dict)\n",
    "        # dash3_tableout.clear_output(wait=True)\n",
    "        # with dash3_tableout:\n",
    "        #     itables.show(paramval_df)\n",
    "        # paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "        # paramval_summary = paramval_grouped['value'].agg(['mean', 'std']).reset_index()\n",
    "        # if change != None and \n",
    "        if change == None or change.owner.description != 'params':\n",
    "            label_data_copy = label_data.copy()\n",
    "            mask = np.isin(label_data_copy, labels_selected, invert=True)\n",
    "            label_data_copy[mask] = -999999\n",
    "            output_dict = combine_forcevol_data(data=data_dict, channel_list=spectro_hist_cols, \n",
    "                                                label_data=label_data_copy, unit_dict=unit_dict)\n",
    "            dash3_figdict['d'] = plot_forcevol_histogram(output_dict[img_dir], plot_type=spectro_hist_type,\n",
    "                                                         bins=len(z_data), prange=100, psat=90)\n",
    "            dash3_figdout.clear_output(wait=True)\n",
    "            with dash3_figdout:\n",
    "                display(HTML(dash3_figdict['d']))\n",
    "                \n",
    "\n",
    "@dash3_output.capture()\n",
    "def dash3_update_summary(change):\n",
    "    labels_selected = dash3_label_select.value\n",
    "    img_dir = dash3_imgdir_button.value\n",
    "    paramval_dict = {'x': [], 'y': [], 'parameter':[], 'direction':[], 'label':[], 'value': []} #'value mean':[], 'value median':[], 'value std':[]}\n",
    "    # for img_dir_i in ['Forward', 'Backward']:\n",
    "    for param_i in param_list:\n",
    "        if param_i == 'Topography':\n",
    "            img_data_i = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                                     unit_dict=unit_dict)\n",
    "            unit_text = unit_dict[param_i] #unit name\n",
    "        else:\n",
    "            img_data_i = get_imgdata(param_data_dict[param_i][img_dir], param_i, unit_dict=unit_dict)\n",
    "            unit_text = parse_paramunit(param_i, unit_dict, evaluate=False)\n",
    "        if param_i in flatten_chan: #flatten channel\n",
    "            img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "        # if param_i == 'Topography':\n",
    "        #     img_data_i = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "        # else:\n",
    "        #     img_data_i = param_data_dict[param_i][img_dir]\n",
    "        for j, lab_j in enumerate(labels_selected):\n",
    "            val_j = img_data_i['Z'][label_data==lab_j].flatten().tolist()\n",
    "            xy_j = np.argwhere(label_data==lab_j).tolist()#.flatten().tolist()\n",
    "            x_val_j = [x_data[kx] for kx, _ in xy_j]\n",
    "            y_val_j = [y_data[ky] for _, ky in xy_j]\n",
    "            val_jnum = len(val_j)\n",
    "            paramval_dict['x'] += x_val_j\n",
    "            paramval_dict['y'] += y_val_j\n",
    "            paramval_dict['parameter'] += [f\"{param_i} [{unit_text}]\"]*val_jnum\n",
    "            paramval_dict['direction'] += [img_dir]*val_jnum\n",
    "            paramval_dict['label'] += [lab_j]*val_jnum\n",
    "            paramval_dict['value'] += val_j\n",
    "            # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "            # paramval_dict['value median'].append(np.median(val_j))\n",
    "            # paramval_dict['value std'].append(np.std(val_j))\n",
    "            # val_j = img_data_i['data']['Z'][label_data==lab_j].flatten()\n",
    "            # paramval_dict['parameter'].append(param_i)\n",
    "            # paramval_dict['direction'].append(img_dir)\n",
    "            # paramval_dict['label'].append(lab_j)\n",
    "            # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "            # paramval_dict['value median'].append(np.median(val_j))\n",
    "            # paramval_dict['value std'].append(np.std(val_j))\n",
    "    \n",
    "    paramval_df = pd.DataFrame(paramval_dict)\n",
    "    \n",
    "    # dash3_datadict['full'] = paramval_df #FIX THIS> FULL DATAFRAME CREATE\n",
    "    dash3_datadict['long'] = paramval_df.pivot(columns='parameter', \n",
    "                                               index=['direction', 'label', 'x', 'y'],\n",
    "                                               values='value').reset_index() \n",
    "    \n",
    "    paramval_groupcols = paramval_df.columns.drop(['value', 'x', 'y']).to_list()\n",
    "    paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "    paramval_summary = paramval_grouped['value'].agg(['mean', 'median', 'std']).reset_index()\n",
    "    dash3_datadict['summary'] = paramval_summary\n",
    "    \n",
    "    dash3_tableout.clear_output(wait=True)\n",
    "    with dash3_tableout:\n",
    "        itables.show(dash3_datadict['summary'])\n",
    "\n",
    "@dash3_output.capture()\n",
    "def dash3_label_update(change):\n",
    "    colorscale_filt = create_discrete_colorscale(n_clusters, color_list)\n",
    "    labels_selected = dash3_label_select.value\n",
    "    for lab in range(n_clusters):\n",
    "        if lab not in labels_selected:\n",
    "            colorscale_filt[2*lab][1] = 'rgba(0,0,0,0)'\n",
    "            colorscale_filt[2*lab+1][1] = 'rgba(0,0,0,0)'\n",
    "    dash3_figdict['b'].layout.coloraxis2.colorscale = colorscale_filt\n",
    "    dash3_histplot_update(None)\n",
    "\n",
    "@dash3_output.capture()\n",
    "def dash3_save_click(change):\n",
    "    img_dir = dash3_imgdir_button.value\n",
    "    if dash3_save_text.value == '':\n",
    "        name_prefix = 'results'\n",
    "    else:\n",
    "        name_prefix = f'{dash3_save_text.value}'\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    dash3_outfilepath = f'{outputpath_forcevol}/{name_prefix}' #COMPLETE THIS! ALSO SAVE PLOTS!\n",
    "    name_suffix = f'{filekey}_{img_dir}_{timestamp}'\n",
    "    combined_image = merge_plotly_figures([dash3_figdict['a'], dash3_figdict['b']], [2])\n",
    "    combined_image.save(f'{dash3_outfilepath}_segmentplot_{name_suffix}.png')\n",
    "    if dash3_histupdate_check.value == True:\n",
    "        dash3_figdict['c'].write_image(f'{dash3_outfilepath}_histplot_{name_suffix}.png')\n",
    "        html2png(dash3_figdict['d'], f'{dash3_outfilepath}_spectrohist_{name_suffix}.png')\n",
    "        dash3_figdict['e'].savefig(f'{dash3_outfilepath}_correlationplot_{name_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    with pd.ExcelWriter(f'{dash3_outfilepath}_segmentstats_{name_suffix}.xlsx', mode=\"w\", engine=\"openpyxl\") as writer:\n",
    "        dash3_datadict['long'].to_excel(writer, sheet_name=\"Data\")\n",
    "    with pd.ExcelWriter(f'{dash3_outfilepath}_segmentstats_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "        dash3_datadict['summary'].to_excel(writer, sheet_name=\"Statistics\")\n",
    "    # dash2_figdict['a'].write_image(f'{dash2_outfilepath}_spectroplot.png')\n",
    "    # dash2_figdict['b'].write_image(f'{dash2_outfilepath}_correlationplot.png')\n",
    "    # dash4_update_data('save')\n",
    "    \n",
    "\n",
    "# dash3_figdict['b'].data[0].showscale = False\n",
    "# dash3_figdict['b'].data[0].coloraxis = None\n",
    "# dash2_figdict['b'] = plotly_multiyplot_initax(fig=None, yvars=[chan_list[0]], yax_dict=dash2_figb_axdict,\n",
    "#                                               font_dict=font_dict, height=500, width=1000)\n",
    "# dash2_figdict['c'] = plotly_pairplot_initax(fig=None, num=len(chan_list), font_dict=font_dict)\n",
    "\n",
    "\n",
    "\n",
    "# files = ['interdigThiols_SitipDiam3Nm_0000']\n",
    "# filepath_i = folderpath + '/' + file_df.loc[(file_df.file==files[0])].iloc[0].loc['name']\n",
    "# test = wsxm_readchan(filepath_i, all_files=True, mute=True)\n",
    "# chan_data = test['Topography']['Forward']['data']\n",
    "# # amp_offset = np.atleast_2d(np.mean(amp_chan['Z'], axis=1)).T\n",
    "# # p, res, rank, sing, rcond = np.polyfit(amp_chan['X'], amp_chan['Z'].T, 1, full=True)\n",
    "# # amp_offset = np.array([np.poly1d(p[:,i])(amp_chan['X']) for i in range(p.shape[1])])\n",
    "# # amp_shifted = amp_chan['Z']-amp_offset\n",
    "# plt.pcolormesh(chan_data['Z'], cmap='afmhot')\n",
    "# plt.clim(vmin=np.percentile(chan_data['Z'],1),vmax=np.percentile(chan_data['Z'],99))\n",
    "# plt.show()\n",
    "\n",
    "# n_clusters = 3\n",
    "# chan_labels = tsf.segment_kmeans(chan_data, n_clusters)\n",
    "\n",
    "# plt.pcolormesh(chan_labels, cmap='afmhot')\n",
    "# plt.show()\n",
    "\n",
    "# data_clustered = {}\n",
    "# for i in range(n_clusters):\n",
    "#     data_clustered[i] = chan_data['Z'][chan_labels==i].flatten()  \n",
    "# sns.histplot(data=data_clustered)#, x=\"flipper_length_mm\", hue=\"species\")\n",
    "# plt.show()\n",
    "\n",
    "dash3_histplot_update(None)\n",
    "\n",
    "with dash3_figaout:\n",
    "    display(dash3_figdict['a'])\n",
    "with dash3_figbout:\n",
    "    display(dash3_figdict['b'])\n",
    "# with dash3_figcout:\n",
    "#     display(dash3_figdict['c']) \n",
    "    \n",
    "dash3_label_select.observe(dash3_label_update, 'value')\n",
    "dash3_mainchan_dropdown.observe(dash3_plot_update, 'value')\n",
    "dash3_chan_select.observe(dash3_histplot_update, 'value')\n",
    "dash3_imgdir_button.observe(dash3_plot_update, 'value')\n",
    "dash3_histupdate_check.observe(dash3_histplot_update, 'value')\n",
    "dash3_save_button.on_click(dash3_save_click)\n",
    "display(dash3_box2)\n",
    "display(dash3_fig_tab)\n",
    "# display(dash3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d012159f-9df2-4fa1-bd7c-513ebb3c85f8",
   "metadata": {},
   "source": [
    "### 3D plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311ac1e-41d8-4ca8-aac9-5762ea47f093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dir = 'Forward'\n",
    "flatten_chan = [] #'Topography'\n",
    "cp_min = 1 #min percentile colour range of data shown in plots\n",
    "cp_max = 99 #max percentile colour range of data showm in plots\n",
    "cmap_dict = {'cmap_name': 'Bluered', 'source': 'plotly', 'reverse': True} #colormap name (check matplotlib/plotly colourmaps)\n",
    "font_dict=dict(family='Arial', size=18)\n",
    "font_dict_axtick=dict(family='Arial', size=14) #for axis ticks\n",
    "\n",
    "dash5_figdict = {'3d': ''}\n",
    "\n",
    "img_data_3d = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                          unit_dict=unit_dict)\n",
    "if 'Topography' in flatten_chan: #flatten channel\n",
    "    img_data_3d['Z'] = tsf.flatten_line(img_data_3d, order=1)\n",
    "img_data_colour = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                              unit_dict=unit_dict)\n",
    "if 'Topography' in flatten_chan: #flatten channel\n",
    "    img_data_colour['Z'] = tsf.flatten_line(img_data_colour, order=1)\n",
    "unit_text = unit_dict['Topography']\n",
    "vmin = np.percentile(img_data_colour['Z'],cp_min)\n",
    "vmax = np.percentile(img_data_colour['Z'],cp_max)\n",
    "\n",
    "#create initial figure\n",
    "dash5_fig3d = plotly_3dplot(z_3d=img_data_3d['Z'], z_colour=img_data_colour['Z'], \n",
    "                            x=x_data, y=y_data, width=1000, height=600,\n",
    "                            aspectratio_z=0.3, nticks_z=4, nticks_x=6, nticks_y=6,\n",
    "                            font_dict=font_dict)\n",
    "dash5_figdict['3d'] = go.FigureWidget(dash5_fig3d)\n",
    "\n",
    "dash5_figdict['3d'].data[0].coloraxis = 'coloraxis1'\n",
    "dash5_figdict['3d'].layout.coloraxis1.cmin=vmin\n",
    "dash5_figdict['3d'].layout.coloraxis1.cmax=vmax\n",
    "dash5_figdict['3d'].update_layout(title=dict(text=f\"Topography [{unit_text}]\", font=font_dict),\n",
    "                                  coloraxis1=dict(colorscale=matplotlib_to_plotly(**cmap_dict),#cmin=68500, cmax=69600,\n",
    "                                                  colorbar=dict(len=0.7, x=0.9, y=0.5, thickness=15,\n",
    "                                                                orientation='v', xanchor='center', \n",
    "                                                                yanchor='middle', title=f\"Topography [{unit_text}]\",\n",
    "                                                               title_font=font_dict, title_side='right', tickfont=font_dict)),\n",
    "                                  scene=dict(xaxis=dict(title=dict(text=f\"X [{unit_dict['X']}]\", font=font_dict),\n",
    "                                                       tickfont=font_dict_axtick,),\n",
    "                                             yaxis=dict(title=dict(text=f\"Y [{unit_dict['Y']}]\", font=font_dict),\n",
    "                                                       tickfont=font_dict_axtick),\n",
    "                                             # xaxis_tickfont=font_dict,\n",
    "                                             # yaxis_tickfont=font_dict,\n",
    "                                             zaxis=dict(title=\"\", tickfont=font_dict_axtick,\n",
    "                                                        range=[vmin, vmax])#to avoid overlapping zeroes\n",
    "                                             # zaxis_tickvals = [0.2,0.4] #set tickvalues manually for z axis\n",
    "                                            )\n",
    "                                 )\n",
    "\n",
    "    \n",
    "dash5_imgdir_button = widgets.ToggleButtons(options=['Forward', 'Backward'])\n",
    "dash5_chan3d_select = widgets.Select(options=param_list, value=param_list[0],\n",
    "                                     description='3d')\n",
    "dash5_chancol_select = widgets.Select(options=param_list, value=param_list[0],\n",
    "                                     description='colour')\n",
    "dash5_slide_3drange = widgets.FloatRangeSlider(value=[1, 99],min=0, max=100, step=0.01,\n",
    "                                               description='3d range',readout=True)\n",
    "dash5_slide_colrange = widgets.FloatRangeSlider(value=[1, 99],min=0, max=100, step=0.01,\n",
    "                                               description='colour range',readout=True)\n",
    "dash5_box1 = widgets.VBox([dash5_imgdir_button, dash5_slide_3drange, dash5_slide_colrange])\n",
    "dash5_box2 = widgets.HBox([dash5_box1, dash5_chan3d_select, dash5_chancol_select])          \n",
    "dash5_output = widgets.Output()\n",
    "dash5_figout = widgets.Output()\n",
    "dash5_fig_tab = widgets.Tab()\n",
    "dash5_fig_tab.children = [widgets.HBox([dash5_figout]), dash5_output]\n",
    "dash5_fig_tab.titles = ['3D plot', 'debug']\n",
    "\n",
    "with dash5_figout:\n",
    "    display(dash5_figdict['3d'])\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_update_plot(change):\n",
    "    img_dir = dash5_imgdir_button.value\n",
    "    channel_3d = dash5_chan3d_select.value\n",
    "    channel_colour = dash5_chancol_select.value\n",
    "    #3d channel\n",
    "    if channel_3d == 'Topography':\n",
    "        img_data_3d = get_imgdata(data_dict[channel_3d][f'Image {img_dir} with Forward Ramps'], channel_3d,\n",
    "                               unit_dict=unit_dict)\n",
    "        unit_text_3d = unit_dict[channel_3d]            \n",
    "    else:\n",
    "        img_data_3d = get_imgdata(param_data_dict[channel_3d][img_dir], channel_3d,\n",
    "                               unit_dict=unit_dict)\n",
    "        unit_text_3d = parse_paramunit(channel_3d, unit_dict, evaluate=False)\n",
    "    #colour channel\n",
    "    if channel_3d in flatten_chan: #flatten channel\n",
    "        img_data_3d['Z'] = tsf.flatten_line(img_data_3d, order=1)\n",
    "\n",
    "    if channel_colour == 'Topography':\n",
    "        img_data_colour = get_imgdata(data_dict[channel_colour][f'Image {img_dir} with Forward Ramps'], channel_colour,\n",
    "                               unit_dict=unit_dict)\n",
    "        unit_text_color = unit_dict[channel_colour]  \n",
    "    else:\n",
    "        img_data_colour = get_imgdata(param_data_dict[channel_colour][img_dir], channel_colour,\n",
    "                               unit_dict=unit_dict)\n",
    "        unit_text_color = parse_paramunit(channel_colour, unit_dict, evaluate=False)\n",
    "    \n",
    "    if channel_colour in flatten_chan: #flatten channel\n",
    "        img_data_colour['Z'] = tsf.flatten_line(img_data_colour, order=1)\n",
    "    \n",
    "    if change.owner.description == '3d':\n",
    "        dash5_figdict['3d'].data[0].z = img_data_3d['Z']\n",
    "    elif change.owner.description == 'colour':\n",
    "        dash5_figdict['3d'].data[0].surfacecolor = img_data_colour['Z']\n",
    "    else: #when img_dir changed\n",
    "        dash5_figdict['3d'].data[0].z = img_data_3d['Z']\n",
    "        dash5_figdict['3d'].data[0].surfacecolor = img_data_colour['Z']\n",
    "    \n",
    "    zmin = np.percentile(img_data_3d['Z'], dash5_slide_3drange.value[0])\n",
    "    zmax = np.percentile(img_data_3d['Z'], dash5_slide_3drange.value[1])\n",
    "    \n",
    "    dash5_figdict['3d'].layout.scene.zaxis.range = [zmin, zmax]\n",
    "    \n",
    "    cmin = np.percentile(img_data_colour['Z'], dash5_slide_colrange.value[0])\n",
    "    cmax = np.percentile(img_data_colour['Z'], dash5_slide_colrange.value[1]) \n",
    "    \n",
    "    dash5_figdict['3d'].layout.coloraxis1.cmin = cmin\n",
    "    dash5_figdict['3d'].layout.coloraxis1.cmax = cmax\n",
    "    dash5_figdict['3d'].layout.coloraxis1.colorbar.title.text = f\"{channel_colour} [{unit_text_color}]\"\n",
    "    dash5_figdict['3d'].layout.title.text =  f\"{channel_3d} [{unit_text_3d}]\"\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_update_3drange(change):\n",
    "    fig_zdata = dash5_figdict['3d'].data[0].z\n",
    "    zmin = np.percentile(fig_zdata, dash5_slide_3drange.value[0])\n",
    "    zmax = np.percentile(fig_zdata, dash5_slide_3drange.value[1])\n",
    "    dash5_figdict['3d'].layout.scene.zaxis.range = (zmin, zmax)\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_update_colrange(change):\n",
    "    fig_coldata = dash5_figdict['3d'].data[0].surfacecolor\n",
    "    cmin = np.percentile(fig_coldata, dash5_slide_colrange.value[0])\n",
    "    cmax = np.percentile(fig_coldata, dash5_slide_colrange.value[1])\n",
    "    dash5_figdict['3d'].layout.coloraxis1.cmin = cmin\n",
    "    dash5_figdict['3d'].layout.coloraxis1.cmax = cmax\n",
    "    \n",
    "dash5_imgdir_button.observe(dash5_update_plot, 'value')\n",
    "dash5_chan3d_select.observe(dash5_update_plot, 'value')\n",
    "dash5_chancol_select.observe(dash5_update_plot, 'value')\n",
    "dash5_slide_3drange.observe(dash5_update_3drange, 'value')\n",
    "dash5_slide_colrange.observe(dash5_update_colrange, 'value')\n",
    "\n",
    "display(dash5_box2)\n",
    "display(dash5_fig_tab)\n",
    "# fig = go.Figure(data=[go.Surface(z=img_data_3d['Z'], surfacecolor=img_data_colour['Z'],\n",
    "#                                  x=x_data, y=y_data)])\n",
    "# fig.update_layout(title=channel_3d, autosize=False,\n",
    "#                   width=1100, height=700,\n",
    "#                   margin=dict(l=65, r=50, b=65, t=90),\n",
    "#                  scene = {\n",
    "#                         \"xaxis\": {\"nticks\": 20},\n",
    "#                         \"zaxis\": {\"nticks\": 4},\n",
    "#                         # 'camera_eye': {\"x\": 0, \"y\": -1, \"z\": 0.5},\n",
    "#                         \"aspectratio\": {\"x\": 1, \"y\": 1, \"z\": 0.2}\n",
    "#                  })\n",
    "# fig.update_xaxes(linecolor='red', showline=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464a71e-e7a7-4c13-8a38-776106152fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrodexceldata_df = pd.read_excel('data/20240626_glassspot1_0069_0081_0082_data_241113-173137.xlsx', sheet_name='Spectro data')\n",
    "# spectrodexceldata_df = pd.read_excel('data/20240626_glassspot1_0071_data_241113-181554.xlsx', sheet_name='Spectro data')\n",
    "display(spectrodexceldata_df)\n",
    "spectrodf_file_list = spectrodexceldata_df['file'].unique()\n",
    "print(spectrodf_file_list)\n",
    "spectrodexceldata_filt = spectrodexceldata_df.query(f\"`curve number`==5 and `file` == '{spectrodf_file_list[2]}'\")\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "sns.lineplot(data=spectrodexceldata_filt, x='z', y='Normal force', style='segment', color=colors[0], ax=ax, legend=True)\n",
    "# sns.lineplot(data=spectrodexceldata_filt, x='z', y='Amplitude-sample distance', style='file', color=colors[1], ax=ax, legend=False)\n",
    "# ax.plot(spectrodexceldata_filt['z'], spectrodexceldata_filt['True Amplitude'], '.-', color=colors[0])\n",
    "# # ax2 = ax.twinx()\n",
    "# ax.plot(spectrodexceldata_filt['z'], spectrodexceldata_filt['Amplitude-sample distance'], '-', color=colors[1])\n",
    "ax.axhline(0, linestyle=':', color='gray')\n",
    "ax.set_xlabel('Distance (nm)')\n",
    "ax.set_ylabel('Normal force (nN)')\n",
    "ax.set_xlim(-4.5,16.5)\n",
    "# ax.set_ylim(-1,15)\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.plot(spectrodexceldata_filt['z'], spectrodexceldata_filt['Frequency shift'], '.-', color=colors[2])\n",
    "# ax2.set_ylabel('Frequency shift (Hz)')\n",
    "# ax.spines['left'].set_color(colors[0])\n",
    "# ax.yaxis.label.set_color(colors[0])\n",
    "# ax.tick_params(axis='y', colors=colors[0])\n",
    "# ax2.spines['left'].set_color(colors[0])\n",
    "# ax2.yaxis.label.set_color(colors[2])\n",
    "# ax2.spines['right'].set_color(colors[2])\n",
    "# ax2.tick_params(axis='y', colors=colors[2])\n",
    "# fig.savefig(f'data/exptspectroplot_normforce_20240626_glassspot1_0082.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8318a-73fc-4b40-b57a-577deb53be4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SPECTROSCOPY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01805f0f-bbf6-46f1-8990-081b590045ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f78a4-b001-497a-8462-ba3d20a359bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties = ['Adhesion', 'Stiffness', 'Snap-in distance'] #, 'Slope-amp', 'True Slope-amp']\n",
    "plot_format = 'png' #png, svg, pdf #format to export plots\n",
    "              #'Growth rate', 'True Growth rate']\n",
    "# set_funcdict_kwargs(channel='True Amplitude',param='True Slope-amp',kwargs={'method':'minmax', 'num_pts':10, \n",
    "#                                                                             'change_factor':10, 'filter_size':5})\n",
    "# set_funcdict_kwargs(channel='Amplitude',param='Slope-amp',kwargs={'method':'minmax', 'num_pts':10, 'change_factor':10})\n",
    "set_funcdict_kwargs(channel='Normal deflection',param='Snap-in distance',kwargs={'method':'gradient', 'findmax': True, \n",
    "                                                                                 'zero': 'ini', 'back_pts': 50})\n",
    "\n",
    "dash4_corr_cols = ['Amplitude', 'Phase', 'Normal force', 'Excitation frequency'] #'True Amplitude', 'True Phase',\n",
    "dash4_color_var = 'file' #'file', 'segment' 'curve number' shows different colors for this parameter in corr plots\n",
    "dash4_errory_dict = {'Normal deflection': 'True Amplitude'} #set error bar channel corresponding to a channel\n",
    "\n",
    "# set EXTRA_CHANNEL_DICT for extra channel calculation parameters\n",
    "# set_extrachan_dict('Frequency shift', 'xc', 0)\n",
    "set_extrachan_dict('Frequency shift', 'ind_plot', 330)\n",
    "set_extrachan_dict('Frequency shift', 'make_plot', False)\n",
    "\n",
    "dash4_filebrowser_channels = ['Normal force', 'Amplitude'] #channels to display in file browser\n",
    "\n",
    "\n",
    "#TODO: ADD ABOVE TO DASH\n",
    "file_df =  dash0_filedict['full']\n",
    "# file_df_spectro = file_df[(file_df['type']=='1D') & (file_df['extension'] == '.curves')]\n",
    "# files_spectro = list(dict.fromkeys(file_df_spectro['file']))\n",
    "# files_spectro.sort()\n",
    "# chanlist_spectro = list(dict.fromkeys(file_df_spectro['channel'])) #unique channels\n",
    "# chanlist_spectro.sort()\n",
    "\n",
    "# files_ini = files_spectro[0]\n",
    "# filepath_ini = folderpath / file_df_spectro.loc[(file_df_spectro.file==files_ini)].iloc[0].loc['name']\n",
    "# spectro_data_ini = wsxm_readspectra(filepath_ini, all_files=True, mute=True, extra_channels=True)\n",
    "# chanlist_ini = list(spectro_data_ini.keys())\n",
    "# curves_ini = list(spectro_data_ini[chanlist_ini[0]]['curves'].keys())\n",
    "# chanlist_spectro = list(spectro_data_ini.keys())\n",
    "# chanlist_spectro.sort()\n",
    "\n",
    "\n",
    "#widgets\n",
    "# dash4_file_select = widgets.SelectMultiple(options=files_spectro, value=[files_ini], layout=widgets.Layout(width='auto', height='1000px'))\n",
    "# dash4_file_box = widgets.VBox([widgets.Label('files'), dash4_file_select])\n",
    "# dash4_chan_select = widgets.SelectMultiple(options=chanlist_ini, value=[chanlist_ini[0]])\n",
    "# dash4_chan_box = widgets.VBox([widgets.Label('channels'), dash4_chan_select])\n",
    "# dash4_curvnum_select = widgets.SelectMultiple(options=curves_ini, value=[curves_ini[0]])\n",
    "# dash4_curvnum_box = widgets.VBox([widgets.Label('curve num'), dash4_curvnum_select])\n",
    "dash4_specdir_select = widgets.SelectMultiple(options=['approach', 'retract', \n",
    "                                                       'X-Y components_1', 'X-Y components_2',\n",
    "                                                       'Amplitude_1', 'Amplitude_2'], value=['approach'])\n",
    "dash4_specdir_box = widgets.VBox([widgets.Label('direction'), dash4_specdir_select])\n",
    "dash4_spectrox_button = widgets.ToggleButtons(options=['x', 'd', 'z'], style={\"button_width\": \"30px\"})\n",
    "dash4_corrplotupdate_check = widgets.ToggleButton(value=False, description='Show corrplot',\n",
    "                                                 layout=widgets.Layout(width='auto'), style={\"button_width\": \"20px\"})\n",
    "dash4_recali_toggle = widgets.ToggleButton(value=False, description='Recalibrate', tooltip='Recalibrate normal deflection from stiffness slope for each curve',\n",
    "                                         layout=widgets.Layout(width='auto'), style={\"button_width\": \"20px\"})#button_style='')\n",
    "dash4_grid_toggle = widgets.ToggleButton(value=False, description='Show grid', tooltip='Show grid',\n",
    "                                         layout=widgets.Layout(width='auto'), style={\"button_width\": \"20px\"})#button_style='')\n",
    "dash4_param_toggle = widgets.ToggleButton(value=False, description='Show calc', tooltip='Show calc',\n",
    "                                          layout=widgets.Layout(width='auto'), style={\"button_width\": \"20px\"})#button_style='')\n",
    "dash4_save_button = widgets.Button(description='Save', tooltip='Save displayed tab or all tabs')\n",
    "dash4_updateplot_button = widgets.Button(description='LOAD', tooltip='Update plot based on selected files in file browser',\n",
    "                                        layout=widgets.Layout(height='auto'), style={\"button_height\": \"100px\", 'font_size':\"28px\"})\n",
    "dash4_save_text = widgets.Text(value='', placeholder='File name to save')\n",
    "dash4_saveall_check = widgets.Checkbox(value=True, description='all', indent=False,\n",
    "                                       layout=widgets.Layout(width='50px'))\n",
    "dash4_marker_toggle = widgets.ToggleButton(value=False, description='Show markers', tooltip='Show markers',\n",
    "                                          layout=widgets.Layout(width='auto'), style={\"button_width\": \"20px\"})#button_style='')\n",
    "dash4_marker_slider = widgets.FloatRangeSlider(value=[0.2, 0.8], min=0, max=1, step=0.001, description='', continuous_update=False, \n",
    "                                               orientation='horizontal', readout=False)\n",
    "\n",
    "\n",
    "#output widgets to display table/figures\n",
    "dash4_output = widgets.Output()\n",
    "dash4_tableout = widgets.Output()\n",
    "dash4_figaout = widgets.Output()\n",
    "dash4_figbout = widgets.Output()\n",
    "dash4_filebrowserout = widgets.Output()\n",
    "dash4_headerout = widgets.Output()\n",
    "\n",
    "#file browser table widget\n",
    "dash4_filedf = dash0_create_summarytable(view_channels=dash4_filebrowser_channels, data_type='1D')\n",
    "dash4_filedf_filtered = file_df[file_df['channel'] == dash4_filebrowser_channels[0]]\n",
    "dash4_filedf_merged = dash4_filedf.merge(dash4_filedf_filtered[['file', 'extension', 'name']], on='file', how='left')\n",
    "dash4_filebrowser = ITable(dash4_filedf_merged,  select=True, selected_rows=[0])\n",
    "\n",
    "#initial channel/curve list\n",
    "filepath_ini = folderpath / dash4_filedf_merged.iloc[0].loc['name']\n",
    "spectro_data_ini = wsxm_readspectra(filepath_ini, all_files=True, mute=True, extra_channels=True)\n",
    "chanlist_ini = list(spectro_data_ini.keys())\n",
    "curves_ini = list(spectro_data_ini[chanlist_ini[0]]['curves'].keys())\n",
    "\n",
    "dash4_chan_select = widgets.SelectMultiple(options=chanlist_ini, value=[chanlist_ini[0]])\n",
    "dash4_chan_box = widgets.VBox([widgets.Label('channels'), dash4_chan_select])\n",
    "dash4_curvnum_select = widgets.SelectMultiple(options=curves_ini, value=[curves_ini[0]])\n",
    "dash4_curvnum_box = widgets.VBox([widgets.Label('curve num'), dash4_curvnum_select])\n",
    "\n",
    "# dash4_unit_dropdown = {}\n",
    "# for chan_i in chanlist_spectro:\n",
    "#     chan_units_i = list(CALIB_DICT[chan_i].keys())\n",
    "#     dash4_unit_dropdown[chan_i] = widgets.Dropdown(options=chan_units_i,value=chan_units_i[0])\n",
    "\n",
    "#layout\n",
    "# dash4_unit_box = widgets.VBox([widgets.Label('unit')]+list(dash4_unit_dropdown.values()))\n",
    "dash4_box1 = widgets.HBox([dash4_chan_box, dash4_curvnum_box, dash4_specdir_box, dash4_updateplot_button])\n",
    "dash4_box2 = widgets.HBox([dash4_param_toggle, dash4_grid_toggle, dash4_corrplotupdate_check, dash4_recali_toggle, \n",
    "                           dash4_spectrox_button, dash4_save_text, dash4_save_button, dash4_saveall_check])\n",
    "dash4_box3 = widgets.HBox([dash4_marker_toggle, dash4_marker_slider])\n",
    "dash4_fig_tab = widgets.Tab()\n",
    "dash4_fig_tab.children = [widgets.HBox([dash4_figaout]), widgets.HBox([dash4_figbout]), dash4_tableout, \n",
    "                          dash4_filebrowserout, dash4_headerout, dash4_output]\n",
    "dash4_fig_tab.titles = ['spectroscopy plot', 'correlation plots', 'summary', 'File browser', 'header', 'debug']\n",
    "\n",
    "dash4_filebrowserout.clear_output(wait=True)\n",
    "with dash4_filebrowserout:\n",
    "    display(dash4_filebrowser)\n",
    "\n",
    "# choose the figure font\n",
    "font_dict = dict(family='Arial', size=18)#, color='white')\n",
    "font_dict_b =dict(family='Arial', size=12) #fonts for corr plot\n",
    "\n",
    "dash4_figa_axdict = {} #dictionary of y axis\n",
    "dash4_figa_tracedict = {'calc':[]} #dictionary of index in FigureWidget.data for each plotted lines (other than vline/hline)\n",
    "# dash4_figb_tracedict = {} #dictionary of traces used in statistics plot\n",
    "\n",
    "dash4_figdict = {'a': '', 'b': ''} \n",
    "# dash4_figdict['a'].update_layout(font=font_dict,  # font formatting\n",
    "#                                  template='plotly_dark',\n",
    "#                           plot_bgcolor='black',  # background color\n",
    "#                           height=500, width=1100, title_text=\"\",\n",
    "#                           margin=dict(t=50, b=0, l=0, r=0),\n",
    "#                           showlegend=False)\n",
    "\n",
    "dash4_figdict['a'] = plotly_multiyplot_initax(fig=None, yvars=[chanlist_ini[0]], yax_dict=dash4_figa_axdict,\n",
    "                                              unit_dict=unit_dict, font_dict=font_dict, \n",
    "                                              margin=dict(t=50, b=300, l=50, r=50),\n",
    "                                              height=800, width=1200, ypos=0.05)\n",
    "# dash4_figdict['b'] = plotly_pairplot_initax(fig=None, num=len(dash4_corr_cols), font_dict=font_dict)\n",
    "\n",
    "# curve_numall = []\n",
    "# spectro_data_long = {}\n",
    "# spectrodf_filt_list = []\n",
    "# spectroparam_dict = {} \n",
    "dash4_datadict = {}#{'full': None, 'long': None, 'param': None, 'paramdict': None, 'summary': None}\n",
    "# dash4_fileselect_state = False #to prevent multiple triggering of selection in filebrowser table\n",
    "\n",
    "# spectrodf_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_i, 'Normal force', \n",
    "#                                                     unit_dict=unit_dict_cali, properties=properties)\n",
    "# if spectroparam_i['Stiffness']['value'] != 0:\n",
    "#     defl_calib = 1/spectroparam_i['Stiffness']['value'] #cantilever deflection calibration in nm/V\n",
    "# else:\n",
    "#     defl_calib = 0\n",
    "#     print('Normal force slope is zero. Check: ', file_i)\n",
    "            \n",
    "@dash4_output.capture()\n",
    "def dash4_update_data(change):\n",
    "    \n",
    "    # files_spectro_filt = dash4_file_select.value\n",
    "    chan_selected = dash4_chan_select.value\n",
    "    filebrowser_selected = dash4_filebrowser.df.iloc[dash4_filebrowser.selected_rows]\n",
    "    # print('hey updatedata', dash4_filebrowser.selected_rows)\n",
    "    curve_numall = []\n",
    "    spectro_data_long = {}\n",
    "    spectrodf_filt_list = []\n",
    "    spectroparam_dict = {} \n",
    "    chanlist_spectro_all = [] \n",
    "    header_data = {}\n",
    "    \n",
    "    paramval_dict = {'file':[], 'channel':[], 'curve number': [], 'segment':[], 'parameter':[], 'value':[]}\n",
    "    # zmin, zmax = np.inf, -np.inf\n",
    "    for i, row_i in filebrowser_selected.iterrows():\n",
    "    # for i, file_i in enumerate(files_spectro_filt):\n",
    "        file_i = row_i['file']\n",
    "        filepath_i = folderpath / row_i['name'] \n",
    "        # print('file', file_i)\n",
    "        # filepath_i = folderpath / file_df_spectro.loc[(file_df_spectro.file==file_i)].iloc[0].loc['name']\n",
    "        spectro_data_i = wsxm_readspectra(filepath_i, all_files=True, mute=True, extra_channels=True)\n",
    "        chanlist_spectro_all += list(spectro_data_i.keys())\n",
    "        spectro_data_long[file_i] = {'file': []}\n",
    "        spectroparam_dict[file_i] = {}\n",
    "        # header_data[file_i] = {}\n",
    "        curvnum_list_file_i = []\n",
    "        for key_i in spectro_data_i.keys():\n",
    "            curvnum_list_file_i += list(spectro_data_i[key_i]['curves'].keys())\n",
    "        curvnum_list_file_unique = list(dict.fromkeys(curvnum_list_file_i))\n",
    "        # curvnum_list_file_unique.sort()\n",
    "        #sort if list is both string and numbers:\n",
    "        curvnum_list_file_unique = sorted(curvnum_list_file_unique, key = lambda x: (isinstance(x, str), x))\n",
    "        for curv_ind in curvnum_list_file_unique: #loop through all possible curves in file (includes all channels)\n",
    "            for chan_i in FUNC_DICT.keys(): #read channels in same order as FUNC_DICT for the curve data. Calculated params correctly\n",
    "                # print(file_i, chan_i, curv_ind)\n",
    "                if chan_i in spectro_data_i.keys():\n",
    "            # for chan_i in spectro_data_i.keys():\n",
    "                    curve_numlist = list(spectro_data_i[chan_i]['curves'].keys()) #number of curves\n",
    "                    # curve_numall += curve_numlist\n",
    "                    if chan_i not in spectro_data_long[file_i].keys():\n",
    "                        spectro_data_long[file_i]['file'] = []\n",
    "                        spectro_data_long[file_i]['curve number'] = []\n",
    "                        spectro_data_long[file_i]['segment'] = []\n",
    "                        spectro_data_long[file_i][chan_i] = []\n",
    "                        spectroparam_dict[file_i][chan_i] = {}\n",
    "                    if curv_ind in curve_numlist:\n",
    "                        curve_numall.append(curv_ind)\n",
    "                    # for curv_ind in curve_numlist: #FIX THIS! CURVE INDEX NEEDS TO BE LOOPED FIRST!\n",
    "                        spectro_data_chani = spectro_data_i[chan_i]['curves'][curv_ind]['data']\n",
    "                        spectro_header_chani = spectro_data_i[chan_i]['curves'][curv_ind]['header']\n",
    "                        if 'Gain in [Dynamic settings]' in spectro_header_chani.keys(): #update calibration for corresponding gain value\n",
    "                            update_gaincalib(gain_value=int(spectro_header_chani['Gain in [Dynamic settings]']))\n",
    "                        # unit_i = dash4_unit_dropdown[chan_i].value\n",
    "                        if 'Normal deflection' in spectro_data_i.keys():\n",
    "                            defl_data_i = spectro_data_i['Normal deflection']['curves'][curv_ind]['data']\n",
    "                            #recalibrate normal deflection for each data\n",
    "                            if dash4_recali_toggle.value == True:\n",
    "                                unit_dict_cali = {'Normal deflection': 'V', 'Normal force': 'V', 'Z': 'nm'} #CHECK 'Z\" units\n",
    "                                _, _ = wsxm_calcspectroparam(defl_data_i, 'Normal deflection', #calculate snapin first to get stiffness correctly\n",
    "                                                             unit_dict=unit_dict_cali, properties={'Snap-in distance'})\n",
    "                                normforce_data_i = spectro_data_i['Normal force']['curves'][curv_ind]['data']\n",
    "                                normforce_data_i, normforce_param_i = wsxm_calcspectroparam(normforce_data_i, 'Normal force', \n",
    "                                                                                            unit_dict=unit_dict_cali, \n",
    "                                                                                            properties=['Stiffness'])\n",
    "                                if normforce_param_i['Stiffness']['value'] != 0:\n",
    "                                    defl_calib_i = 1/normforce_param_i['Stiffness']['value'] #cantilever deflection calibration in nm/V\n",
    "                                    \n",
    "                                    set_calibdict_values(channel = 'Normal force', \n",
    "                                                         unit_kw = {'nN': {'factor': defl_calib_i * get_calibdict_value('Spring constant','N/m')['factor'],\n",
    "                                                                           'offset':0}\n",
    "                                                                    })\n",
    "                                    set_calibdict_values(channel = 'Normal deflection', \n",
    "                                                         unit_kw = {'nm': {'factor': defl_calib_i, 'offset':0},\n",
    "                                                                   })\n",
    "                                else:\n",
    "                                    defl_calib_i = 0\n",
    "                                    print('Normal force slope is zero. Check: ', file_i)                            \n",
    "                        else:\n",
    "                            defl_data_i = None\n",
    "                        spectrodf_filt_i, spectroparam_i = wsxm_calcspectroparam(spectro_data_chani, chan_i, unit_dict=unit_dict, \n",
    "                                                                                 calc_params=True, properties=properties, \n",
    "                                                                                 defl_data=defl_data_i) #CHECK CALIBRATION EVERYWHERE! TODO!\n",
    "                        spectroparam_dict[file_i][chan_i][curv_ind] = spectroparam_i\n",
    "                        if file_i not in header_data.keys(): #collate header data\n",
    "                            header_data[file_i] = spectro_header_chani\n",
    "                        #zero shift #TODO: make this more clean and general/modular\n",
    "                        if chan_i == 'Normal force':\n",
    "                            zero_shift_i = spectroparam_i['Adhesion']['zero']\n",
    "                        elif chan_i == 'Normal deflection':\n",
    "                            zero_shift_i = spectroparam_i['Snap-in distance']['zero']\n",
    "                            # print(zero_shift_i)\n",
    "                        else:\n",
    "                            zero_shift_i = 0\n",
    "                        # if chan_i == 'Amplitude-sample distance':\n",
    "                        #     print(spectrodf_filt_i)\n",
    "                        # zero_shift_i = spectroparam_i['Adhesion']['zero'] if chan_i == 'Normal force' else 0\n",
    "                        \n",
    "                        spectrodf_filt_i.loc[:,'y'] = spectrodf_filt_i.loc[:,'y']-zero_shift_i\n",
    "                        spectrodf_filt_i.insert(0,'channel',chan_i)\n",
    "                        spectrodf_filt_i.insert(0,'file',file_i)\n",
    "                        spectrodf_filt_i.insert(0,'curve number',curv_ind)                \n",
    "                        spectrodf_filt_list.append(spectrodf_filt_i)\n",
    "\n",
    "                        #collect data for pair plot and statistics for all channels\n",
    "                        spectro_data_long[file_i]['file'] += [file_i]*len(spectrodf_filt_i['y'])\n",
    "                        spectro_data_long[file_i]['curve number'] += [curv_ind]*len(spectrodf_filt_i['y'])\n",
    "                        spectro_data_long[file_i]['segment'] += spectrodf_filt_i['segment'].to_list()\n",
    "                        spectro_data_long[file_i][chan_i] += spectrodf_filt_i['y'].to_list()\n",
    "\n",
    "                        #collected calculated parameters for all channels\n",
    "                        for param_i, param_dict_i in spectroparam_i.items():\n",
    "                            segment_i = get_funcdict_kwargs(channel=chan_i, param=param_i)['segment']\n",
    "                            paramval_dict['file'].append(file_i)\n",
    "                            paramval_dict['channel'].append(chan_i)\n",
    "                            paramval_dict['curve number'].append(curv_ind)\n",
    "                            paramval_dict['segment'].append(segment_i)\n",
    "                            paramval_dict['parameter'].append(param_i)\n",
    "                            paramval_dict['value'].append(param_dict_i['value'])\n",
    "    \n",
    "    #update channel list based on what's present in files\n",
    "    chanlist_spectro = np.unique(chanlist_spectro_all).tolist()\n",
    "    chanlist_spectro.sort()\n",
    "    # chanlist_old = list(dash4_chan_select.value)\n",
    "    # print('hey', chan_selected, chanlist_spectro)\n",
    "    dash4_chan_select.unobserve(dash4_update_plotchan, 'value')\n",
    "    dash4_chan_select.options = chanlist_spectro\n",
    "    dash4_chan_select.index = (0,) #used to fix bug, now widget value can be updated after options update\n",
    "    if all(ind in chanlist_spectro for ind in chan_selected) == False:\n",
    "        dash4_chan_select.value = (chanlist_spectro[0],)\n",
    "    else:\n",
    "        dash4_chan_select.value = tuple(chan_selected) #set channel in case channel list changed\n",
    "    dash4_chan_select.observe(dash4_update_plotchan, 'value')\n",
    "    curvnum_old = list(dash4_curvnum_select.value)\n",
    "    # print('hey', curvnum_old, curve_numall)\n",
    "    dash4_curvnum_select.unobserve(dash4_update_allplots, 'value')\n",
    "    dash4_curvnum_select.options = list(dict.fromkeys(curve_numall))\n",
    "    dash4_curvnum_select.index = (0,) #used to fix bug, now widget value can be updated after options update\n",
    "    if all(ind in curve_numall for ind in curvnum_old) == False:\n",
    "        dash4_curvnum_select.value = (curve_numall[0],)\n",
    "    else:\n",
    "        dash4_curvnum_select.value = tuple(curvnum_old)\n",
    "    dash4_curvnum_select.observe(dash4_update_allplots, 'value')            \n",
    "\n",
    "    dash4_datadict['full'] = pd.concat(spectrodf_filt_list)\n",
    "    if 'd' in dash4_datadict['full'].columns: #CHECK THIS\n",
    "        x_extra_cols = ['z', 'd']\n",
    "    else:\n",
    "        x_extra_cols = []\n",
    "    dash4_datadict['long'] = dash4_datadict['full'].pivot_table(columns='channel', index=['file', 'curve number', 'segment', 'x'] + x_extra_cols,\n",
    "                                                                values='y', sort=False).reset_index()    \n",
    "    dash4_datadict['paramdict'] = spectroparam_dict\n",
    "    \n",
    "    #statistics of spectroscopy calculated parameters\n",
    "    paramval_groupcols = ['channel', 'parameter', 'file', 'segment']\n",
    "    paramval_df = pd.DataFrame(paramval_dict)\n",
    "    paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "    paramval_summary = paramval_grouped['value'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    dash4_datadict['param'] = paramval_df\n",
    "    dash4_datadict['summary'] = paramval_summary\n",
    "\n",
    "    # long_cols = []\n",
    "    # for long_col_i in dash4_corr_cols: #check if dash4_corr_cols exists in spectrolong_filt, only take those that do exist\n",
    "    #     if long_col_i in dash4_datadict['long'].columns:\n",
    "    #         long_cols.append(long_col_i)\n",
    "    # plotly_pairplot_initax(fig=dash4_figdict['b'], num=len(long_cols), font_dict=font_dict)\n",
    "    \n",
    "    dash4_tableout.clear_output()\n",
    "    with dash4_tableout:\n",
    "        itables.show(paramval_summary, paging=False)\n",
    "        itables.show(paramval_df)\n",
    "\n",
    "    header_series_list = []\n",
    "    for file_i, header_data_i in header_data.items():\n",
    "        header_series_list.append(pd.Series(header_data_i, name=file_i))    \n",
    "    header_data_merged = pd.concat(header_series_list, axis=1)\n",
    "    dash4_datadict['header'] = header_data_merged\n",
    "    \n",
    "    dash4_headerout.clear_output(wait=True)\n",
    "    with dash4_headerout:\n",
    "        display(ITable(dash4_datadict['header'], paging=False))\n",
    "    # if all([chan_i in dash4_chan_select.options for chan_i in chan_selected]) == False:\n",
    "    #     dash4_chan_select.value = [dash4_chan_select.options[0]]\n",
    "    # else:\n",
    "    #     dash4_chan_select.value = chan_selected #set channel in case channel list changed\n",
    "\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_update_plot(change):\n",
    "    # print('hey updateplot')\n",
    "    # files_selected = dash4_file_select.value\n",
    "    marker_visible = dash4_marker_toggle.value\n",
    "    files_selected = list(dash4_filebrowser.df.iloc[dash4_filebrowser.selected_rows]['file'])\n",
    "    chan_selected = dash4_chan_select.value\n",
    "    spec_dir = dash4_specdir_select.value\n",
    "    curv_ind = dash4_curvnum_select.value\n",
    "    calc_show = dash4_param_toggle.value\n",
    "    spectro_x = dash4_spectrox_button.value\n",
    "    \n",
    "    spectrodf_full = dash4_datadict['full']\n",
    "    spectro_longdf = dash4_datadict['long'] #pd.DataFrame(dash4_datadict['long'][list(dash4_file_select.value)[0]])\n",
    "    spectroparam_dict = dash4_datadict['paramdict']\n",
    "\n",
    "    #add error channels to spectrodf_filt if not in selected channel\n",
    "    chan_needed = list(chan_selected)\n",
    "    for key, val in dash4_errory_dict.items():\n",
    "        if key in chan_needed and val not in chan_needed:\n",
    "            chan_needed.append(val)\n",
    "    # print(chan_selected, chan_needed)\n",
    "    spectrodf_filt = spectrodf_full[(spectrodf_full['channel'].isin(chan_needed)) & (spectrodf_full['segment'].isin(spec_dir)) &\n",
    "                                   (spectrodf_full['curve number'].isin(curv_ind))]\n",
    "    spectrolong_filt = spectro_longdf[(spectro_longdf['segment'].isin(spec_dir)) & (spectro_longdf['curve number'].isin(curv_ind))]\n",
    "\n",
    "    # with dash4_figdict['a'].batch_update():\n",
    "    #update spectroscopy plot\n",
    "    plotly_multiyplot(fig=dash4_figdict['a'], yax_dict= dash4_figa_axdict, data=spectrodf_filt, \n",
    "                      color = 'file' if len(files_selected) > 1 else None,\n",
    "                      multiy_col='channel', yvars=chan_selected, x=spectro_x, y=\"y\", line_group=\"curve number\", \n",
    "                      symbol='file', hover_name=\"file\", line_dash=\"segment\", \n",
    "                      errory_dict = dash4_errory_dict, font_dict=font_dict, marker_size=1, line_width=2)\n",
    "\n",
    "    dash4_update_grid(None)\n",
    "    chanfirst = dash4_figdict['a'].layout.yaxis1.title.text.split('[')[0].strip()\n",
    "    spectrodf_filt_chanfirst = spectrodf_filt[(spectrodf_filt['channel'] == chanfirst)]\n",
    "    data_xrange = (spectrodf_filt_chanfirst[spectro_x].min(), spectrodf_filt_chanfirst[spectro_x].max())\n",
    "    data_yrange = (spectrodf_filt_chanfirst['y'].min(), spectrodf_filt_chanfirst['y'].max())\n",
    "    dash4_marker_initialize(data_xrange, data_yrange)\n",
    "    # print(chanfirst, data_xrange, data_yrange)\n",
    "    # print('thread before')\n",
    "    # threading.Timer(2, dash4_marker_initialize).start() # reinitialize markers\n",
    "    # print('thread after')\n",
    "    dash4_figdict['a'].update_layout(xaxis_title_text=f\"{SPECT_DICT[spectro_x]} [{unit_dict['Z']}]\",\n",
    "                                     xaxis_title_font=font_dict)\n",
    "    \n",
    "    if change != 'append':\n",
    "        dash4_figdict['a'].layout.shapes = []\n",
    "        dash4_figa_tracedict['calc'] = []\n",
    "    for file_i in files_selected:\n",
    "        for chan_i in chan_selected:\n",
    "            for curv_i in curv_ind:\n",
    "                try:\n",
    "                    spectroparam_i = spectroparam_dict[file_i][chan_i][curv_i]\n",
    "                except:\n",
    "                    print('ERROR', file_i, chan_i, curv_i)\n",
    "                    continue\n",
    "                #zero shift #TODO: make this more clean and general/modular\n",
    "                if chan_i == 'Normal force':\n",
    "                    zero_shift_i = spectroparam_i['Adhesion']['zero']\n",
    "                elif chan_i == 'Normal deflection':\n",
    "                    zero_shift_i = spectroparam_i['Snap-in distance']['zero']\n",
    "                    # dash4_figdict['a'].data[0].error_y = {'array': [1]*512}\n",
    "                else:\n",
    "                    zero_shift_i = 0\n",
    "                for param_i, param_dict_i in spectroparam_i.items():\n",
    "                    #plot parameter calculation lines, fits. Only plot if parameter calculated for selected segment\n",
    "                    if param_dict_i['segment'] in spec_dir: #CHECK THIS!                            \n",
    "                        if FUNC_DICT[chan_i][param_i]['plot type'] == 'line': #CHECK THIS!\n",
    "                            if len(param_dict_i['y']) != 0:\n",
    "                                plotly_dashedlines(plot_type='line', fig=dash4_figdict['a'], \n",
    "                                                   x=param_dict_i[spectro_x], y=param_dict_i['y']-zero_shift_i,\n",
    "                                                   yaxis=dash4_figa_axdict[chan_i], visible=calc_show, \n",
    "                                                   line_width=2, line_dash='dot') #'solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'\n",
    "                            # dash4_figdict['a'].add_trace(go.Scatter(x=param_dict_i['x'], y=param_dict_i['y']-zero_shift_i,\n",
    "                            #                                         mode='lines', yaxis=dash4_figa_axdict[chan_i],\n",
    "                            #                                         line_dash=\"dash\", line_color=\"white\", line_width=3,\n",
    "                            #                                        visible=calc_show))\n",
    "                                dash4_figa_tracedict['calc'].append(len(dash4_figdict['a'].data)-1)\n",
    "                        else:\n",
    "                            for paramtype_i, ptype_i in FUNC_DICT[chan_i][param_i]['plot type'].items():\n",
    "                                plotly_dashedlines(plot_type=ptype_i, fig=dash4_figdict['a'], \n",
    "                                                   x=param_dict_i[paramtype_i], y=param_dict_i[paramtype_i]-zero_shift_i,\n",
    "                                                   yaxis=dash4_figa_axdict[chan_i], visible=calc_show, line_width=2, line_dash='solid')\n",
    "                                # if ptype_i == 'hline':\n",
    "                                #     dash4_figdict['a'].add_hline(y=param_dict_i[paramtype_i]-zero_shift_i,\n",
    "                                #                                  yref=dash4_figa_axdict[chan_i],secondary_y=True,\n",
    "                                #                                  line_dash=\"dash\", line_color=\"white\", line_width=3,\n",
    "                                #                                 visible=calc_show)\n",
    "                                # elif ptype_i == 'vline': #ADD OTHER PLOT TYPES HERE TODO!\n",
    "                                #     dash4_figdict['a'].add_vline(x=param_dict_i[paramtype_i],\n",
    "                                #                                  line_dash=\"dash\", line_color=\"white\", line_width=3,\n",
    "                                #                                 visible=calc_show)\n",
    "    \n",
    "    dash4_figaout.clear_output(wait=True)\n",
    "    with dash4_figaout: \n",
    "        display(dash4_figdict['a'])  \n",
    "     \n",
    "    #don't update statistics plot if only channel or specro specific widget values changed\n",
    "    if change in ['all']:\n",
    "        # long_cols = list(spectrolong_filt.columns)\n",
    "        # long_cols.remove('file')\n",
    "        # long_cols.remove('curve number')\n",
    "        # long_cols.remove('segment')\n",
    "        # long_cols.remove('x')\n",
    "        # long_cols.sort()\n",
    "        # itables.show(spectrolong_filt)\n",
    "        long_cols = []\n",
    "        for long_col_i in dash4_corr_cols: #check if dash4_corr_cols exists in spectrolong_filt, only take those that do exist\n",
    "            if long_col_i in spectrolong_filt.columns:\n",
    "                long_cols.append(long_col_i)\n",
    "        if dash4_corrplotupdate_check.value == True:\n",
    "            # plotly_pairplot(fig=dash4_figdict['b'], data=spectrolong_filt, cols = long_cols, \n",
    "            #                 hue='file', diag_kind = 'hist', font_dict=font_dict)\n",
    "            dash4_figdict['b'] = seaborn_pairplot(spectrolong_filt, cols=long_cols, hue=dash4_color_var, \n",
    "                                                  diag_kind='kde', plot_kws=dict(s=10, linewidth=0.0), font_dict=font_dict_b)\n",
    "            \n",
    "            dash4_figbout.clear_output(wait=True)\n",
    "            with dash4_figbout:\n",
    "                display(dash4_figdict['b'])\n",
    "            plt.close('all')\n",
    "        # dash4_figdict['b'] = go.FigureWidget(dash4_figb)\n",
    "\n",
    "    if marker_visible == True:\n",
    "        dash4_marker_update(None)\n",
    "        # dash4_calc_markerfunc() #calculate marker functions (e.g. slope)\n",
    "\n",
    "\n",
    "    \n",
    "@dash4_output.capture()\n",
    "def dash4_update_file(change):\n",
    "    # print('hey updatefile')\n",
    "    # dash4_filebrowser.unobserve(dash4_update_file, 'selected_rows')\n",
    "    # dash4_fileselect_state = True\n",
    "    dash4_update_data(None)\n",
    "    dash4_update_plot('all')\n",
    "    # time.sleep(2)\n",
    "    # dash4_fileselect_state = False\n",
    "        \n",
    "    # dash4_filebrowser.observe(dash4_update_file, 'selected_rows')\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_update_plotchan(change):\n",
    "    # print('hey plotchan')\n",
    "    chan_selected = dash4_chan_select.value\n",
    "    plotly_multiyplot_initax(fig=dash4_figdict['a'], yvars=chan_selected, yax_dict=dash4_figa_axdict, \n",
    "                             unit_dict=unit_dict, font_dict=font_dict, ypos=0.05)\n",
    "    if change == 'all':\n",
    "        dash4_update_plot('all')\n",
    "    else:\n",
    "        chan_old = change.old\n",
    "        chan_new = change.new\n",
    "        if all(c in chan_new for c in chan_old) == False:\n",
    "            dash4_update_plot('reset')\n",
    "        else:\n",
    "            dash4_update_plot('append')\n",
    "    \n",
    "@dash4_output.capture()\n",
    "def dash4_update_plotcalc(change):\n",
    "    # print('hey plotcalc')\n",
    "    calc_show = change.new #dash4_param_toggle.value\n",
    "    for i, data in enumerate(dash4_figdict['a'].data):\n",
    "        if i in dash4_figa_tracedict['calc']:\n",
    "            dash4_figdict['a'].data[i].visible = calc_show\n",
    "    \n",
    "    for i, shape in enumerate(dash4_figdict['a'].layout.shapes):\n",
    "        dash4_figdict['a'].layout.shapes[i].visible = calc_show\n",
    "        \n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_update_allplots(change):\n",
    "    # print('hey allplot')\n",
    "    dash4_update_plot('all')\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_update_grid(change):\n",
    "    if dash4_grid_toggle.value == True:\n",
    "        dash4_figdict['a'].update_layout(yaxis_showgrid=True, yaxis_zeroline=True,\n",
    "                                         xaxis_showgrid=True, xaxis_zeroline=True)\n",
    "                                        \n",
    "        # dash4_figdict['a'].layout.plot_bgcolor=None\n",
    "    else:\n",
    "        dash4_figdict['a'].update_layout(yaxis_showgrid=False, yaxis_zeroline=False,\n",
    "                                         xaxis_showgrid=False, xaxis_zeroline=False)\n",
    "                                        \n",
    "        # dash4_figdict['a'].layout.plot_bgcolor='black'\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_save_click(change):\n",
    "    if dash4_save_text.value == '':\n",
    "        name_prefix = 'results'\n",
    "    else:\n",
    "        name_prefix = f'{dash4_save_text.value}'\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    dash4_outfilepath = outputpath / 'Specroscopy' #COMPLETE THIS! ALSO SAVE PLOTS!\n",
    "    name_suffix = f'{timestamp}'\n",
    "    \n",
    "    # timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    \n",
    "    param_datakey = 'param with marker' if 'param with marker' in dash4_datadict.keys() else 'param'\n",
    "    summary_datakey = 'summary with marker' if 'summary with marker' in dash4_datadict.keys() else 'summary'\n",
    "    \n",
    "    # dash4_outfilepath = f'{outputpath}/spectroscopy_results_{timestamp}' #COMPLETE THIS! ALSO SAVE PLOTS!\n",
    "    if dash4_saveall_check.value == True or dash4_fig_tab.selected_index == 2: #same summary data\n",
    "        with pd.ExcelWriter(dash4_outfilepath / f'{name_prefix}_data_{name_suffix}.xlsx', mode=\"w\", engine=\"openpyxl\") as writer:\n",
    "            dash4_datadict[param_datakey].to_excel(writer, sheet_name=\"Data\")\n",
    "        with pd.ExcelWriter(dash4_outfilepath / f'{name_prefix}_data_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "            dash4_datadict[summary_datakey].to_excel(writer, sheet_name=\"Statistics\")\n",
    "        with pd.ExcelWriter(dash4_outfilepath / f'{name_prefix}_data_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "            dash4_datadict['header'].to_excel(writer, sheet_name=\"Header\")\n",
    "        with pd.ExcelWriter(dash4_outfilepath / f'{name_prefix}_data_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "            dash4_datadict['long'].to_excel(writer, sheet_name=\"Spectro data\")\n",
    "    if dash4_saveall_check.value == True or dash4_fig_tab.selected_index == 0: #save spectroscopy plot\n",
    "        dash4_figdict['a'].write_image(dash4_outfilepath / f'{name_prefix}_spectroplot_{name_suffix}.{plot_format}', scale=4)\n",
    "    if dash4_corrplotupdate_check.value == True and (dash4_saveall_check.value == True or dash4_fig_tab.selected_index == 1): #save corr plot\n",
    "        dash4_figdict['b'].savefig(dash4_outfilepath / f'{name_prefix}_correlationplot_{name_suffix}.{plot_format}', dpi=300, bbox_inches='tight')\n",
    "    # dash4_update_data('save')\n",
    "\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_marker_initialize(data_xrange, data_yrange):\n",
    "    # print('ini')\n",
    "    # padding = 0.06\n",
    "    marker_slider_range = dash4_marker_slider.value\n",
    "    marker_visible = dash4_marker_toggle.value\n",
    "    # xaxis_range = dash4_figdict['a'].layout.xaxis.range\n",
    "    # print(xaxis_range)\n",
    "    # xaxis_rangediff = xaxis_range[1]-xaxis_range[0]\n",
    "    xaxis_rangediff_true = data_xrange[1] - data_xrange[0] #xaxis_rangediff/(1+(2*padding))\n",
    "    xaxis_rangenew1 = data_xrange[0] #xaxis_range[0] + (padding*xaxis_rangediff_true)\n",
    "    # xaxis_rangenew2 = xaxis_range[1] - (padding*xaxis_rangediff_true)\n",
    "    marker1_xini = xaxis_rangenew1 + (marker_slider_range[0]*xaxis_rangediff_true)\n",
    "    marker2_xini = xaxis_rangenew1 + (marker_slider_range[1]*xaxis_rangediff_true)\n",
    "    # yaxis_range = dash4_figdict['a'].layout.yaxis.range\n",
    "    # yaxis_rangediff_true = (yaxis_range[1]-yaxis_range[0])/(1+(2*padding))\n",
    "    # yaxis_rangenew1 = yaxis_range[0] + (padding*yaxis_rangediff_true)\n",
    "    # yaxis_rangenew2 = yaxis_range[1] - (padding*yaxis_rangediff_true)\n",
    "    # yaxis_rangenew = (yaxis_rangenew1, yaxis_rangenew2)\n",
    "    dash4_figdict['a'].add_scatter(x=[marker1_xini, marker1_xini], y=data_yrange, mode='lines', line=dict(color='white'), \n",
    "                                   name='marker 1', showlegend=False, visible=marker_visible)\n",
    "    dash4_figdict['a'].add_scatter(x=[marker2_xini, marker2_xini], y=data_yrange, mode='lines', line=dict(color='white'), \n",
    "                                   name='marker 2', showlegend=False, visible=marker_visible)\n",
    "\n",
    "    #marker calculation curves\n",
    "    files_selected = list(dash4_filebrowser.df.iloc[dash4_filebrowser.selected_rows]['file'])\n",
    "    spec_dir = dash4_specdir_select.value\n",
    "    curv_ind = dash4_curvnum_select.value\n",
    "    i = 0\n",
    "    for file_i in files_selected:\n",
    "        for curv_i in curv_ind:\n",
    "            for spec_dir_i in spec_dir:\n",
    "                dash4_figdict['a'].add_scatter(x=[], y=[], mode='lines', line=dict(color='white'),\n",
    "                                               name=f'marker_linefit_{i}', showlegend=False, visible=marker_visible) #linear fit\n",
    "                i += 1\n",
    "    # print('oni')\n",
    "\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_marker_update(change):\n",
    "    marker_slider_range = dash4_marker_slider.value\n",
    "    padding = 0.06\n",
    "    xaxis_range = dash4_figdict['a'].layout.xaxis.range\n",
    "    xaxis_rangediff = xaxis_range[1]-xaxis_range[0]\n",
    "    xaxis_rangediff_true = xaxis_rangediff/(1+(2*padding))\n",
    "    xaxis_rangenew1 = xaxis_range[0] + (padding*xaxis_rangediff_true)\n",
    "    # xaxis_rangenew2 = xaxis_range[1] - (padding*xaxis_rangediff_true)\n",
    "    # marker_slider_range.sort()\n",
    "    for i in dash4_figdict['a'].data:\n",
    "        if i.name == 'marker 1':\n",
    "            marker1_x = xaxis_rangenew1 + (marker_slider_range[0]*xaxis_rangediff_true)\n",
    "            i.x = [marker1_x, marker1_x]\n",
    "        if i.name == 'marker 2':\n",
    "            marker2_x = xaxis_rangenew1 + (marker_slider_range[1]*xaxis_rangediff_true)\n",
    "            i.x = [marker2_x, marker2_x]\n",
    "    \n",
    "    dash4_calc_markerfunc() #calculate marker functions (e.g. slope)\n",
    "\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_marker_visibility(change):\n",
    "    marker_visible = dash4_marker_toggle.value\n",
    "    files_selected = list(dash4_filebrowser.df.iloc[dash4_filebrowser.selected_rows]['file'])\n",
    "    spec_dir = dash4_specdir_select.value\n",
    "    curv_ind = dash4_curvnum_select.value\n",
    "    number_of_fitlines = len(files_selected) * len(curv_ind) * len(spec_dir)\n",
    "    for i in dash4_figdict['a'].data:\n",
    "        if i.name in ['marker 1', 'marker 2']:\n",
    "            i.visible = marker_visible\n",
    "        if i.name.startswith('marker_linefit'):\n",
    "            if int(i.name.split('_')[-1]) < number_of_fitlines:\n",
    "                i.visible = marker_visible\n",
    "            else:\n",
    "                i.visible = False\n",
    "    if marker_visible == True:\n",
    "        dash4_calc_markerfunc() #calculate marker functions (e.g. slope)\n",
    "    else:\n",
    "        dash4_tableout.clear_output(wait=True)\n",
    "        with dash4_tableout:\n",
    "            display(ITable(dash4_datadict['summary'], paging=False))\n",
    "            display(ITable(dash4_datadict['param']))\n",
    "\n",
    "@dash4_output.capture()\n",
    "def dash4_calc_markerfunc():\n",
    "    for i in dash4_figdict['a'].data:\n",
    "        if i.name == 'marker 1':\n",
    "            marker1_x = i.x[0]\n",
    "        if i.name == 'marker 2':\n",
    "            marker2_x = i.x[1]\n",
    "    \n",
    "    # print(marker1_x, marker2_x)\n",
    "    \n",
    "    files_selected = list(dash4_filebrowser.df.iloc[dash4_filebrowser.selected_rows]['file'])\n",
    "    # chan_selected = dash4_chan_select.value\n",
    "    spec_dir = dash4_specdir_select.value\n",
    "    curv_ind = dash4_curvnum_select.value\n",
    "    spectro_x = dash4_spectrox_button.value\n",
    "    marker_visible = dash4_marker_toggle.value\n",
    "    fit_order = 1\n",
    "\n",
    "    chanfirst = dash4_figdict['a'].layout.yaxis1.title.text.split('[')[0].strip()\n",
    "    spectrodf_full = dash4_datadict['full']\n",
    "    spectrodf_filt = spectrodf_full[(spectrodf_full['channel'] == chanfirst) & (spectrodf_full['segment'].isin(spec_dir)) &\n",
    "                                       (spectrodf_full['curve number'].isin(curv_ind))]\n",
    "    paramval_dict = {'file':[], 'channel':[], 'curve number': [], 'segment': [], 'parameter':[], 'value':[]}\n",
    "    j = 0\n",
    "    for file_i in files_selected:\n",
    "        for curv_i in curv_ind:\n",
    "            for spec_dir_i in spec_dir:\n",
    "                spectrodf_filt = spectrodf_full[(spectrodf_full['file'] == file_i) & (spectrodf_full['channel'] == chanfirst) & \n",
    "                                        (spectrodf_full['segment'] == spec_dir_i) & (spectrodf_full['curve number'] == curv_i)]\n",
    "                spectrodf_markerfilt = spectrodf_filt[spectrodf_filt[spectro_x].between(marker1_x, marker2_x)]\n",
    "                xdata, ydata = spectrodf_markerfilt[spectro_x], spectrodf_markerfilt['y']\n",
    "                if len(xdata) == 0: #skip empty data\n",
    "                    continue\n",
    "                else:\n",
    "                    p, res, rank, sing, rcond = np.polyfit(xdata, ydata, fit_order, full=True) #2nd order fit \n",
    "                    poly1 = np.poly1d(p)\n",
    "                    xdata_fit, ydata_fit = xdata, poly1(xdata)\n",
    "                    for i in dash4_figdict['a'].data:\n",
    "                        if i.name == f'marker_linefit_{j}':\n",
    "                            i.x = xdata_fit\n",
    "                            i.y = ydata_fit\n",
    "                            break\n",
    "    \n",
    "                    j += 1\n",
    "                    # dash4_figdict['a'].add_scatter(x=xdata_fit, y=ydata_fit, mode='lines', line=dict(color='white'), \n",
    "                    #                                name='marker_linefit', showlegend=False, visible=marker_visible)\n",
    "                    # print(p[0], p[1], spec_dir_i)\n",
    "                    # display(spectrodf_markerfilt)\n",
    "    \n",
    "                    paramval_dict['file'].append(file_i)\n",
    "                    paramval_dict['channel'].append(chanfirst)\n",
    "                    paramval_dict['curve number'].append(curv_i)\n",
    "                    paramval_dict['segment'].append(spec_dir_i)\n",
    "                    paramval_dict['parameter'].append('Slope (marker)')\n",
    "                    paramval_dict['value'].append(p[0])\n",
    "\n",
    "    paramval_df = pd.DataFrame(paramval_dict)\n",
    "\n",
    "    paramval_df_merged = pd.concat([dash4_datadict['param'], paramval_df])\n",
    "    dash4_datadict['param with marker'] = paramval_df_merged\n",
    "\n",
    "    #statistics of spectroscopy calculated parameters\n",
    "    paramval_groupcols = ['channel', 'parameter', 'file', 'segment']\n",
    "    paramval_df = pd.DataFrame(paramval_dict)\n",
    "    paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "    paramval_summary = paramval_grouped['value'].agg(['mean', 'std']).reset_index()\n",
    "    paramval_summary_merged = pd.concat([dash4_datadict['summary'], paramval_summary])\n",
    "    dash4_datadict['summary with marker'] = paramval_summary_merged\n",
    "    \n",
    "    dash4_tableout.clear_output(wait=True)\n",
    "    with dash4_tableout:\n",
    "        display(ITable(paramval_summary_merged, paging=False))\n",
    "        display(ITable(paramval_df_merged))\n",
    "\n",
    "dash4_chan_select.observe(dash4_update_plotchan, 'value')\n",
    "# dash4_file_select.observe(dash4_update_file, 'value')\n",
    "dash4_specdir_select.observe(dash4_update_allplots, 'value')\n",
    "dash4_curvnum_select.observe(dash4_update_allplots, 'value')\n",
    "dash4_param_toggle.observe(dash4_update_plotcalc, 'value')\n",
    "dash4_grid_toggle.observe(dash4_update_grid, 'value')\n",
    "dash4_spectrox_button.observe(dash4_update_plotchan, 'value')\n",
    "dash4_corrplotupdate_check.observe(dash4_update_allplots, 'value')\n",
    "dash4_recali_toggle.observe(dash4_update_file, 'value')\n",
    "# for dash4_dropi in dash4_unit_dropdown.values():\n",
    "#     dash4_dropi.observe(dash4_update_allplots, 'value')\n",
    "dash4_save_button.on_click(dash4_save_click)\n",
    "dash4_updateplot_button.on_click(dash4_update_file)\n",
    "# dash4_filebrowser.observe(dash4_update_file) #, 'selected_rows')\n",
    "dash4_marker_slider.observe(dash4_marker_update, 'value')\n",
    "dash4_marker_toggle.observe(dash4_marker_visibility, 'value')\n",
    "\n",
    "dash4_update_data(None)\n",
    "dash4_update_plotchan('all')\n",
    "\n",
    "# import threading\n",
    "# threading.Timer(2.0, dash4_marker_initialize).start()\n",
    "# dash4_marker_initialize()\n",
    "\n",
    "display(dash4_box1)\n",
    "display(dash4_box2)\n",
    "display(dash4_box3)\n",
    "display(dash4_fig_tab)\n",
    "# display(dash4_filebrowserout)\n",
    "# display(dash4_file_box)\n",
    "# display(dash4_figaout)\n",
    "# display(dash4_figbout)\n",
    "# display(dash4_tableout)\n",
    "# display(dash4_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097ef3c-45e6-4b89-b4dc-432cf34faaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "data_x = dash4_figdict['a'].data[0].x\n",
    "data_y = dash4_figdict['a'].data[0].y\n",
    "# print(np.flip(data_x), np.flip(data_y))\n",
    "tck = interpolate.splrep(np.flip(data_x), np.flip(data_y), s=200)\n",
    "data_y_smooth = interpolate.splev(data_x, tck, der=0)\n",
    "# data_y_smooth = interpolate.BSpline(*tck)(data_x)\n",
    "data_y_grad = interpolate.splev(data_x, tck, der=1)#np.gradient(data_y, data_x)\n",
    "# dash4_figdict['a'].data[0].y = data_y_grad\n",
    "# dash4_figdict['a'].add_trace(go.Scatter(x=data_x, y=data_y_smooth, name=\"second trace\"))\n",
    "# dash4_figdict['a'].add_trace(go.Scatter(x=data_x, y=data_y_grad, name=\"second trace\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af140fdc-223f-4766-9425-a7438aebc643",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash4_figdict['a'].layout.xaxis.range = 0.4, 0.8\n",
    "dash4_figdict['a'].layout.yaxis1.fixedrange = False\n",
    "# dash4_figdict['a'].layout.yaxis1.autorange=True\n",
    "# dash4_figdict['a'].layout.yaxis1.range = -0.02, 0\n",
    "# dash4_figdict['a'].layout.yaxis2.range = -1500, 3000\n",
    "# dash4_figdict['a'].layout.yaxis3.range = -80, -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a8a83-9715-412f-9b50-424dd7c7062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dash4_figdict['a'].data[0].y\n",
    "t[dash4_figdict['a'].data[0].y > 972] = 972\n",
    "t1 = np.array(t)\n",
    "dash4_figdict['a'].data[0].y = np.linspace(0,1,len(t))\n",
    "dash4_figdict['a'].data[0].y = t1 #np.linspace(0,1,len(t))\n",
    "# dash4_figdict['a'].data[0].x = np.linspace(0,1,len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480b1c1-736e-4d7c-aed9-015a7c00f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash4_figdict['a'].layout.yaxis1.range, dash4_figdict['a'].layout.yaxis2.range, dash4_figdict['a'].layout.yaxis3.range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15b804-805d-4c16-9d94-c8f766f98dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash4_figdict['a'].layout.yaxis1.range, dash4_figdict['a'].layout.yaxis2.range , dash4_figdict['a'].layout.yaxis3.range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d3c544-2094-40dc-9eb6-b7aabedd0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customize plot using low-level plotly figurewidget functions\n",
    "\n",
    "# px.colors.qualitative.swatches() #check available discrete color maps\n",
    "# dash4_figdict['a'].layout.legend.visible=True #set legend visibility\n",
    "# dash4_figdict['a'].layout.legend.font.size=14 #set legend font size\n",
    "# dash4_figdict['a'].layout.height = 500 #set figure dimensions\n",
    "\n",
    "# rename legend name based on keywords present in file name\n",
    "keywords = ['\\d{4}']\n",
    "for data_i in dash4_figdict['a'].data:\n",
    "    input_string = data_i.name\n",
    "    components = input_string.split('_')\n",
    "    matched_components = []    \n",
    "    for keyword in keywords: # Loop through the components and match against each keyword\n",
    "        pattern = re.compile(rf\"\\S*{keyword.strip()}\\S*\")\n",
    "        for component in components:\n",
    "            if pattern.match(component):\n",
    "                if component in ['']: #ignore these keywords\n",
    "                    continue\n",
    "                else:\n",
    "                    matched_components.append(component)\n",
    "                # break # Assuming we want only the first match for each keyword\n",
    "    if len(matched_components) != 0:\n",
    "        data_i.name = ', '.join(matched_components) # Join the matched components with a comma and space\n",
    "\n",
    "# dash4_figdict['a'].layout.xaxis.title.text = 'Excitation frequency [Hz]' #set x-axis label\n",
    "\n",
    "#set axis range\n",
    "# dash4_figdict['a'].layout.yaxis.range = [0, 1000]\n",
    "# dash4_figdict['a'].layout.yaxis2.range = [0, 1000]\n",
    "\n",
    "#check extra channel outputs\n",
    "# HTML(get_extrachan_dict('Frequency shift')['plots'][1])\n",
    "\n",
    "#selected files\n",
    "# dash4_file_select.value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c4841-8b8f-430b-8e68-4eb448f63cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dash4_file_select.value\n",
    "files_ini = 'thiolinterdigi_glasspot1_tipAC240TS_forcedistance_osci0.125V_gain10_plloff_speed10nmps_0065'\n",
    "filepath_ini = folderpath + '/' + file_df_spectro.loc[(file_df_spectro.file==files_ini)].iloc[0].loc['name']\n",
    "spectro_data_ini = wsxm_readspectra(filepath_ini, all_files=True, mute=True)\n",
    "curv_ind = 1\n",
    "ind_plot = 350 #point to plot to check\n",
    "pts_free = 10 #number of \"free amplitude\" points to average\n",
    "data_x = spectro_data_ini['Amplitude']['curves'][curv_ind]['data']['approach']['x']\n",
    "data_amp = spectro_data_ini['Amplitude']['curves'][curv_ind]['data']['approach']['y']\n",
    "data_amptrue = spectro_data_ini['True Amplitude']['curves'][curv_ind]['data']['approach']['y']\n",
    "data_ph = spectro_data_ini['Phase']['curves'][curv_ind]['data']['approach']['y']\n",
    "data_freq = spectro_data_ini['Excitation frequency']['curves'][curv_ind]['data']['approach']['y']\n",
    "data_defl = spectro_data_ini['Normal deflection']['curves'][curv_ind]['data']['approach']['y']\n",
    "header_ini = spectro_data_ini['Excitation frequency']['curves'][curv_ind]['header']\n",
    "# q_fac = float(header_ini['Quality factor (Q) [Dynamic settings]'])\n",
    "q_fac = 100# 132.899289\n",
    "res_freq = float(header_ini['Resonance frequency [Dynamic settings]'].split(' ')[0])\n",
    "drive_freq = float(header_ini['Resonance frequency [Dynamic settings]'].split(' ')[0])\n",
    "freq_sens = float(header_ini['Frq. Scan Sensitivity [Dynamic settings]'].split(' ')[0])\n",
    "# amp_cali_fact = get_calibdict_value('True Amplitude', 'nm')['factor']\n",
    "amp_min = np.mean(data_amp[:pts_free]) #average first 10 points to get initial \"free\" amplitude\n",
    "amptrue_min = np.mean(data_amptrue[:pts_free])\n",
    "xc = get_extrachan_dict('Frequency shift')['kwargs']['xc']\n",
    "# print(amp_min)\n",
    "def circle(center, radius, theta_range):   \n",
    "    theta = np.linspace(theta_range[0], theta_range[1], 1000)\n",
    "    x = center[0] + radius * np.cos(theta)\n",
    "    y = center[1] + radius * np.sin(theta)\n",
    "    return x, y, theta\n",
    "\n",
    "# Function to find the intersection point on the circle\n",
    "# def find_intersection(center, radius, point):\n",
    "#     h, k = center\n",
    "#     dx, dy = point\n",
    "    \n",
    "#     # Direction vector from center to the point\n",
    "#     # dx = x #- h\n",
    "#     # dy = y #- k\n",
    "    \n",
    "#     # Calculate the distance from the center to the point\n",
    "#     distance = np.sqrt(dx**2 + dy**2)\n",
    "#     cos_theta = dy/distance\n",
    "#     chord_length = 2*radius*cos_theta \n",
    "    \n",
    "#     # Normalize the direction vector to unit length\n",
    "#     dx /= distance\n",
    "#     dy /= distance\n",
    "    \n",
    "#     # Scale the direction vector by the radius of the circle\n",
    "#     dx *= chord_length#radius\n",
    "#     dy *= chord_length#radius\n",
    "    \n",
    "#     # Calculate the intersection point\n",
    "#     intersection_x = -dx # + h\n",
    "#     intersection_y = -dy # + k \n",
    "    \n",
    "#     return (intersection_x, intersection_y)\n",
    "\n",
    "def find_intersection(center, radius, point):\n",
    "    xc, yc = center[0], center[1]\n",
    "    rc = radius\n",
    "    xp, yp = point[0], point[1]\n",
    "    x1, y1 = center[0], yc+rc #true \"origin\" of the circle, ie. upper most point\n",
    "    # # Direction vector of the line from origin to (xp, yp)\n",
    "    # D = np.array([xp-xc, yp])\n",
    "    \n",
    "    # # Coefficients of the quadratic equation\n",
    "    # a = (xp-xc)**2 + yp**2\n",
    "    # b = -2 * ((xp-xc) * xc + yp * yc)\n",
    "    # c = xc**2 + yc**2 - rc**2\n",
    "    \n",
    "    # # Solve the quadratic equation\n",
    "    # discriminant = b**2 - 4 * a * c\n",
    "    # if discriminant < 0:\n",
    "    #     return None  # No real intersection (line does not intersect the circle)\n",
    "    \n",
    "    # sqrt_discriminant = np.sqrt(discriminant)\n",
    "    # t1 = (-b + sqrt_discriminant) / (2 * a)\n",
    "    # t2 = (-b - sqrt_discriminant) / (2 * a)\n",
    "    \n",
    "    # # Calculate intersection points\n",
    "    # I1 = t1 * D\n",
    "    # I2 = t2 * D\n",
    "    # if I1[1] <= 0:\n",
    "    #     return I1\n",
    "    # else:\n",
    "    #     return I2\n",
    "    # Direction vector of the line from (x1, y1) to (xp, yp)\n",
    "    D = np.array([xp - x1, yp - y1])\n",
    "    \n",
    "    # Coefficients of the quadratic equation\n",
    "    a = D[0]**2 + D[1]**2\n",
    "    b = 2 * (D[0] * (x1 - xc) + D[1] * (y1 - yc))\n",
    "    c = (x1 - xc)**2 + (y1 - yc)**2 - rc**2\n",
    "    \n",
    "    # Solve the quadratic equation\n",
    "    discriminant = b**2 - 4 * a * c\n",
    "    if discriminant < 0:\n",
    "        return None  # No real intersection (line does not intersect the circle)\n",
    "    \n",
    "    sqrt_discriminant = np.sqrt(discriminant)\n",
    "    t1 = (-b + sqrt_discriminant) / (2 * a)\n",
    "    t2 = (-b - sqrt_discriminant) / (2 * a)\n",
    "    \n",
    "    # Calculate intersection points\n",
    "    I1 = np.array([x1, y1]) + t1 * D\n",
    "    I2 = np.array([x1, y1]) + t2 * D\n",
    "    \n",
    "    if I1[1] <= 0:\n",
    "        return I1\n",
    "    else:\n",
    "        return I2\n",
    "    \n",
    "    \n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111,aspect='equal')  \n",
    "\n",
    "phis=np.arange(0,6.28,0.01)\n",
    "# r = abs(amp_min)/2\n",
    "# r0 = amp_min/2\n",
    "center = (xc,amp_min/2)#(0,r0)\n",
    "r = np.mean(np.sqrt((data_amp[:pts_free]-center[1])**2 + (data_ph[:pts_free]-center[0])**2))\n",
    "# r = np.mean(np.sqrt(data_amp[:pts_free]**2 + data_ph[:pts_free]**2))/2\n",
    "r0 = -r\n",
    "\n",
    "print(center, r)\n",
    "circ_x, circ_y, circ_theta = circle(center=center, radius=r, theta_range=(-np.pi/2, -3*np.pi/2))\n",
    "plt.axhline(y=0, linewidth=1, alpha=0.7)\n",
    "plt.axvline(x=0, linewidth=1, alpha=0.7)\n",
    "plt.plot(circ_x, circ_y, 'r--')\n",
    "plt.plot(data_ph, data_amp, 'y.')\n",
    "\n",
    "freq_shift = []\n",
    "amp_diff = []\n",
    "phase_ang = []\n",
    "for data_ind in range(len(data_amp)):\n",
    "    data_pt = (data_ph[data_ind], data_amp[data_ind])\n",
    "    inter_pt = find_intersection(center=center, radius=r, point=data_pt)\n",
    "    # print(inter_pt)\n",
    "    # cos_theta = data_pt[1]/np.sqrt(data_pt[0]**2 + data_pt[1]**2)\n",
    "    # print(data_pt, inter_pt, np.arctan2(inter_pt[1]-center[1],inter_pt[0])*180/np.pi)    \n",
    "    if inter_pt[0] == 0 or data_pt[1] >= 0:\n",
    "        freq_shift.append(0)\n",
    "        amp_diff.append(0)\n",
    "        phase_ang_pt = -90\n",
    "        phase_ang.append(phase_ang_pt)\n",
    "    else:\n",
    "        ampdiff_pt = (inter_pt[0]**2 + inter_pt[1]**2) - (data_pt[0]**2 + data_pt[1]**2) #square difference of amp (energy bal.)\n",
    "        if ampdiff_pt >= 0:\n",
    "            amp_diff.append(np.sqrt(ampdiff_pt))\n",
    "        else:\n",
    "            amp_diff.append(np.sqrt(-ampdiff_pt))\n",
    "        phase_pt = inter_pt[1]/inter_pt[0]\n",
    "        phase_ang_pt = np.arctan2(inter_pt[1],inter_pt[0])*180/np.pi\n",
    "        phase_ang.append(phase_ang_pt)\n",
    "        inter_ind = np.argmin(abs(circ_y-inter_pt[1]))\n",
    "        freq_pt = drive_freq - data_freq[data_ind] #actual drive frequency\n",
    "        # print(inter_pt[1], circ_y[inter_ind])\n",
    "        if phase_pt >= 0 :\n",
    "            freq_calc = res_freq - ((freq_pt/(2*q_fac*phase_pt))*(np.sqrt(1+(4*(q_fac**2)*(phase_pt**2)))-1))\n",
    "            freq_shift.append(freq_calc) #attractive freq shift considered positive\n",
    "        else:\n",
    "            freq_calc = res_freq - ((freq_pt/(2*q_fac*phase_pt))*(-np.sqrt(1+(4*(q_fac**2)*(phase_pt**2)))-1))\n",
    "            freq_shift.append(freq_calc) #attractive freq shift considered positive\n",
    "\n",
    "    if data_ind == ind_plot:\n",
    "        inter_pt_plot = inter_pt[0], inter_pt[1]\n",
    "        data_pt_plot = data_pt[0], data_pt[1]\n",
    "        print(phase_ang_pt, ampdiff_pt, amptrue_min - ampdiff_pt)\n",
    "        print(data_pt, inter_pt) \n",
    "        print(freq_pt, data_freq[data_ind], freq_calc, res_freq, res_freq-freq_calc, freq_pt)\n",
    "        print(phase_pt, (res_freq-freq_calc)*(freq_pt)/(q_fac*(((res_freq-freq_calc)**2)-((freq_pt)**2))))\n",
    "        # if freq_calc < 0:\n",
    "        #     print(data_ind, data_pt, freq_calc, data_x[data_ind])\n",
    "    # print(freq_shift, freq_calc)\n",
    "\n",
    "# print(cali_fact)\n",
    "k_cant = get_calibdict_value('Spring constant', 'N/m')['factor']\n",
    "mass_cant = k_cant/(4*(np.pi*res_freq)**2)\n",
    "energy_diss =  mass_cant*(np.pi**2)*np.square(amp_diff)*(np.square(drive_freq-data_freq)+\\\n",
    "                                                         np.square(res_freq-np.array(freq_shift))) #dissipation energy\n",
    "\n",
    "amp_true_diss = np.sqrt(np.abs(np.square(amptrue_min)-np.square(data_amptrue)))\n",
    "\n",
    "plt.plot([xc, inter_pt_plot[0]], [0, inter_pt_plot[1]], 'w:')\n",
    "plt.plot(*inter_pt_plot, 'wo')\n",
    "plt.plot(*data_pt_plot, 'wo')\n",
    "plt.plot(*center, 'or')\n",
    "\n",
    "# plt.grid(True, alpha=0.5)\n",
    "plt.gca().minorticks_on()\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "# plt.gca().set_aspect('equal')\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(data_x, energy_diss, '-g.')\n",
    "# ax1.plot(data_x, amp_diff, '-g.')\n",
    "# ax1.plot(data_x[ind_plot], amp_diss[ind_plot], 'wo')\n",
    "# ax1.plot(data_x, amp_true_diss, '-r')\n",
    "# ax1.plot(data_x[ind_plot], data_amptrue[ind_plot], 'wo')\n",
    "# ax2.plot(data_x, phase_ang, '-y.')\n",
    "# ax2.plot(data_x[ind_plot], phase_ang[ind_plot], 'wo')\n",
    "ax2.plot(data_x, freq_shift, '-b.')\n",
    "ax2.plot(data_x, data_freq, '-y')\n",
    "# ax2.plot(data_x, data_defl, '-y')\n",
    "# plt.plot(data_x, data_ph)\n",
    "# ax1.set_ylim(*ax2.get_ylim())\n",
    "ax1.grid(True, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "#compare with pll on data\n",
    "files_ini2 = 'thiolinterdigi_glasspot1_tipAC240TS_forcedistance_osci0.125V_gain10_pllon_speed10nmps_0064'\n",
    "filepath_ini2 = folderpath + '/' + file_df_spectro.loc[(file_df_spectro.file==files_ini2)].iloc[0].loc['name']\n",
    "spectro_data_ini2 = wsxm_readspectra(filepath_ini2, all_files=True, mute=True)\n",
    "curv_ind = 1\n",
    "data_x2 = spectro_data_ini2['Amplitude']['curves'][curv_ind]['data']['approach']['x']\n",
    "data_amp2 = spectro_data_ini2['Amplitude']['curves'][curv_ind]['data']['approach']['y']\n",
    "data_ph2 = spectro_data_ini2['Phase']['curves'][curv_ind]['data']['approach']['y']\n",
    "data_freq2 = spectro_data_ini2['Excitation frequency']['curves'][curv_ind]['data']['approach']['y']\n",
    "data_defl2 = spectro_data_ini2['Normal deflection']['curves'][curv_ind]['data']['approach']['y']\n",
    "\n",
    "fig2, ax3 = plt.subplots()\n",
    "ax4 = ax3.twinx()\n",
    "\n",
    "ax3.plot(data_x, freq_shift, '-g.')\n",
    "# ax4.plot(data_x, data_defl, '-r.')\n",
    "ax3.plot(data_x2, data_freq2, 'y.')\n",
    "# ax4.plot(data_x2, data_defl2, 'magenta')\n",
    "# ax3.set_ylim(0,1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64cdb4-b753-4dee-b320-7859cfa4d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_phase3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaed303-6444-4445-983f-df7ceec5718e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_key = 'interdigThiols_tipSi3nN_a_0003'\n",
    "file_df =  dash0_filedict['full']\n",
    "test_filepath = folderpath + '/' + file_df.loc[(file_df.file==test_key)].iloc[0].loc['name']\n",
    "spectro_data_test = wsxm_readspectra(test_filepath, all_files=True, mute=True)\n",
    "test_curvind = 1\n",
    "test = spectro_data_test['Normal force']['curves'][test_curvind]['data']['approach']\n",
    "# thresh=0.03 #fraction of total points\n",
    "# filter_size=20\n",
    "max_percentile = 1\n",
    "fit_order = 2\n",
    "test_x, test_y = test['x'], test['y']\n",
    "# test2_x, test2_y = test2['Z'], test2['ZZ'][:,y_ind,x_ind]\n",
    "# test_y_filt = ndimage.median_filter(test_y, size=filter_size) #filter\n",
    "# test_y_filt_sobel = ndimage.sobel(test_y_filt) #sobel transform\n",
    "# #this method works well when the jump in points is very fast, no points in between.\n",
    "# n_data = len(test_x)\n",
    "# tol_ind = int(thresh*n_data) #tolerance\n",
    "ind_min = np.argmin(test_y)\n",
    "# ind_min = np.argmax(test_y_filt_sobel)\n",
    "\n",
    "# amp_sobel = ndimage.sobel(test_y[:ind_min+tol_ind]) #sobel transform\n",
    "# # amp_sobel = ndimage.sobel(test_y) #sobel transform\n",
    "# # amp_sobel = ndimage.sobel(test_y_filt) #sobel transform\n",
    "# # ind_max = np.argmax(amp_sobel)\n",
    "ind_maxs = np.where(test_y[:ind_min]>=np.percentile(test_y[:ind_min],max_percentile))[0]\n",
    "# # testmin_x, testmin_y = test_x[ind_max], test_y[ind_max]\n",
    "# # poly = np.poly1d([-amp_sobel[ind_max], testmin_y-(-amp_sobel[ind_max]*testmin_x)])\n",
    "# # poly = np.poly1d([slope_avg, testmin_y-(slope_avg*testmin_x)])\n",
    "# if len(ind_maxs) == 1:\n",
    "#     slope_avg = -amp_sobel[ind_maxs].mean()\n",
    "#     testmin_x, testmin_y = test_x[ind_maxs].mean(), test_y[ind_maxs].mean()\n",
    "#     poly = np.poly1d([slope_avg, testmin_y-(slope_avg*testmin_x)])\n",
    "# else:\n",
    "p, res, rank, sing, rcond = np.polyfit(test_x[ind_maxs], test_y[ind_maxs], fit_order, full=True)\n",
    "poly = np.poly1d(p)\n",
    "    \n",
    "fit_x_all = np.linspace(test_x[0], test_x[ind_min], n_data*10)\n",
    "fit_y_all = poly(fit_x_all)\n",
    "\n",
    "snapin_x = test_x[ind_min]\n",
    "snapin_y0 = test_y[ind_min]\n",
    "snapin_y1 = poly(snapin_x)\n",
    "snapin_distance = snapin_y1-snapin_y0\n",
    "\n",
    "fit_x = np.append(fit_x_all, [snapin_x, snapin_x])\n",
    "fit_y = np.append(fit_y_all, [snapin_y0, snapin_y1])\n",
    "# fitind_min = np.argmin(abs(fit_y_all-test_y.min()))\n",
    "# fitind_max = np.argmin(abs(fit_y_all-test_y.max()))\n",
    "# fit_x = fit_x_all[fitind_min:fitind_max]\n",
    "# fit_y = fit_y_all[fitind_min:fitind_max]\n",
    "plt.plot(test_x, test_y,'r.')\n",
    "# plt.plot(test_x[ind_maxs], test_y[ind_maxs],'b')\n",
    "# plt.vlines(x=test2_x[ind_min], ymin=-0.1, ymax=0.1, color='y')\n",
    "# plt.vlines(x=test_x[ind_max], ymin=-0.1, ymax=0.1, color='r')\n",
    "# plt.plot(test_x[:ind_min+tol_ind], amp_sobel,'b-o')\n",
    "# plt.plot(test_x, amp_sobel,'b')\n",
    "# plt.plot(test_x, test_y_filt,'y')\n",
    "# plt.plot(test_x[ind_min-3:ind_min+3], poly(test_x[ind_min-3:ind_min+3]),'g')\n",
    "# plt.plot(fit_x_all, fit_y_all,'g')\n",
    "# plt.plot([snapin_x, snapin_x], [snapin_y0, snapin_y1], 'b')\n",
    "plt.plot(fit_x, fit_y, 'y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55975566-ebd5-4b53-8bc2-9769ebf24b9c",
   "metadata": {},
   "source": [
    "## IMAGE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db75b65-be1f-47e0-a5f6-7a4cac694254",
   "metadata": {},
   "source": [
    "### Compare image segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df22f4-97d8-4cae-b937-8f8afad4ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'Forward' #initial image direction\n",
    "n_clusters = 3 #number of clusters\n",
    "nbins = 100 #number of bins for histograms\n",
    "\n",
    "cp_min = 1 #min percentile range of data shown in plots\n",
    "cp_max = 99 #max percentile range of data showm in plots\n",
    "spectro_hist_type = 'histogram' #'histogram', 'line' choose histogram type for spectro hist plot\n",
    "spectro_hist_cols = ['Amplitude', 'Excitation frequency',  'Normal force'] #'Normal deflection', 'Phase', 'True Amplitude', 'True Phase'\n",
    "flatten_chan = ['Topography'] #list of channels to apply flatten\n",
    "\n",
    "dash5_filebrowser_channels = ['Topography', 'Excitation frequency', 'Amplitude']#, 'Phase'] #channels to display in file browser\n",
    "plot_format = 'png' #png, svg, pdf #format to export plots\n",
    "\n",
    "# choose the figure font\n",
    "font_dict=dict(family='Arial', size=18)#, color='white')\n",
    "font_dict_b=dict(family='Arial', size=12) #font for corr plot\n",
    "color_list = px.colors.qualitative.Plotly\n",
    "dash5_figdict = {'a': '', 'b': '', 'c': '', 'd': '', 'e': ''} \n",
    "\n",
    "file_df =  dash0_filedict['full']\n",
    "file_df_img = file_df[(file_df['type']=='2D')]# & (file_df['channel'] != 'Other')]\n",
    "files_img = list(dict.fromkeys(file_df_img['file']))\n",
    "# files_spectro.sort()\n",
    "chanlist_img = list(dict.fromkeys(file_df_img['channel'])) #unique channels\n",
    "chanlist_img.sort()\n",
    "files_ini = files_img[0]\n",
    "\n",
    "# files = ['spot1_bcpA108afterDMFagain_freeosci3.48V_setpoint3V_gain10_pllon_RH71_0053']\n",
    "# file_df =  dash0_filedict['full']\n",
    "filepath_i = folderpath / file_df.loc[(file_df.file==files_ini)].iloc[0].loc['name']\n",
    "data_dict = wsxm_readchan(filepath_i, all_files=True, mute=True, extra_channels=True)\n",
    "chan_ini = list(data_dict.keys())[0]\n",
    "#topography\n",
    "# dash2_figa = go.FigureWidget()\n",
    "img_data = get_imgdata(data_dict[chan_ini][img_dir],#[f'Image {img_dir} with Forward Ramps'], \n",
    "                       chan_ini, unit_dict=unit_dict)\n",
    "if chan_ini in flatten_chan: #flatten channel\n",
    "    img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "# img_data = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "dash5_figa = plotly_heatmap(x=img_data['X'],\n",
    "                            y=img_data['Y'],\n",
    "                            z_mat=img_data['Z'], style='full', font_dict=font_dict)\n",
    "dash5_figa.data[0].coloraxis = 'coloraxis1'\n",
    "# dash2_figdict['a'].add_trace(dash2_figa.data[0])\n",
    "dash5_figdict['a'] = go.FigureWidget(dash5_figa)\n",
    "\n",
    "x_data, y_data = img_data['X'], img_data['Y']\n",
    "xmin, xmax = x_data.min(), x_data.max()\n",
    "ymin, ymax = y_data.min(), y_data.max()\n",
    "# param_list = list(data_dict.keys())\n",
    "\n",
    "dash5_figdict['a'].update_layout(coloraxis1=dict(colorscale=cm_afmhot,#cmin=68500, cmax=69600,\n",
    "                                 colorbar=dict(#len=0.6, x=0.65, y=1, \n",
    "                                               thickness=15, #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                 )),\n",
    "                                 xaxis = dict(range=[xmin,xmax]),\n",
    "                                 yaxis = dict(range=[ymin,ymax]),\n",
    "                                 # font=font_dict,  # font formatting\n",
    "                                 # template='plotly_dark',\n",
    "                                  # plot_bgcolor='black',  # background color\n",
    "                                  height=500, width=600, title_text=\"\",\n",
    "                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "                                  showlegend=False)\n",
    "# dash2_figdict['b'].update_layout(font=font_dict,  # font formatting\n",
    "#                                  template='plotly_dark',\n",
    "#                                  plot_bgcolor='black',  # background color\n",
    "#                                  height=500, width=1000, title_text=\"\",\n",
    "#                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "#                                  showlegend=False)\n",
    "\n",
    "# dash2_figb_axdict = {} #dictionary of y axis\n",
    "# dash2_figb_tracedict = {'calc':[]} #dictionary of index in FigureWidget.data for each plotted lines (other than vline/hline)\n",
    "\n",
    "labels_selected = list(range(n_clusters))\n",
    "label_data = tsf.segment_kmeans(img_data, n_clusters)\n",
    "colorscale = create_discrete_colorscale(n_clusters, color_list)\n",
    "dash5_figb = plotly_heatmap(x=img_data['X'],\n",
    "                            y=img_data['Y'], #color = colorscale,\n",
    "                            z_mat=label_data, style='full', font_dict=font_dict, opacity=0.7)\n",
    "# dash5_figb.data[0].coloraxis = 'coloraxis'\n",
    "# dash5_figb.data[0].colorscale = [[0,'red'], [1,'blue']]#color_list[:n_clusters]]\n",
    "dash5_figb.data[0].colorbar = dict(#len=0.6, x=0.65, y=1, \n",
    "                                     #tick0=0,\n",
    "                                     dtick=1,\n",
    "                                    # tickvals=[0,1,2,3],\n",
    "                                     # ticktext=[0,1,2],\n",
    "                                     thickness=15, #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                 )\n",
    "dash5_figb.data[0].coloraxis = 'coloraxis2'\n",
    "# dash2_figdict['a'].add_trace(dash2_figa.data[0])\n",
    "dash5_figdict['b'] = go.FigureWidget(dash5_figa)\n",
    "# dash5_figdict['b'].add_trace(dash5_figa.data[0])\n",
    "dash5_figdict['b'].add_trace(dash5_figb.data[0])\n",
    "# dash5_figdict['b'].add_traces(dash5_figb)\n",
    "\n",
    "dash5_figdict['b'].update_layout(coloraxis1=dict(colorscale=cm_afmhot, showscale=False),\n",
    "                                 coloraxis2=dict(colorscale=colorscale,\n",
    "                                                 colorbar=dict(dtick=1,thickness=15)\n",
    "                                                ),\n",
    "                                 xaxis = dict(range=[xmin,xmax]),\n",
    "                                 yaxis = dict(range=[ymin,ymax]),\n",
    "                                 # font=font_dict,  # font formatting\n",
    "                                 # template='plotly_dark',\n",
    "                                  # plot_bgcolor='black',  # background color\n",
    "                                  height=500, width=600, title_text=\"\",\n",
    "                                  margin=dict(t=50, b=0, l=0, r=0),\n",
    "                                  showlegend=False)\n",
    "\n",
    "dash5_figdict['c'] = go.FigureWidget()\n",
    "# dash5_figdict['e'] = plotly_pairplot_initax(fig=None, num=len(param_list), font_dict=font_dict)\n",
    "\n",
    "# dash5_figdict['c'] = plotly_subplots_init(rows=len(param_list),cols=2, width=1000, height=450*len(param_list), \n",
    "#                                           font_dict=font_dict, horizontal_spacing=0.1, \n",
    "#                                           subplot_titles = np.concatenate([[key, ''] for key in  param_list]))\n",
    "\n",
    "#widgets\n",
    "# dash5_file_select = widgets.Select(options=files_img, value=files_ini, \n",
    "#                                    layout=widgets.Layout(width='auto', height='200px'))\n",
    "dash5_imgdir_button = widgets.ToggleButtons(options=['Forward', 'Backward'])\n",
    "dash5_mainchan_dropdown = widgets.Dropdown(options=chanlist_img, value=chan_ini,#'Topography',\n",
    "                                           layout=widgets.Layout(width='200px'))\n",
    "dash5_chan_select = widgets.SelectMultiple(options=chanlist_img, value=chanlist_img,\n",
    "                                          description='channels')\n",
    "dash5_label_select = widgets.SelectMultiple(options=labels_selected, value=labels_selected,\n",
    "                                          description='labels')\n",
    "dash5_updateplot_button = widgets.Button(description='LOAD', tooltip='Update plot based on selected files in file browser',\n",
    "                                        layout=widgets.Layout(height='auto'), style={\"button_height\": \"100px\", 'font_size':\"28px\"})\n",
    "dash5_histupdate_check = widgets.ToggleButton(value=False, description='Show histograms')\n",
    "dash5_corrupdate_check = widgets.ToggleButton(value=False, description='Show correlation')\n",
    "dash5_slide_cb = widgets.FloatRangeSlider(value=[1, 99], min=-100, max=200, \n",
    "                                          step=1, description='color',readout=True)\n",
    "dash5_color_button = widgets.Button(description='Update color', tooltip='Update color range based on histogram range')\n",
    "dash5_save_button = widgets.Button(description='Save')\n",
    "dash5_save_text = widgets.Text(value='', placeholder='File name to save')\n",
    "dash5_output = widgets.Output()\n",
    "\n",
    "dash5_box1 = widgets.VBox([dash5_imgdir_button, \n",
    "                           widgets.HBox([dash5_mainchan_dropdown,dash5_slide_cb]), \n",
    "                           widgets.HBox([dash5_histupdate_check, dash5_corrupdate_check, dash5_color_button]),\n",
    "                           widgets.HBox([dash5_save_text, dash5_save_button])])\n",
    "dash5_box2 = widgets.HBox([dash5_box1, dash5_label_select, dash5_chan_select, dash5_updateplot_button])\n",
    "dash5_figaout = widgets.Output()\n",
    "dash5_figbout = widgets.Output()\n",
    "dash5_figcout = widgets.Output()\n",
    "# dash5_figdout = widgets.Output()\n",
    "dash5_figeout = widgets.Output()\n",
    "dash5_tableout = widgets.Output()\n",
    "dash5_filebrowserout = widgets.Output()\n",
    "dash5_headerout = widgets.Output()\n",
    "\n",
    "#file browser table widget\n",
    "dash5_filedf = dash0_create_summarytable(view_channels=dash5_filebrowser_channels, data_type='2D')\n",
    "# dash5_filedf_filtered = file_df[file_df['channel'] == dash5_filebrowser_channels[0]]\n",
    "# dash5_filedf_merged = dash5_filedf.merge(dash4_filedf_filtered[['file', 'extension', 'name']], on='file', how='left')\n",
    "dash5_filebrowser = ITable(dash5_filedf,  select=True, selected_rows=[0])\n",
    "\n",
    "\n",
    "dash5_figbox = widgets.HBox([dash5_figaout, dash5_figbout])\n",
    "dash5_fig_tab = widgets.Tab()\n",
    "dash5_fig_tab.children = [dash5_figbox, dash5_tableout, dash5_figcout, dash5_figeout, dash5_filebrowser, dash5_headerout, dash5_output]\n",
    "dash5_fig_tab.titles = ['segmentation', 'summary', 'histograms', 'correlation plots', 'File browser', 'header', 'debug']\n",
    "\n",
    "dash5_datadict = {}\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_update_data(change):\n",
    "    files_img_filt = dash5_filebrowser.df.iloc[dash5_filebrowser.selected_rows[0]]['file'] #dash5_file_select.value\n",
    "\n",
    "    filepath_i = folderpath / file_df.loc[(file_df.file==files_img_filt)].iloc[0].loc['name']\n",
    "    # dash5_datadict['data'] = wsxm_readchan(filepath_i, all_files=True, mute=True, extra_channels=True)\n",
    "    data_dict = wsxm_readchan(filepath_i, all_files=True, mute=True, extra_channels=True)\n",
    "\n",
    "    param_data_long = {}\n",
    "    header_data = {}\n",
    "    # data_dict = dash5_datadict['data']\n",
    "    dash5_datadict['data'] = {}\n",
    "\n",
    "    #update channel list based on what's present in file\n",
    "    chan_select_old = dash5_chan_select.value\n",
    "    mainchan_old = dash5_mainchan_dropdown.value\n",
    "    chanlist_img = list(data_dict.keys())\n",
    "    chanlist_img.sort()\n",
    "    try: #bug in unobserve initialization\n",
    "        dash5_mainchan_dropdown.unobserve(dash5_plot_update, 'value')\n",
    "        dash5_chan_select.unobserve(dash5_histplot_update, 'value')\n",
    "    except:\n",
    "        pass\n",
    "    dash5_chan_select.options = chanlist_img\n",
    "    dash5_mainchan_dropdown.options = chanlist_img\n",
    "    if all(item in chanlist_img for item in chan_select_old):\n",
    "        dash5_chan_select.value = chan_select_old\n",
    "    if mainchan_old in chanlist_img:\n",
    "        dash5_mainchan_dropdown.value = mainchan_old\n",
    "    dash5_mainchan_dropdown.observe(dash5_plot_update, 'value')\n",
    "    dash5_chan_select.observe(dash5_histplot_update, 'value')\n",
    "    \n",
    "    for i, key in enumerate(data_dict.keys()):\n",
    "        dash5_datadict['data'][key] = {}\n",
    "        for img_dir in data_dict[key].keys():\n",
    "            if img_dir not in param_data_long.keys():\n",
    "                param_data_long[img_dir] = {}\n",
    "                header_data[img_dir] = {}\n",
    "            # if key == 'Topography':\n",
    "            #     img_data_i = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "            #                              unit_dict=unit_dict)\n",
    "            #     unit_text = unit_dict[key] #unit name\n",
    "            # else:\n",
    "            data_header_i = data_dict[key][img_dir]['header']\n",
    "            if 'Gain in [Dynamic settings]' in data_header_i.keys(): #update calibration for corresponding gain value\n",
    "                update_gaincalib(gain_value=int(data_header_i['Gain in [Dynamic settings]']))            \n",
    "            img_data_i = get_imgdata(data_dict[key][img_dir], key, unit_dict=unit_dict)\n",
    "            unit_text = unit_dict[key] #unit name\n",
    "            # unit_text = parse_paramunit(key, unit_dict, evaluate=False)\n",
    "            \n",
    "            if key in flatten_chan: #flatten channel\n",
    "                img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "\n",
    "            dash5_datadict['data'][key][img_dir] = img_data_i\n",
    "            param_data_long[img_dir][key] = img_data_i['Z'].flatten()\n",
    "            header_data[img_dir][key] = data_header_i.copy()\n",
    "    \n",
    "    dash5_datadict['data long'] = param_data_long.copy()\n",
    "    \n",
    "    dash5_datadict['header'] = pd.Series(header_data[dash5_imgdir_button.value][dash5_mainchan_dropdown.value], name=files_img_filt)\n",
    "    # dash5_datadict['header'] = header_data.copy()\n",
    "    dash5_plot_update(change)\n",
    "    \n",
    "@dash5_output.capture()\n",
    "def dash5_plot_update(change):\n",
    "    global label_data\n",
    "    files_img_filt = dash5_filebrowser.df.iloc[dash5_filebrowser.selected_rows[0]]['file'] #dash5_file_select.value\n",
    "    img_dir = dash5_imgdir_button.value\n",
    "    channel_top = dash5_mainchan_dropdown.value\n",
    "    cp_min1 = min(dash5_slide_cb.value)\n",
    "    cp_max1 = max(dash5_slide_cb.value)\n",
    "    \n",
    "    data_dict = dash5_datadict['data']\n",
    "    # if channel_top == 'Topography':        \n",
    "    #     img_data = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "    #                                      unit_dict=unit_dict)\n",
    "    #     # img_data = data_dict[channel_top][f'Image {img_dir} with Forward Ramps']\n",
    "    # else:\n",
    "    img_data = data_dict[channel_top][img_dir] #get_imgdata(data_dict[channel_top][img_dir], channel_top, unit_dict=unit_dict)\n",
    "    # header_data = dash5_datadict['header'][img_dir][channel_top]\n",
    "    \n",
    "        # img_data = param_data_dict[channel_top][img_dir]\n",
    "    \n",
    "    if channel_top in flatten_chan: #flatten channel\n",
    "        img_data['Z'] = tsf.flatten_line(img_data, order=1)\n",
    "    dash5_figdict['a'].data[0].z = img_data['Z']\n",
    "    dash5_figdict['a'].data[0].x = img_data['X']\n",
    "    dash5_figdict['a'].data[0].y = img_data['Y']\n",
    "    # print(img_data['X'], dash5_figdict['a'].data[0].x, img_data['Y'], dash5_figdict['a'].data[0].y)\n",
    "    \n",
    "    # vmin = np.percentile(img_data['Z'], cp_min, method='midpoint')\n",
    "    # vmax = np.percentile(img_data['Z'], cp_max, method='midpoint')\n",
    "    z_min_i, z_max_i = img_data['Z'].min(), img_data['Z'].max()\n",
    "    if cp_min1 >= 0:\n",
    "        vmin = np.percentile(img_data['Z'], cp_min1, method='midpoint')\n",
    "    else:\n",
    "        vmin = z_min_i + ((cp_min1/100)*(z_max_i-z_min_i)) #(1+(cp_min/100))*img_data_z_i.min()\n",
    "    if cp_max1 <= 100:\n",
    "        vmax = np.percentile(img_data['Z'], cp_max1, method='midpoint')\n",
    "    else:\n",
    "        vmax = z_max_i + (((cp_max1-100)/100)*(z_max_i-z_min_i)) #(cp_max/100)*img_data_z_i.max()\n",
    "    \n",
    "    dash5_figdict['a'].layout.coloraxis1.cmin=vmin\n",
    "    dash5_figdict['a'].layout.coloraxis1.cmax=vmax\n",
    "    \n",
    "    label_data = tsf.segment_kmeans(img_data, n_clusters)\n",
    "    # colorscale = create_discrete_colorscale(n_clusters, color_list)\n",
    "    dash5_figb = plotly_heatmap(x=img_data['X'],\n",
    "                                y=img_data['Y'], #color = colorscale,\n",
    "                                z_mat=label_data, style='full', font_dict=font_dict)\n",
    "    # dash5_figb.data[0].coloraxis = 'coloraxis'\n",
    "    # dash5_figb.data[0].colorscale = [[0,'red'], [1,'blue']]#color_list[:n_clusters]]\n",
    "    dash5_figb.data[0].colorbar = dict(#len=0.6, x=0.65, y=1, \n",
    "                                         #tick0=0,\n",
    "                                         dtick=1,\n",
    "                                        # tickvals=[0,1,2,3],\n",
    "                                         # ticktext=[0,1,2],\n",
    "                                         thickness=15, #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                     )\n",
    "    dash5_figb.data[0].coloraxis = 'coloraxis2'\n",
    "    # dash2_figdict['a'].add_trace(dash2_figa.data[0])\n",
    "    # dash5_figdict['b'] = go.FigureWidget(dash5_figa)\n",
    "    # dash5_figdict['b'].add_trace(dash5_figa.data[0])\n",
    "    dash5_figdict['b'].data[0].z = img_data['Z']\n",
    "    dash5_figdict['b'].data[0].x = img_data['X']\n",
    "    dash5_figdict['b'].data[0].y = img_data['Y']\n",
    "    dash5_figdict['b'].layout.coloraxis1.cmin=vmin\n",
    "    dash5_figdict['b'].layout.coloraxis1.cmax=vmax\n",
    "    dash5_figdict['b'].data[1].z = dash5_figb.data[0].z\n",
    "    dash5_figdict['b'].data[1].x = img_data['X']\n",
    "    dash5_figdict['b'].data[1].y = img_data['Y']\n",
    "\n",
    "    dash5_figdict['a']['layout']['yaxis'].update(autorange = True)\n",
    "    dash5_figdict['a']['layout']['xaxis'].update(autorange = True)\n",
    "    dash5_figdict['b']['layout']['yaxis'].update(autorange = True)\n",
    "    dash5_figdict['b']['layout']['xaxis'].update(autorange = True)\n",
    "    dash5_figdict['a']['layout'].title = dict(text=channel_top, x=0.5)\n",
    "    dash5_figdict['b']['layout'].title = dict(text='Segmentation', x=0.5)\n",
    "\n",
    "    dash5_update_summary()\n",
    "    dash5_histplot_update(None)\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_histplot_update(change):    \n",
    "    if dash5_histupdate_check.value == True and len(dash5_chan_select.value) != 0:\n",
    "        \n",
    "        img_dir = dash5_imgdir_button.value\n",
    "        labels_selected = dash5_label_select.value\n",
    "        param_selected = dash5_chan_select.value\n",
    "        # cp_min = 1 #min(dash5_slide_cb.value)\n",
    "        # cp_max = 99 #max(dash5_slide_cb.value)\n",
    "        \n",
    "        data_dict = dash5_datadict['data']\n",
    "\n",
    "        # dash5_update_summary() #update summary table CHECK!\n",
    "        \n",
    "        # paramval_dict = {'parameter':[], 'direction':[], 'label':[], 'value mean':[], 'value median':[], 'value std':[]}\n",
    "        # dash5_figdict['c'].data = []\n",
    "        # dash5_figdict['c'].data = []\n",
    "        #TODO: OPTIMIZE. AVOID RECREATING FIGUREWIDGET EVERYTIME!\n",
    "        dash5_figdict['c'] = plotly_subplots_init(rows=len(param_selected),cols=2, width=1000, height=450*len(param_selected),\n",
    "                                                  fig=dash5_figdict['c'], font_dict=font_dict, \n",
    "                                                  horizontal_spacing=0.1, vertical_spacing=75/(450*len(param_selected)), \n",
    "                                                  subplot_titles = np.concatenate([[key, ''] for key in  param_selected]))\n",
    "        dash5_figdict['c'].update_annotations(font=font_dict)\n",
    "        for i in range(1, len(param_selected)): #share x_y axis of images\n",
    "            dash5_figdict['c'].update_layout({f\"xaxis{(2*i)+1}\": {\"matches\": 'x'},\n",
    "                                              f\"yaxis{(2*i)+1}\": {\"matches\": 'y'}})\n",
    "        # i = 1\n",
    "        # labels_selected\n",
    "        colors_selected = [color_list[k] for k in labels_selected]\n",
    "        \n",
    "        # param_data_long = {}\n",
    "        for i, key in enumerate(param_selected):\n",
    "            # if key == 'Topography':\n",
    "            #     img_data_i = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "            #                              unit_dict=unit_dict)\n",
    "            #     unit_text = unit_dict[key] #unit name\n",
    "            # else:\n",
    "            img_data_i = data_dict[key][img_dir] #get_imgdata(data_dict[key][img_dir], key, unit_dict=unit_dict)\n",
    "            unit_text = unit_dict[key] #unit name\n",
    "            # unit_text = parse_paramunit(key, unit_dict, evaluate=False)\n",
    "            \n",
    "            # if key in flatten_chan: #flatten channel\n",
    "            #     img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "            # param_data_long[key] = img_data_i['Z'].flatten()\n",
    "            # if key == 'Topography':\n",
    "            #     img_data_i = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "            # else:\n",
    "            #     img_data_i = param_data_dict[key][img_dir]\n",
    "            dash5_figdict['c'].update_layout({f'xaxis{2*(i+1)}': dict(title_text=f\"{key} [{unit_text}]\", \n",
    "                                                                      title_font=font_dict, title_standoff=5)})\n",
    "            dash5_figc_hm_i = plotly_heatmap(x=img_data_i['X'],\n",
    "                                            y=img_data_i['Y'],\n",
    "                                            z_mat=img_data_i['Z'], style='full', font_dict=font_dict)\n",
    "            dash5_figc_hm_i.data[0].coloraxis = f'coloraxis{i+1}'\n",
    "            # if len(dash5_figdict['c'].data) < 2*len(param_selected):\n",
    "            dash5_figdict['c'].add_trace(dash5_figc_hm_i.data[0], row=i+1, col=1) #data[0]\n",
    "            # else:\n",
    "            #     dash5_figdict['c'].data[2*(i-1)].z = dash5_figc_hm_i.data[0].z\n",
    "            # data_clustered_i = {'label':[], 'value':[]}\n",
    "            # vmin = np.percentile(img_data_i['Z'],cp_min)\n",
    "            # vmax = np.percentile(img_data_i['Z'],cp_max)\n",
    "            z_min_i, z_max_i = img_data_i['Z'].min(), img_data_i['Z'].max()\n",
    "            if cp_min >= 0:\n",
    "                vmin = np.percentile(img_data_i['Z'], cp_min, method='midpoint')\n",
    "            else:\n",
    "                vmin = z_min_i + ((cp_min/100)*(z_max_i-z_min_i)) #(1+(cp_min/100))*img_data_z_i.min()\n",
    "            if cp_max <= 100:\n",
    "                vmax = np.percentile(img_data_i['Z'], cp_max, method='midpoint')\n",
    "            else:\n",
    "                vmax = z_max_i + (((cp_max-100)/100)*(z_max_i-z_min_i)) #(cp_max/100)*img_data_z_i.max()\n",
    "            # val_list = []\n",
    "            #complete histogram\n",
    "            # val_j = img_data_i['Z'].flatten()\n",
    "            # vmin_j, vmax_j = val_j.min(), val_j.max()\n",
    "            # dash5_figc_hist_i = go.Histogram(x=val_j, marker=dict(color=get_theme()['fontcolor']), \n",
    "            #                                  xbins=dict(start=vmin_j,end=vmax_j,size=(vmax_j-vmin_j)/int(nbins*0.9*len(labels_selected))),#nbinsx=nbins,\n",
    "            #                                  name='full', opacity=0.6,showlegend=False)#) if i==0 else False)\n",
    "            # dash5_figdict['c'].add_trace(dash5_figc_hist_i, row=i+1, col=2)\n",
    "            bin_size_j = (vmax-vmin)/(nbins*len(labels_selected)) #common bin size for all segments\n",
    "            # vmin_list, vmax_list = [], []\n",
    "            for j, lab_j in enumerate(labels_selected):\n",
    "                val_j = img_data_i['Z'][label_data==lab_j].flatten()\n",
    "                # vmin_j = np.percentile(val_j,cp_min)\n",
    "                # vmax_j = np.percentile(val_j,cp_max)\n",
    "                vmin_j, vmax_j = val_j.min(), val_j.max()\n",
    "                # if cp_min >= 0:\n",
    "                #     vmin_j = np.percentile(val_j, cp_min, method='midpoint')\n",
    "                # else:\n",
    "                #     vmin_j = val_min_j + ((cp_min/100)*(val_max_j-val_min_j)) #(1+(cp_min/100))*img_data_z_i.min()\n",
    "                # if cp_max <= 100:\n",
    "                #     vmax_j = np.percentile(val_j, cp_max, method='midpoint')\n",
    "                # else:\n",
    "                #     vmax_j = val_max_j + (((cp_max-100)/100)*(val_max_j-val_min_j)) #(cp_max/100)*img_data_z_i.max()\n",
    "                # vmin_list.append(vmin_j)\n",
    "                # vmax_list.append(vmax_j)\n",
    "                # val_list.append(val_j)\n",
    "                # value_list.append(val_j)\n",
    "                # label_list.append([j]*len(val_j))\n",
    "                dash5_figc_hist_i = go.Histogram(x=val_j, marker=dict(color=colors_selected[j]), \n",
    "                                                 xbins=dict(start=vmin_j,end=vmax_j,size=bin_size_j),#(vmax_j-vmin_j)/nbins),#nbinsx=nbins,\n",
    "                                                 name=lab_j, opacity=0.6,showlegend=False)#) if i==0 else False)\n",
    "                dash5_figdict['c'].add_trace(dash5_figc_hist_i, row=i+1, col=2)\n",
    "\n",
    "                # paramval_dict['parameter'].append(key)\n",
    "                # paramval_dict['direction'].append(img_dir)\n",
    "                # paramval_dict['label'].append(lab_j)\n",
    "                # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "                # paramval_dict['value median'].append(np.median(val_j))\n",
    "                # paramval_dict['value std'].append(np.std(val_j))\n",
    "            # data_clustered_i = {'label': np.concatenate(label_list), 'value': np.concatenate(value_list)}\n",
    "            # dash5_figc_hist_i = px.histogram(data_clustered_i, color='label', nbins=100)#df, x=\"total_bill\", color=\"sex\")\n",
    "            # for j, _ in enumerate(labels_selected):\n",
    "                # dash5_figdict['c'].add_trace(dash5_figc_hist_i.data[j], row=i, col=2) #data[0]\n",
    "                # dash5_figdict['c'].add_trace(dash5_figc_hist_i.data[1], row=i, col=2) #data[0]\n",
    "            # val_all = np.concatenate(val_list)\n",
    "            # vmin = np.percentile(val_all,1)\n",
    "            # vmax = np.percentile(val_all,99)\n",
    "            dash5_figdict['c'].update_layout({f'coloraxis{i+1}': dict(colorscale=cm_afmhot, showscale=False,cmin=vmin, cmax=vmax,\n",
    "                                                                    # colorbar=dict(len=0.26, x=0.25, y=0.25*(i), thickness=10,\n",
    "                                                                    #               orientation='h',yanchor='bottom',\n",
    "                                                                    #               xanchor='center',thicknessmode=\"pixels\" #orientation='h', xanchor='center',  yanchor='bottom'\n",
    "                                                                    # )\n",
    "                                                                   )},\n",
    "                                            )\n",
    "            # dash5_figdict['c'].layout[f'xaxis{i*2}'].range=[min(vmin_list), max(vmax_list)]\n",
    "            # i += 1\n",
    "\n",
    "        dash5_figcout.clear_output(wait=True)\n",
    "        with dash5_figcout:\n",
    "            display(dash5_figdict['c']) \n",
    "    \n",
    "@dash5_output.capture()\n",
    "def dash5_corrplot_update(change):\n",
    "    if dash5_corrupdate_check.value == True:\n",
    "        labels_selected = dash5_label_select.value\n",
    "        param_selected = dash5_chan_select.value\n",
    "        img_dir = dash5_imgdir_button.value\n",
    "        # cp_min = 1 #min(dash5_slide_cb.value)\n",
    "        # cp_max = 99 #max(dash5_slide_cb.value)\n",
    "        \n",
    "        colors_selected = [color_list[k] for k in labels_selected]\n",
    "        \n",
    "        param_data_long = dash5_datadict['data long'][img_dir]\n",
    "        param_data_long['label'] = label_data.flatten()  \n",
    "        param_data_longdf = pd.DataFrame(param_data_long)\n",
    "        param_data_longdf = param_data_longdf[param_data_longdf['label'].isin(labels_selected)].reset_index(drop=True)\n",
    "        # dash5_fig3 = plotly_pairplot(data=param_data_longdf, cols = param_selected, \n",
    "        #                              hue='label', diag_kind = 'hist', font_dict=font_dict, line_style='markers')\n",
    "        dash5_figdict['e'] = seaborn_pairplot(param_data_longdf, cols=param_selected, hue='label', palette = colors_selected,\n",
    "                                              diag_kind='kde', plot_kws=dict(s=10, linewidth=0.0), font_dict=font_dict_b)\n",
    "        for i, param_i in enumerate(param_selected):\n",
    "            vmin = np.percentile(param_data_longdf[param_i],cp_min)\n",
    "            vmax = np.percentile(param_data_longdf[param_i],cp_max)\n",
    "            dash5_figdict['e'].axes[i].set_xlim((vmin,vmax))\n",
    "            dash5_figdict['e'].axes[i*len(param_selected)].set_ylim((vmin,vmax))\n",
    "        # dash5_figdict['e'] = fig2html(dash5_fig3, plot_type='plotly', width=1200, height=1200, pad=0.1)\n",
    "        # dash5_figdict['e'] = dash5_fig3.to_image(format=\"png\")\n",
    "        dash5_figeout.clear_output(wait=True)\n",
    "        with dash5_figeout:\n",
    "            display(dash5_figdict['e'])\n",
    "        plt.close('all')\n",
    "            \n",
    "        #statistics of spectroscopy calculated parameters\n",
    "        # paramval_groupcols = ['channel', 'parameter', 'file']\n",
    "        # paramval_df = pd.DataFrame(paramval_dict)\n",
    "        # dash5_tableout.clear_output(wait=True)\n",
    "        # with dash5_tableout:\n",
    "        #     itables.show(paramval_df)\n",
    "        # paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "        # paramval_summary = paramval_grouped['value'].agg(['mean', 'std']).reset_index()\n",
    "        # if change != None and \n",
    "        # if change == None or change.owner.description != 'params':\n",
    "        #     label_data_copy = label_data.copy()\n",
    "        #     mask = np.isin(label_data_copy, labels_selected, invert=True)\n",
    "        #     label_data_copy[mask] = -999999\n",
    "        #     output_dict = combine_forcevol_data(data=data_dict, channel_list=spectro_hist_cols, \n",
    "        #                                         label_data=label_data_copy, unit_dict=unit_dict)\n",
    "        #     dash5_figdict['d'] = plot_forcevol_histogram(output_dict[img_dir], plot_type=spectro_hist_type,\n",
    "        #                                                  bins=len(z_data), prange=100, psat=90)\n",
    "        #     dash5_figdout.clear_output(wait=True)\n",
    "        #     with dash5_figdout:\n",
    "        #         display(HTML(dash5_figdict['d']))\n",
    "                \n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_update_summary():\n",
    "    labels_selected = dash5_label_select.value\n",
    "    img_dir = dash5_imgdir_button.value\n",
    "    data_dict = dash5_datadict['data']\n",
    "\n",
    "    chanlist_img = list(data_dict.keys())\n",
    "    chanlist_img.sort()\n",
    "    \n",
    "    paramval_dict = {'x': [], 'y': [], 'channel':[], 'direction':[], 'label':[], 'value': []} #'value mean':[], 'value median':[], 'value std':[]}\n",
    "    # for img_dir_i in ['Forward', 'Backward']:\n",
    "    for param_i in chanlist_img:\n",
    "        # if param_i == 'Topography':\n",
    "        #     img_data_i = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "        #                              unit_dict=unit_dict)\n",
    "        #     unit_text = unit_dict[param_i] #unit name\n",
    "        # else:\n",
    "        img_data_i = data_dict[param_i][img_dir] #get_imgdata(data_dict[param_i][img_dir], param_i, unit_dict=unit_dict)\n",
    "        unit_text = unit_dict[param_i] #unit name\n",
    "        # unit_text = parse_paramunit(param_i, unit_dict, evaluate=False)\n",
    "        if param_i in flatten_chan: #flatten channel\n",
    "            img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "        # if param_i == 'Topography':\n",
    "        #     img_data_i = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "        # else:\n",
    "        #     img_data_i = param_data_dict[param_i][img_dir]\n",
    "        x_data, y_data = img_data_i['X'], img_data_i['Y']\n",
    "        for j, lab_j in enumerate(labels_selected):\n",
    "            val_j = img_data_i['Z'][label_data==lab_j].flatten().tolist()\n",
    "            xy_j = np.argwhere(label_data==lab_j).tolist()#.flatten().tolist()\n",
    "            x_val_j = [x_data[kx] for kx, _ in xy_j]\n",
    "            y_val_j = [y_data[ky] for _, ky in xy_j]\n",
    "            val_jnum = len(val_j)\n",
    "            paramval_dict['x'] += x_val_j\n",
    "            paramval_dict['y'] += y_val_j\n",
    "            paramval_dict['channel'] += [f\"{param_i} [{unit_text}]\"]*val_jnum\n",
    "            paramval_dict['direction'] += [img_dir]*val_jnum\n",
    "            paramval_dict['label'] += [lab_j]*val_jnum\n",
    "            paramval_dict['value'] += val_j\n",
    "            # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "            # paramval_dict['value median'].append(np.median(val_j))\n",
    "            # paramval_dict['value std'].append(np.std(val_j))\n",
    "            # val_j = img_data_i['data']['Z'][label_data==lab_j].flatten()\n",
    "            # paramval_dict['parameter'].append(param_i)\n",
    "            # paramval_dict['direction'].append(img_dir)\n",
    "            # paramval_dict['label'].append(lab_j)\n",
    "            # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "            # paramval_dict['value median'].append(np.median(val_j))\n",
    "            # paramval_dict['value std'].append(np.std(val_j))\n",
    "    \n",
    "    paramval_df = pd.DataFrame(paramval_dict)\n",
    "    \n",
    "    # dash5_datadict['full'] = paramval_df #FIX THIS> FULL DATAFRAME CREATE\n",
    "    dash5_datadict['long'] = paramval_df.pivot(columns='channel', \n",
    "                                               index=['direction', 'label', 'x', 'y'],\n",
    "                                               values='value').reset_index() \n",
    "    \n",
    "    paramval_groupcols = paramval_df.columns.drop(['value', 'x', 'y']).to_list()\n",
    "    paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "    paramval_summary = paramval_grouped['value'].agg(['mean', 'median', 'std']).reset_index()\n",
    "    dash5_datadict['summary'] = paramval_summary\n",
    "    \n",
    "    dash5_tableout.clear_output(wait=True)\n",
    "    with dash5_tableout:\n",
    "        itables.show(dash5_datadict['summary'])\n",
    "\n",
    "    #show header info\n",
    "    dash5_headerout.clear_output(wait=True)\n",
    "    with dash5_headerout:\n",
    "        display(ITable(dash5_datadict['header'], paging=False))\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_label_update(change):\n",
    "    colorscale_filt = create_discrete_colorscale(n_clusters, color_list)\n",
    "    labels_selected = dash5_label_select.value\n",
    "    for lab in range(n_clusters):\n",
    "        if lab not in labels_selected:\n",
    "            colorscale_filt[2*lab][1] = 'rgba(0,0,0,0)'\n",
    "            colorscale_filt[2*lab+1][1] = 'rgba(0,0,0,0)'\n",
    "    dash5_figdict['b'].layout.coloraxis2.colorscale = colorscale_filt\n",
    "    dash5_histplot_update(None)\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_colormain_update(change):\n",
    "    cp_min1 = min(dash5_slide_cb.value)\n",
    "    cp_max1 = max(dash5_slide_cb.value)\n",
    "    fig_list = [dash5_figdict['a'], dash5_figdict['b']]\n",
    "    for fig_i in fig_list:\n",
    "        img_data_z_i = fig_i.data[0].z\n",
    "        z_min_i, z_max_i = img_data_z_i.min(), img_data_z_i.max()\n",
    "        if cp_min1 >= 0:\n",
    "            vmin = np.percentile(img_data_z_i, cp_min1, method='midpoint')\n",
    "        else:\n",
    "            vmin = z_min_i + ((cp_min1/100)*(z_max_i-z_min_i)) #(1+(cp_min/100))*img_data_z_i.min()\n",
    "        if cp_max1 <= 100:\n",
    "            vmax = np.percentile(img_data_z_i, cp_max1, method='midpoint')\n",
    "        else:\n",
    "            vmax = z_max_i + (((cp_max1-100)/100)*(z_max_i-z_min_i)) #(cp_max/100)*img_data_z_i.max()\n",
    "        # print(cp_min, vmin)\n",
    "        fig_i.layout.coloraxis1.cmin=vmin\n",
    "        fig_i.layout.coloraxis1.cmax=vmax\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_colorhist_update(change):\n",
    "    if dash5_histupdate_check.value == True:\n",
    "        # i = 1\n",
    "        # for subplot_i in dash5_figdict['c']['data']:\n",
    "        #     if subplot_i.type == 'heatmap':\n",
    "        #         # coloraxis_i = dash5_figdict['c']['layout'][f'coloraxis{i}']\n",
    "        #         # print(coloraxis_i.cmin, coloraxis_i.cmax)\n",
    "        #         img_data_z_i = subplot_i.z\n",
    "        #         z_min_i, z_max_i = img_data_z_i.min(), img_data_z_i.max()\n",
    "        #         if cp_min >= 0:\n",
    "        #             vmin = np.percentile(img_data_z_i, cp_min, method='midpoint')\n",
    "        #         else:\n",
    "        #             vmin = z_min_i + ((cp_min/100)*(z_max_i-z_min_i)) #(1+(cp_min/100))*img_data_z_i.min()\n",
    "        #         if cp_max <= 100:\n",
    "        #             vmax = np.percentile(img_data_z_i, cp_max, method='midpoint')\n",
    "        #         else:\n",
    "        #             vmax = z_max_i + (((cp_max-100)/100)*(z_max_i-z_min_i)) #(cp_max/100)*img_data_z_i.max()\n",
    "        #         # print(cp_min, vmin)\n",
    "        #         coloraxis_i = dash5_figdict['c']['layout'][f'coloraxis{i}']\n",
    "        #         coloraxis_i.cmin=vmin\n",
    "        #         coloraxis_i.cmax=vmax\n",
    "        #         i += 1\n",
    "        #update color range based on histogram x axis range\n",
    "        for i in range(1, len(dash5_chan_select.value)+1):\n",
    "            dash5_figdict['c'].layout[f'coloraxis{i}']['cmin'] = 1*dash5_figdict['c'].layout[f'xaxis{i*2}']['range'][0]\n",
    "            dash5_figdict['c'].layout[f'coloraxis{i}']['cmax'] = 1*dash5_figdict['c'].layout[f'xaxis{i*2}']['range'][1]\n",
    "\n",
    "\n",
    "@dash5_output.capture()\n",
    "def dash5_save_click(change):\n",
    "    img_dir = dash5_imgdir_button.value\n",
    "    filekey = dash5_filebrowser.df.iloc[dash5_filebrowser.selected_rows[0]]['file'] #dash5_file_select.value\n",
    "    if dash5_save_text.value == '':\n",
    "        name_prefix = 'results'\n",
    "    else:\n",
    "        name_prefix = f'{dash5_save_text.value}'\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    outputpath_imaging = outputpath / 'Imaging'\n",
    "    dash5_outfilepath = f'{outputpath_imaging}/{name_prefix}' #COMPLETE THIS! ALSO SAVE PLOTS!\n",
    "    name_suffix = f'{filekey}_{img_dir}_{timestamp}'\n",
    "    combined_image = merge_plotly_figures([dash5_figdict['a'], dash5_figdict['b']], [2])\n",
    "    combined_image.save(f'{dash5_outfilepath}_segmentplot_{name_suffix}.{plot_format}')\n",
    "    if dash5_histupdate_check.value == True:\n",
    "        dash5_figdict['c'].write_image(f'{dash5_outfilepath}_histplot_{name_suffix}.{plot_format}', scale=len(dash5_chan_select.value))\n",
    "        # html2png(dash5_figdict['d'], f'{dash5_outfilepath}_spectrohist_{name_suffix}.png')\n",
    "    if dash5_corrupdate_check.value == True:\n",
    "        dash5_figdict['e'].savefig(f'{dash5_outfilepath}_correlationplot_{name_suffix}.{plot_format}', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "    with pd.ExcelWriter(f'{dash5_outfilepath}_segmentstats_{name_suffix}.xlsx', mode=\"w\", engine=\"openpyxl\") as writer:\n",
    "        dash5_datadict['summary'].to_excel(writer, sheet_name=\"Statistics\")\n",
    "    with pd.ExcelWriter(f'{dash5_outfilepath}_segmentstats_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "        dash5_datadict['header'].to_excel(writer, sheet_name=\"Header\")\n",
    "    with pd.ExcelWriter(f'{dash5_outfilepath}_segmentstats_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "        dash5_datadict['long'].to_excel(writer, sheet_name=\"Data\")\n",
    "    # dash2_figdict['a'].write_image(f'{dash2_outfilepath}_spectroplot.png')\n",
    "    # dash2_figdict['b'].write_image(f'{dash2_outfilepath}_correlationplot.png')\n",
    "    # dash4_update_data('save')\n",
    "    \n",
    "\n",
    "# dash5_figdict['b'].data[0].showscale = False\n",
    "# dash5_figdict['b'].data[0].coloraxis = None\n",
    "# dash2_figdict['b'] = plotly_multiyplot_initax(fig=None, yvars=[chan_list[0]], yax_dict=dash2_figb_axdict,\n",
    "#                                               font_dict=font_dict, height=500, width=1000)\n",
    "# dash2_figdict['c'] = plotly_pairplot_initax(fig=None, num=len(chan_list), font_dict=font_dict)\n",
    "\n",
    "\n",
    "\n",
    "# files = ['interdigThiols_SitipDiam3Nm_0000']\n",
    "# filepath_i = folderpath + '/' + file_df.loc[(file_df.file==files[0])].iloc[0].loc['name']\n",
    "# test = wsxm_readchan(filepath_i, all_files=True, mute=True)\n",
    "# chan_data = test['Topography']['Forward']['data']\n",
    "# # amp_offset = np.atleast_2d(np.mean(amp_chan['Z'], axis=1)).T\n",
    "# # p, res, rank, sing, rcond = np.polyfit(amp_chan['X'], amp_chan['Z'].T, 1, full=True)\n",
    "# # amp_offset = np.array([np.poly1d(p[:,i])(amp_chan['X']) for i in range(p.shape[1])])\n",
    "# # amp_shifted = amp_chan['Z']-amp_offset\n",
    "# plt.pcolormesh(chan_data['Z'], cmap='afmhot')\n",
    "# plt.clim(vmin=np.percentile(chan_data['Z'],1),vmax=np.percentile(chan_data['Z'],99))\n",
    "# plt.show()\n",
    "\n",
    "# n_clusters = 3\n",
    "# chan_labels = tsf.segment_kmeans(chan_data, n_clusters)\n",
    "\n",
    "# plt.pcolormesh(chan_labels, cmap='afmhot')\n",
    "# plt.show()\n",
    "\n",
    "# data_clustered = {}\n",
    "# for i in range(n_clusters):\n",
    "#     data_clustered[i] = chan_data['Z'][chan_labels==i].flatten()  \n",
    "# sns.histplot(data=data_clustered)#, x=\"flipper_length_mm\", hue=\"species\")\n",
    "# plt.show()\n",
    "\n",
    "# dash5_histplot_update(None)\n",
    "# dash5_plot_update(None)\n",
    "dash5_update_data(None)\n",
    "\n",
    "with dash5_figaout:\n",
    "    display(dash5_figdict['a'])\n",
    "with dash5_figbout:\n",
    "    display(dash5_figdict['b'])\n",
    "# with dash5_figcout:\n",
    "#     display(dash5_figdict['c']) \n",
    "\n",
    "# dash5_file_select.observe(dash5_update_data, 'value')\n",
    "dash5_label_select.observe(dash5_label_update, 'value')\n",
    "dash5_mainchan_dropdown.observe(dash5_plot_update, 'value')\n",
    "dash5_chan_select.observe(dash5_histplot_update, 'value')\n",
    "dash5_imgdir_button.observe(dash5_plot_update, 'value')\n",
    "dash5_histupdate_check.observe(dash5_histplot_update, 'value')\n",
    "dash5_corrupdate_check.observe(dash5_corrplot_update, 'value')\n",
    "dash5_slide_cb.observe(dash5_colormain_update)\n",
    "dash5_color_button.on_click(dash5_colorhist_update)\n",
    "dash5_save_button.on_click(dash5_save_click)\n",
    "dash5_updateplot_button.on_click(dash5_update_data)\n",
    "# display(dash5_file_select)\n",
    "display(dash5_box2)\n",
    "display(dash5_fig_tab)\n",
    "# display(dash5_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e6cac1-ce72-43d2-ad2c-f559210efc3a",
   "metadata": {},
   "source": [
    "### Compare multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923c3c3-6b21-453e-b6b1-26d7ff6ceecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash6_filebrowser_channels = ['Topography', 'Excitation frequency', 'Amplitude']#, 'Phase'] #channels to display in file browser\n",
    "flatten_chan = ['Topography'] #list of channels to apply flatten\n",
    "nbins = 100 #number of bins for histograms\n",
    "cp_min = 1 #min(dash5_slide_cb.value)\n",
    "cp_max = 99 #max(dash5_slide_cb.value)\n",
    "# choose the figure font\n",
    "font_dict=dict(family='Arial', size=18)#, color='white')\n",
    "color_list = px.colors.qualitative.Plotly\n",
    "plot_format = 'png' #png, svg, pdf #format to export plots\n",
    "\n",
    "file_df =  dash0_filedict['full']\n",
    "file_df_img = file_df[(file_df['type']=='2D')]# & (file_df['channel'] != 'Other')]\n",
    "# files_img = list(dict.fromkeys(file_df_img['file']))\n",
    "# files_spectro.sort()\n",
    "chanlist_img = list(dict.fromkeys(file_df_img['channel'])) #unique channels\n",
    "chanlist_img.sort()\n",
    "# files_ini = files_img[0]\n",
    "\n",
    "dash6_datadict = {}\n",
    "dash6_figdict = {}\n",
    "\n",
    "dash6_figdict['a'] = go.FigureWidget()\n",
    "\n",
    "dash6_imgdir_button = widgets.ToggleButtons(options=['Forward', 'Backward'])\n",
    "# dash6_mainchan_dropdown = widgets.Dropdown(options=chanlist_img, value=chan_ini,#'Topography',\n",
    "#                                            layout=widgets.Layout(width='200px'))\n",
    "dash6_chan_select = widgets.SelectMultiple(options=chanlist_img, value=chanlist_img,\n",
    "                                          description='channels')\n",
    "# dash6_label_select = widgets.SelectMultiple(options=labels_selected, value=labels_selected,\n",
    "#                                           description='labels')\n",
    "dash6_loaddata_button = widgets.Button(description='LOAD', tooltip='Update plot based on selected files in file browser',\n",
    "                                        layout=widgets.Layout(height='auto'), style={\"button_height\": \"100px\", 'font_size':\"28px\"})\n",
    "dash6_updateplot_button = widgets.Button(description='Update plot')\n",
    "# dash6_corrupdate_check = widgets.ToggleButton(value=False, description='Show correlation')\n",
    "# dash6_slide_cb = widgets.FloatRangeSlider(value=[0, 100], min=-100, max=200, \n",
    "#                                           step=1, description='color',readout=True)\n",
    "dash6_color_button = widgets.Button(description='Update color', tooltip='Update color range based on histogram range')\n",
    "dash6_save_button = widgets.Button(description='Save')\n",
    "dash6_save_text = widgets.Text(value='', placeholder='File name to save')\n",
    "dash6_output = widgets.Output()\n",
    "\n",
    "dash6_box1 = widgets.VBox([dash6_imgdir_button, \n",
    "                           widgets.HBox([dash6_updateplot_button, dash6_color_button]),\n",
    "                           widgets.HBox([dash6_save_text, dash6_save_button])])\n",
    "dash6_box2 = widgets.HBox([dash6_box1, dash6_chan_select, dash6_loaddata_button])\n",
    "dash6_figaout = widgets.Output()\n",
    "# dash6_figbout = widgets.Output()\n",
    "# dash6_figcout = widgets.Output()\n",
    "# dash6_figdout = widgets.Output()\n",
    "# dash6_figeout = widgets.Output()\n",
    "dash6_tableout = widgets.Output()\n",
    "dash6_filebrowserout = widgets.Output()\n",
    "dash6_headerout = widgets.Output()\n",
    "dash6_figbox = widgets.HBox([dash6_figaout])\n",
    "\n",
    "#file browser table widget\n",
    "dash6_filedf = dash0_create_summarytable(view_channels=dash6_filebrowser_channels, data_type='2D')\n",
    "# dash6_filedf_filtered = file_df[file_df['channel'] == dash6_filebrowser_channels[0]]\n",
    "# dash6_filedf_merged = dash6_filedf.merge(dash4_filedf_filtered[['file', 'extension', 'name']], on='file', how='left')\n",
    "dash6_filebrowser = ITable(dash6_filedf,  select=True, selected_rows=[0])\n",
    "\n",
    "\n",
    "# dash6_figbox = widgets.HBox([dash6_figaout, dash6_figbout])\n",
    "dash6_fig_tab = widgets.Tab()\n",
    "dash6_fig_tab.children = [dash6_figbox, dash6_tableout, dash6_filebrowser, dash6_headerout, dash6_output]\n",
    "dash6_fig_tab.titles = ['plots', 'summary', 'File browser', 'header', 'debug']\n",
    "\n",
    "@dash6_output.capture()\n",
    "def dash6_update_data(change):\n",
    "    files_selected = dash6_filebrowser.df.iloc[dash6_filebrowser.selected_rows]['file'] #dash6_file_select.value\n",
    "    dash6_datadict['data'] = {}\n",
    "    dash6_datadict['data long'] = {}\n",
    "    # dash6_datadict['header'] = {}\n",
    "    header_data = {}\n",
    "    for file_i in files_selected:\n",
    "        filepath_i = folderpath / file_df.loc[(file_df.file==file_i)].iloc[0].loc['name']\n",
    "        data_dict = wsxm_readchan(filepath_i, all_files=True, mute=True, extra_channels=True)\n",
    "\n",
    "        # param_data_long = {}\n",
    "        header_data[file_i] = {}\n",
    "        dash6_datadict['data'][file_i] = {}\n",
    "        # data_dict = dash6_datadict['data'][file_i]\n",
    "    \n",
    "        #update channel list based on what's present in file\n",
    "        chan_select_old = dash6_chan_select.value\n",
    "        # mainchan_old = dash6_mainchan_dropdown.value\n",
    "        chanlist_img = list(data_dict.keys())\n",
    "        chanlist_img.sort()\n",
    "        # try: #bug in unobserve initialization\n",
    "        #     # dash6_mainchan_dropdown.unobserve(dash6_plot_update, 'value')\n",
    "        #     dash6_chan_select.unobserve(dash6_plot_update, 'value')\n",
    "        # except:\n",
    "        #     pass\n",
    "        dash6_chan_select.options = chanlist_img\n",
    "        # dash6_mainchan_dropdown.options = chanlist_img\n",
    "        if all(item in chanlist_img for item in chan_select_old):\n",
    "            dash6_chan_select.value = chan_select_old\n",
    "        # if mainchan_old in chanlist_img:\n",
    "        #     dash6_mainchan_dropdown.value = mainchan_old\n",
    "        # dash6_mainchan_dropdown.observe(dash6_plot_update, 'value')\n",
    "        # dash6_chan_select.observe(dash6_plot_update, 'value')\n",
    "        \n",
    "        for i, key in enumerate(data_dict.keys()):\n",
    "            dash6_datadict['data'][file_i][key] = {}\n",
    "            header_data[file_i][key] = {}\n",
    "            for img_dir in data_dict[key].keys():\n",
    "                header_data[file_i][key][img_dir] = {}\n",
    "                # if img_dir not in header_data.keys():\n",
    "                #     # param_data_long[img_dir] = {}\n",
    "                #     header_data[img_dir] = {}\n",
    "                # if key == 'Topography':\n",
    "                #     img_data_i = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "                #                              unit_dict=unit_dict)\n",
    "                #     unit_text = unit_dict[key] #unit name\n",
    "                # else:\n",
    "                data_header_i = data_dict[key][img_dir]['header']\n",
    "                if 'Gain in [Dynamic settings]' in data_header_i.keys(): #update calibration for corresponding gain value\n",
    "                    update_gaincalib(gain_value=int(data_header_i['Gain in [Dynamic settings]']))            \n",
    "                img_data_i = get_imgdata(data_dict[key][img_dir], key, unit_dict=unit_dict)\n",
    "                unit_text = unit_dict[key] #unit name\n",
    "                # unit_text = parse_paramunit(key, unit_dict, evaluate=False)\n",
    "                \n",
    "                if key in flatten_chan: #flatten channel\n",
    "                    img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "\n",
    "                dash6_datadict['data'][file_i][key][img_dir] = img_data_i\n",
    "                # param_data_long[img_dir][key] = img_data_i['Z'].flatten()\n",
    "                header_data[file_i][key][img_dir] = data_header_i.copy()\n",
    "        \n",
    "        # dash6_datadict['data long'][file_i] = param_data_long.copy()\n",
    "        # dash6_datadict['header'][file_i] = header_data.copy()   \n",
    "    # header_data = dash6_datadict['header']#[img_dir][channel_top]\n",
    "    header_series_list = []\n",
    "    for file_i, header_data_i in header_data.items():\n",
    "        header_series_list.append(pd.Series(header_data_i[dash6_chan_select.value[0]][dash6_imgdir_button.value], name=file_i))    \n",
    "    header_data_merged = pd.concat(header_series_list, axis=1)\n",
    "    dash6_datadict['header'] = header_data_merged\n",
    "    \n",
    "    dash6_update_summary()\n",
    "    dash6_plot_update(change)\n",
    "\n",
    "@dash6_output.capture()\n",
    "def dash6_plot_update(change):\n",
    "    img_dir = dash6_imgdir_button.value\n",
    "    files_selected = dash6_filebrowser.df.iloc[dash6_filebrowser.selected_rows]['file']\n",
    "    param_selected = dash6_chan_select.value   \n",
    "    \n",
    "    data_dict = dash6_datadict['data']\n",
    "    # dash6_update_summary() #update summary table CHECK!\n",
    "\n",
    "    #TODO: OPTIMIZE. AVOID RECREATING FIGUREWIDGET EVERYTIME!\n",
    "    dash6_figdict['a'] = plotly_subplots_init(rows=len(files_selected)+1,cols=len(param_selected),\n",
    "                                              width=450*len(param_selected), height=450*(len(files_selected)+1),\n",
    "                                              fig=dash6_figdict['a'], font_dict=font_dict, \n",
    "                                              horizontal_spacing=75/(450*len(param_selected)), \n",
    "                                              vertical_spacing=75/(450*(len(files_selected)+1)), \n",
    "                                              # subplot_titles = np.concatenate([[key, ''] for key in  param_selected])\n",
    "                                             )\n",
    "    dash6_figdict['a'].update_annotations(font=font_dict)\n",
    "    \n",
    "    for i in range(0, len(param_selected)*len(files_selected)): #share x_y axis of images CHECK!!\n",
    "        dash6_figdict['a'].update_layout({f\"xaxis{i+1}\": {\"matches\": 'x'},\n",
    "                                          f\"yaxis{i+1}\": {\"matches\": 'y'}})\n",
    "    # i = 1\n",
    "    # labels_selected\n",
    "    colors_selected = [color_list[k] for k in range(len(files_selected))]\n",
    "    \n",
    "    # param_data_long = {}\n",
    "    k = 0\n",
    "    vmin_dict, vmax_dict = {}, {}\n",
    "    for j, file_j in enumerate(files_selected):\n",
    "        for i, key in enumerate(param_selected):\n",
    "            # img_data_i = get_imgdata(data_dict[file_j][key][img_dir], key, unit_dict=unit_dict)\n",
    "            img_data_i = data_dict[file_j][key][img_dir]\n",
    "            unit_text = unit_dict[key] #unit name\n",
    "            \n",
    "            # if key in flatten_chan: #flatten channel\n",
    "            #     img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "\n",
    "            if j == len(files_selected)-1:\n",
    "                num_imgplots = len(files_selected)*len(param_selected)\n",
    "                k += 1 #axis counter\n",
    "                dash6_figdict['a'].update_layout({f'xaxis{num_imgplots+k}': dict(title_text=f\"{key} [{unit_text}]\", \n",
    "                                                                      title_font=font_dict, title_standoff=5)})\n",
    "            dash6_figc_hm_i = plotly_heatmap(x=img_data_i['X'],\n",
    "                                            y=img_data_i['Y'],\n",
    "                                            z_mat=img_data_i['Z'], style='full', font_dict=font_dict)\n",
    "            dash6_figc_hm_i.data[0].coloraxis = f'coloraxis{i+1}'\n",
    "    \n",
    "            dash6_figdict['a'].add_trace(dash6_figc_hm_i.data[0], row=j+1, col=i+1) #data[0]\n",
    "    \n",
    "            z_min_i, z_max_i = img_data_i['Z'].min(), img_data_i['Z'].max()\n",
    "            if cp_min >= 0:\n",
    "                vmin = np.percentile(img_data_i['Z'], cp_min, method='midpoint')\n",
    "            else:\n",
    "                vmin = z_min_i + ((cp_min/100)*(z_max_i-z_min_i)) #(1+(cp_min/100))*img_data_z_i.min()\n",
    "            if cp_max <= 100:\n",
    "                vmax = np.percentile(img_data_i['Z'], cp_max, method='midpoint')\n",
    "            else:\n",
    "                vmax = z_max_i + (((cp_max-100)/100)*(z_max_i-z_min_i)) #(cp_max/100)*img_data_z_i.max()\n",
    "    \n",
    "            # bin_size_j = (vmax-vmin)/(nbins*len(files_selected)) #common bin size for all segments\n",
    "            bin_size_j = (vmax-vmin)/nbins\n",
    "\n",
    "            if key not in vmin_dict.keys():\n",
    "                vmin_dict[key] = []\n",
    "                vmax_dict[key] = []\n",
    "            vmin_dict[key].append(vmin)\n",
    "            vmax_dict[key].append(vmax)\n",
    "            # for j, lab_j in enumerate(labels_selected):\n",
    "            val_j = img_data_i['Z'].flatten()\n",
    "            # val_min_j, val_max_j = val_j.min(), val_j.max()\n",
    "            vmin_j, vmax_j = val_j.min(), val_j.max()\n",
    "            # if cp_min >= 0:\n",
    "            #     vmin_j = np.percentile(val_j, cp_min, method='midpoint')\n",
    "            # else:\n",
    "            #     vmin_j = val_min_j + ((cp_min/100)*(val_max_j-val_min_j)) #(1+(cp_min/100))*img_data_z_i.min()\n",
    "            # if cp_max <= 100:\n",
    "            #     vmax_j = np.percentile(val_j, cp_max, method='midpoint')\n",
    "            # else:\n",
    "            #     vmax_j = val_max_j + (((cp_max-100)/100)*(val_max_j-val_min_j)) #(cp_max/100)*img_data_z_i.max()\n",
    "\n",
    "            dash6_figc_hist_i = go.Histogram(x=val_j, marker=dict(color=colors_selected[j]), \n",
    "                                             xbins=dict(start=vmin_j,end=vmax_j,size=bin_size_j),#(vmax_j-vmin_j)/nbins),#nbinsx=nbins,\n",
    "                                             name=file_j, opacity=0.6,showlegend=True if i==0 else False)\n",
    "            dash6_figdict['a'].add_trace(dash6_figc_hist_i, row=len(files_selected)+1, col=i+1)\n",
    "    \n",
    "    \n",
    "            dash6_figdict['a'].update_layout({f'coloraxis{i+1}': dict(colorscale=cm_afmhot, showscale=False,\n",
    "                                                                      cmin=min(vmin_dict[key]), cmax=max(vmax_dict[key]))},\n",
    "                                                 legend=dict(\n",
    "                                                            orientation=\"v\",       # horizontal\n",
    "                                                            yanchor=\"bottom\",\n",
    "                                                            y=-0.4/(len(files_selected)+1),                # a bit below the plot\n",
    "                                                            xanchor=\"center\",\n",
    "                                                            x=0.5\n",
    "                                                        )\n",
    "                                            )\n",
    "    dash6_figaout.clear_output(wait=True)\n",
    "    with dash6_figaout:\n",
    "        display(dash6_figdict['a']) \n",
    "\n",
    "\n",
    "@dash6_output.capture()\n",
    "def dash6_update_summary():\n",
    "    files_selected = dash6_filebrowser.df.iloc[dash6_filebrowser.selected_rows]['file']\n",
    "    img_dir = dash6_imgdir_button.value\n",
    "    param_selected = dash6_chan_select.value\n",
    "    \n",
    "    data_dict = dash6_datadict['data']    \n",
    "    paramval_dict = {'file':[], 'channel':[], 'direction':[], 'x': [], 'y': [], 'value': []} #'value mean':[], 'value median':[], 'value std':[]}\n",
    "    # for img_dir_i in ['Forward', 'Backward']:\n",
    "    for j, file_j in enumerate(files_selected):\n",
    "        chanlist_img = list(data_dict[file_j].keys())\n",
    "        chanlist_img.sort()\n",
    "        for param_i in chanlist_img:\n",
    "            # if param_i == 'Topography':\n",
    "            #     img_data_i = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'], 'Topography',\n",
    "            #                              unit_dict=unit_dict)\n",
    "            #     unit_text = unit_dict[param_i] #unit name\n",
    "            # else:\n",
    "            # print(file_j, param_i, data_dict.keys(), print(data_dict[file_j].keys()))\n",
    "            img_data_i = data_dict[file_j][param_i][img_dir] #get_imgdata(data_dict[param_i][img_dir], param_i, unit_dict=unit_dict)\n",
    "            unit_text = unit_dict[param_i] #unit name\n",
    "            # unit_text = parse_paramunit(param_i, unit_dict, evaluate=False)\n",
    "            # if param_i in flatten_chan: #flatten channel\n",
    "            #     img_data_i['Z'] = tsf.flatten_line(img_data_i, order=1)\n",
    "            # if param_i == 'Topography':\n",
    "            #     img_data_i = data_dict['Topography'][f'Image {img_dir} with Forward Ramps']\n",
    "            # else:\n",
    "            #     img_data_i = param_data_dict[param_i][img_dir]\n",
    "            x_data, y_data = img_data_i['X'], img_data_i['Y']\n",
    "            # for j, lab_j in enumerate(labels_selected):\n",
    "            val_j = img_data_i['Z'].flatten().tolist()\n",
    "            xy_j = np.argwhere(img_data_i['Z'] > -np.inf).tolist() #CHECK. IMPROVE THIS\n",
    "            # xy_i = np.indices(img_data_i['Z'].shape)\n",
    "            x_val_j = [x_data[kx] for kx, _ in xy_j]\n",
    "            y_val_j = [y_data[ky] for _, ky in xy_j]\n",
    "            val_jnum = len(val_j)\n",
    "            paramval_dict['file'] += [file_j]*val_jnum\n",
    "            paramval_dict['x'] += x_val_j\n",
    "            paramval_dict['y'] += y_val_j\n",
    "            paramval_dict['channel'] += [f\"{param_i} [{unit_text}]\"]*val_jnum\n",
    "            paramval_dict['direction'] += [img_dir]*val_jnum\n",
    "            paramval_dict['value'] += val_j\n",
    "                # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "                # paramval_dict['value median'].append(np.median(val_j))\n",
    "                # paramval_dict['value std'].append(np.std(val_j))\n",
    "                # val_j = img_data_i['data']['Z'][label_data==lab_j].flatten()\n",
    "                # paramval_dict['parameter'].append(param_i)\n",
    "                # paramval_dict['direction'].append(img_dir)\n",
    "                # paramval_dict['label'].append(lab_j)\n",
    "                # paramval_dict['value mean'].append(np.mean(val_j))\n",
    "                # paramval_dict['value median'].append(np.median(val_j))\n",
    "                # paramval_dict['value std'].append(np.std(val_j))\n",
    "    \n",
    "    paramval_df = pd.DataFrame(paramval_dict)\n",
    "    \n",
    "    # dash6_datadict['full'] = paramval_df #FIX THIS> FULL DATAFRAME CREATE\n",
    "    dash6_datadict['long'] = paramval_df.pivot(columns='channel', \n",
    "                                               index=['file', 'direction', 'x', 'y'],\n",
    "                                               values='value').reset_index() \n",
    "    \n",
    "    paramval_groupcols = paramval_df.columns.drop(['value', 'x', 'y']).to_list()\n",
    "    paramval_grouped = paramval_df.groupby(paramval_groupcols)\n",
    "    paramval_summary = paramval_grouped['value'].agg(['mean', 'median', 'std']).reset_index()\n",
    "    dash6_datadict['summary'] = paramval_summary\n",
    "    \n",
    "    dash6_tableout.clear_output(wait=True)\n",
    "    with dash6_tableout:\n",
    "        itables.show(dash6_datadict['summary'])\n",
    "\n",
    "    #show header info\n",
    "    # header_data = dash6_datadict['header']#[img_dir][channel_top]\n",
    "    # header_series_list = []\n",
    "    # for file_i, header_data_i in header_data.items():\n",
    "    #     header_series_list.append(pd.Series(header_data_i[img_dir][param_selected[0]], name=file_i))    \n",
    "    # header_data_merged = pd.concat(header_series_list, axis=1)\n",
    "    # dash6_datadict['header table'] = header_data_merged\n",
    "    dash6_headerout.clear_output(wait=True)\n",
    "    with dash6_headerout:\n",
    "        display(ITable(dash6_datadict['header'], paging=False))\n",
    "\n",
    "\n",
    "#update color range based on histogram x axis range\n",
    "@dash6_output.capture()\n",
    "def dash6_colorhist_update(change):\n",
    "    files_selected = dash6_filebrowser.df.iloc[dash6_filebrowser.selected_rows]['file']\n",
    "    param_selected = dash6_chan_select.value \n",
    "    \n",
    "    k = len(files_selected) * len(param_selected) #x axis index before first histogram plot\n",
    "    for i in range(1, len(dash6_chan_select.value)+1):\n",
    "        dash6_figdict['a'].layout[f'coloraxis{i}']['cmin'] = 1*dash6_figdict['a'].layout[f'xaxis{k+i}']['range'][0]\n",
    "        dash6_figdict['a'].layout[f'coloraxis{i}']['cmax'] = 1*dash6_figdict['a'].layout[f'xaxis{k+i}']['range'][1]\n",
    "\n",
    "@dash6_output.capture()\n",
    "def dash6_save_click(change):\n",
    "    # img_dir = dash6_imgdir_button.value\n",
    "    # filekey = dash6_filebrowser.df.iloc[dash6_filebrowser.selected_rows]['file'] #dash6_file_select.value\n",
    "    if dash6_save_text.value == '':\n",
    "        name_prefix = 'results'\n",
    "    else:\n",
    "        name_prefix = f'{dash6_save_text.value}'\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    outputpath_imaging = outputpath / 'Imaging'\n",
    "    dash6_outfilepath = f'{outputpath_imaging}/{name_prefix}' #COMPLETE THIS! ALSO SAVE PLOTS!\n",
    "    name_suffix = f'{timestamp}'\n",
    "\n",
    "    dash6_figdict['a'].write_image(f'{dash6_outfilepath}_multifile_{name_suffix}.{plot_format}', scale=len(dash6_chan_select.value))\n",
    "        \n",
    "    with pd.ExcelWriter(f'{dash6_outfilepath}_channelstats_{name_suffix}.xlsx', mode=\"w\", engine=\"openpyxl\") as writer:\n",
    "        dash6_datadict['summary'].to_excel(writer, sheet_name=\"Statistics\")\n",
    "    with pd.ExcelWriter(f'{dash6_outfilepath}_channelstats_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "        dash6_datadict['header'].to_excel(writer, sheet_name=\"Header\")\n",
    "    with pd.ExcelWriter(f'{dash6_outfilepath}_channelstats_{name_suffix}.xlsx', mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "        dash6_datadict['long'].to_excel(writer, sheet_name=\"Data\")\n",
    "    # dash2_figdict['a'].write_image(f'{dash2_outfilepath}_spectroplot.png')\n",
    "    # dash2_figdict['b'].write_image(f'{dash2_outfilepath}_correlationplot.png')\n",
    "    # dash4_update_data('save')\n",
    "\n",
    "dash6_update_data(None)\n",
    "# with dash6_figaout:\n",
    "#     display(dash6_figdict['a'])\n",
    "\n",
    "\n",
    "# dash6_chan_select.observe(dash6_histplot_update, 'value')\n",
    "dash6_imgdir_button.observe(dash6_plot_update, 'value')\n",
    "dash6_color_button.on_click(dash6_colorhist_update)\n",
    "dash6_save_button.on_click(dash6_save_click)\n",
    "dash6_updateplot_button.on_click(dash6_plot_update)\n",
    "dash6_loaddata_button.on_click(dash6_update_data)\n",
    "\n",
    "display(dash6_box2)\n",
    "display(dash6_fig_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cf494-d4f7-4ce3-ac5d-0fb48987f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['spot1_bcpA108afterDMFagain_freeosci3.48V_setpoint3V_gain10_pllon_RH71_0053']\n",
    "file_df =  dash0_filedict['full']\n",
    "filepath_i = folderpath / file_df.loc[(file_df.file==files[0])].iloc[0].loc['name']\n",
    "img_data_i = wsxm_readchan(filepath_i, all_files=True, mute=False)\n",
    "chan = 'Excitation frequency'#'Topography', 'Normal force', 'Excitation frequency', 'Amplitude'\n",
    "chan_dir = 'Forward'\n",
    "\n",
    "freq_data = img_data_i[chan][chan_dir]#get_imgdata(spectro_data_i['Excitation frequency'][chan_dir], channel='Excitation frequency', unit_dict=unit_dict)\n",
    "\n",
    "img_data = freq_data['data']\n",
    "head_data = freq_data['header']\n",
    "# print(head_data)\n",
    "freq_res = float(head_data['Resonance frequency [Dynamic settings]'].split(' ')[0])\n",
    "print(freq_res)\n",
    "# freq_offset = float(head_data['X starting offset [General Info]'].split(' ')[0])*1000\n",
    "# freq_amp = float(head_data['X Amplitude [Control]'].split(' ')[0])*1000\n",
    "# freq_array_shifted = (img_data['X']*1000) + freq_initial - freq_offset - freq_amp\n",
    "plt.pcolormesh(img_data['X'], img_data['Y'],freq_res-img_data['Z'], cmap='afmhot')#, vmin=-0.5, vmax=3.5) #set color range here\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.pcolormesh(img_data['X'], img_data['Y'],z_flattened, cmap='afmhot', vmin=-10, vmax=250) #set color range here\n",
    "# plt.colorbar()\n",
    "plt.axis('off')\n",
    "# plt.colorbar()\n",
    "# plt.gca().set_ylim(3.5457843137254903, 15.80421568627451)\n",
    "# plt.gca().set_xlabel('Frequency [Hz]')\n",
    "# plt.gca().set_ylabel('Piezo position shifted [nm]')\n",
    "# print(plt.gca().get_ylim())\n",
    "# plt.gcf().savefig(f'{outputpath}/Imaging/topoadh_0015.png', format='png', bbox_inches='tight', \n",
    "#                   dpi=300, transparent=True)\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d72c4-f202-47d7-b6ab-f9589bf64d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(img_data['X'], img_data['Y'])\n",
    "zz = img_data['Z']\n",
    "# xind_list = [50, 60, 180, 190]\n",
    "# yind_list = [0, 80, 160, 240]\n",
    "xind_list = [10, 30, 140, 240]\n",
    "yind_list = [0, 80, 160, 240]\n",
    "# i, j = 60, 200\n",
    "# i, j = 180, 200\n",
    "points_selected = []\n",
    "for i in xind_list:\n",
    "    for j in yind_list:\n",
    "        print(xx[i][j], yy[i][j], zz[i][j])\n",
    "        points_selected.append([xx[i][j], yy[i][j], zz[i][j]])\n",
    "points_selected = np.array(points_selected)\n",
    "# print(points_selected[:,1])\n",
    "import itertools\n",
    "\n",
    "#generate Matrix to use with lstsq for levelling\n",
    "def poly_matrix(x, y, order=2):\n",
    "    ncols = (order + 1)**2\n",
    "    G = np.zeros((x.size, ncols))\n",
    "    ij = itertools.product(range(order+1), range(order+1))\n",
    "    for k, (i, j) in enumerate(ij):\n",
    "        G[:, k] = x**i * y**j\n",
    "    return G\n",
    "\n",
    "\n",
    "def level_data(img_data, points, order=1):\n",
    "    # X,Y = np.meshgrid(self.df_matrix.columns,\n",
    "    #                   self.df_matrix.index)\n",
    "    X, Y = np.meshgrid(img_data['X'], img_data['Y'])\n",
    "\n",
    "    if order == 1:\n",
    "        # best-fit linear plane\n",
    "        A = np.c_[points[:,0], points[:,1], np.ones(points.shape[0])]\n",
    "        C,_,_,_ = np.linalg.lstsq(A, points[:,2], rcond=None)    # coefficients\n",
    "        #print(C)\n",
    "        # evaluate it on grid\n",
    "        Z_zerofit = C[0]*X + C[1]*Y + C[2]\n",
    "##            print(Z)\n",
    "        # self.df['Zero fit'] = C[0]*self.df[self.plot_x] + \\\n",
    "        #                       C[1]*self.df[self.plot_y] + C[2]\n",
    "        #print(self.df)\n",
    "    elif order == 2:\n",
    "        x, y, z = points.T\n",
    "        #x, y = x - x[0], y - y[0]  # this improves accuracy\n",
    "\n",
    "        # make Matrix:\n",
    "        G = poly_matrix(x, y, order)\n",
    "        # Solve for np.dot(G, m) = z:\n",
    "        m = np.linalg.lstsq(G, z, rcond=None)[0]\n",
    "        #print('m', m)\n",
    "        # Evaluate it on a grid...\n",
    "##            GG = self.poly_matrix(X.ravel(), Y.ravel(), order)\n",
    "##            Z = np.reshape(np.dot(GG, m), X.shape)\n",
    "##            print(Z)\n",
    "        df['Zero fit'] = np.polynomial.polynomial.polyval2d(df[plot_x],\n",
    "                                                                 df[plot_y],\n",
    "                                                                 np.reshape(m, (-1, 3)))\n",
    "    \n",
    "    # df[plot_z+' corrected'] = df[plot_z]-df['Zero fit']\n",
    "    Z_leveled = img_data['Z'] - Z_zerofit\n",
    "    \n",
    "    #organize data into matrix for heatmap plot\n",
    "    # self.df_matrix = self.df.pivot_table(values=self.plot_z+' corrected',\n",
    "    #                                      index=self.plot_y,\n",
    "    #                                      columns=self.plot_x,\n",
    "    #                                      aggfunc='first')\n",
    "    return Z_leveled - Z_leveled.min()\n",
    "\n",
    "z_flattened = level_data(img_data, points_selected, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d53536-bfd1-4efd-b4c3-3c24fffeace0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = ['thiolinterdigi_thiolspot2_tipAC240TS_3dmode_freqsweep_osc0.0005V_gain100_0279',\n",
    "         'thiolinterdigi_glassspot2_tipAC240TS_3dmode_freqsweep_osc0.0005V_gain100_0257']\n",
    "file_df =  dash0_filedict['full']\n",
    "filepath_i = folderpath + '/' + file_df.loc[(file_df.file==files[0])].iloc[0].loc['name']\n",
    "z_shift = 4.235\n",
    "spectro_data_i = wsxm_readchan(filepath_i, all_files=True, mute=False)\n",
    "chan = 'True Amplitude'#'Topography', 'Normal force', 'Excitation frequency', 'Amplitude'\n",
    "chan_dir = 'Forward'\n",
    "amp_data = {}\n",
    "chan_dirs = list(spectro_data_i[chan].keys())\n",
    "for dir_i in chan_dirs:\n",
    "    im_data_i = spectro_data_i[chan][dir_i]\n",
    "    amp_data[dir_i] = get_imgdata(im_data_i, channel=chan, unit_dict=unit_dict)\n",
    "\n",
    "img_data = amp_data[chan_dir]\n",
    "head_data = spectro_data_i[chan][chan_dir]['header']\n",
    "\n",
    "freq_initial = float(head_data['Resonance frequency [Dynamic settings]'].split(' ')[0])\n",
    "freq_offset = float(head_data['X starting offset [General Info]'].split(' ')[0])*1000\n",
    "freq_amp = float(head_data['X Amplitude [Control]'].split(' ')[0])*1000\n",
    "freq_array_shifted = (img_data['X']*1000) + freq_initial - freq_offset - freq_amp\n",
    "plt.pcolormesh(freq_array_shifted, -img_data['Y']-z_shift,img_data['Z'], cmap='afmhot')#, vmin=-0.2, vmax=0.2) #set color range here\n",
    "plt.gca().set_ylim(3.5457843137254903, 15.80421568627451)\n",
    "# plt.gca().set_xlabel('Frequency [Hz]')\n",
    "# plt.gca().set_ylabel('Piezo position shifted [nm]')\n",
    "print(plt.gca().get_ylim())\n",
    "plt.gcf().savefig(f'{outputpath}/Specroscopy/thiol_3dfreq_0279.png', format='png', bbox_inches='tight', \n",
    "                  dpi=2400, transparent=True)\n",
    "# plt.colorbar()\n",
    "plt.show()\n",
    "# img_data['X']\n",
    "# freq_offset, freq_initial, head_data\n",
    "\n",
    "#find index in \"a\" closest to val\n",
    "def find_index(a, val):\n",
    "    return np.argmin(abs(a-val))\n",
    "\n",
    "spectro_data = spectro_data_i['Normal force'][chan_dir]['data']\n",
    "minarg = np.argmin(spectro_data['Z'][:,0])\n",
    "\n",
    "\n",
    "#plot spectra and fit at index\n",
    "z_list = [10, 7, 5]\n",
    "z_ind_list = [find_index(-img_data['Y'], val) for val in z_list]\n",
    "    \n",
    "fit_results = {'Z':[], 'Normal force':[], 'Resonance frequency': [] , 'Q factor': [], \n",
    "               'FWHM': [], 'Area': [], 'Amp max': [], 'Amp rms': []} \n",
    "color_list = iter(px.colors.qualitative.Light24)\n",
    "for i in range(img_data['Z'].shape[0]):\n",
    "    # psd_final = z_pow_mean[i,:]\n",
    "    #smooth data\n",
    "    # psd_smooth = rollavg_cumsum_edges(psd_final, smooth_window)\n",
    "    freqresponse_i = img_data['Z'][i,:]\n",
    "\n",
    "    #guess = [0, 76000, 2000, 100000]\n",
    "    y_guess = 0 #psd_final.min()\n",
    "    f_guess = freq_array_shifted[freqresponse_i.argmax()]\n",
    "    w_guess = 2*np.abs(freq_array_shifted[(np.abs(freqresponse_i - freqresponse_i.max()/2)).argmin()]-f_guess)\n",
    "    A_guess = np.pi*w_guess*freqresponse_i.max()/2\n",
    "    guess = [y_guess, f_guess, w_guess, A_guess] #y0,f0,w,A\n",
    "    # print(guess)\n",
    "    #fit\n",
    "    try:\n",
    "        popt, pcov = curve_fit(ftf.lorentzian, freq_array_shifted,freqresponse_i,\n",
    "                            p0=guess, bounds=(0,np.inf))\n",
    "    except:\n",
    "        continue\n",
    "    #print(np.linalg.cond(pcov))\n",
    "    params = ['offset','resonance freq', 'fwhm', 'area']\n",
    "    fit_dict = dict(zip(params, popt))\n",
    "    # fit_dict['Q factor'] = fit_dict['resonance freq']/fit_dict['fwhm']    \n",
    "    if i > minarg:\n",
    "        q_factor = popt[1]/popt[2]\n",
    "        fit_results['Resonance frequency'].append(popt[1])\n",
    "        fit_results['FWHM'].append(popt[2])\n",
    "        fit_results['Area'].append(popt[3])\n",
    "        fit_results['Q factor'].append(q_factor)\n",
    "        amp_max = popt[0] + (2*popt[3]/(np.pi*popt[2])) #amp_max = y0 + 2A/(pi*w)\n",
    "        fit_results['Amp max'].append(amp_max)\n",
    "    else:\n",
    "        fit_results['Resonance frequency'].append(np.nan)\n",
    "        fit_results['FWHM'].append(np.nan)\n",
    "        fit_results['Area'].append(np.nan)\n",
    "        fit_results['Q factor'].append(np.nan)\n",
    "        fit_results['Amp max'].append(np.nan)\n",
    "    fit_results['Z'].append(-img_data['Y'][i])\n",
    "    fit_results['Normal force'].append(spectro_data['Z'][i,:].mean())\n",
    "    \n",
    "    #calcualte rms amplitude for each line\n",
    "    amp_list = []\n",
    "    for dir_i in chan_dirs:\n",
    "        amp_i = amp_data[dir_i]['Z'][i,:].flatten()\n",
    "        amp_list.append(amp_i)\n",
    "    amp_full = np.concatenate(amp_list)\n",
    "    amp_rms = np.sqrt(amp_full.dot(amp_full)/amp_full.size)\n",
    "    fit_results['Amp rms'].append(amp_rms)\n",
    "    \n",
    "    #plot only spectra naf fits corresponding to z_list indices\n",
    "    if i in z_ind_list:\n",
    "        color = next(color_list)\n",
    "        plt.plot(freq_array_shifted, freqresponse_i, color=color, alpha=0.4)\n",
    "        # plt.plot(freq_array_shifted, psd_smooth, ':', color=color,)\n",
    "        f_min, f_max = freq_array_shifted.min(), freq_array_shifted.max()\n",
    "        f_ext = 0.1*(f_max-f_min)\n",
    "        freq_fit_range = np.linspace(f_min-f_ext, f_max+f_ext, 100000)\n",
    "        z_val = -img_data['Y'][i]\n",
    "        plt.plot(freq_fit_range,ftf.lorentzian(freq_fit_range, *popt), '-', color=color, label=f'{z_val:,.2f} nm')\n",
    "        plt.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "font_dict = dict(family='Arial', size=18)\n",
    "fit_df = pd.DataFrame(fit_results)\n",
    "# fit_df['Resonance frequency'] = fit_df['Resonance frequency'] - 89673 #SHIFT FREQUENCY\n",
    "fit_df_long = pd.melt(fit_df, id_vars=['Z'], value_vars=fit_df.columns.drop('Z'))\n",
    "fig, _ = plotly_multiyplot(data=fit_df_long, multiy_col='variable', x='Z', y='value',\n",
    "                           yvars=['Resonance frequency', 'Normal force', 'Amp max'],  #'Resonance frequency', 'Q factor', 'Normal force', 'Amp max'\n",
    "                           symbol='variable',\n",
    "                           font_dict=font_dict, marker_size=5, line_width=1) \n",
    "display(fig)\n",
    "display(fit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc2e85-96e5-44e1-b124-f45e25d3d889",
   "metadata": {},
   "source": [
    "### 3D plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40666343-5c2f-47b6-a10e-90eca3c7247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['interdigThiols1week_tipDiam3nN_heated_0014', #adhesion\n",
    "         'interdigThiols1week_tipDiam3nN_heated_0002'] #freqshift\n",
    "file_df =  dash0_filedict['full']\n",
    "filepath_i = folderpath + '/' + file_df.loc[(file_df.file==files[1])].iloc[0].loc['name']\n",
    "file_data = wsxm_readchan(filepath_i, all_files=True, mute=False)\n",
    "chan1 = 'Topography'#'Topography', 'Normal force', 'Excitation frequency', 'Amplitude'\n",
    "chan2 = 'Excitation frequency' #Excitation frequency, Adhesion\n",
    "chan_dir = 'Forward'\n",
    "chan1_data = get_imgdata(file_data[chan1][chan_dir], channel=chan1)\n",
    "chan2_data = get_imgdata(file_data[chan2][chan_dir], channel=chan1)\n",
    "# head_data = spectro_data_i[chan][chan_dir]['header']\n",
    "\n",
    "cmap_dict = {'cmap_name': 'Bluered', 'source': 'plotly', 'reverse': False} #colormap name (check matplotlib/plotly colourmaps)\n",
    "unit_text1 = unit_dict[chan1]\n",
    "unit_text2 = unit_dict[chan2]\n",
    "vmin = 0.3#np.percentile(chan1_data['Z'],0)/1000\n",
    "vmax = 0.6#np.percentile(chan1_data['Z'],100)/1000\n",
    "cmin = np.percentile(chan2_data['Z'],1)\n",
    "cmax = np.percentile(chan2_data['Z'],90)\n",
    "\n",
    "# interdigThiols1week_tipDiam3nN_heated_0014 \n",
    "# interdigThiols1week_tipDiam3nN_heated_0002 \n",
    "font_dict=dict(family='Arial', size=12)\n",
    "font_dict_axtick=dict(family='Arial', size=14) #for axis ticks\n",
    "#create initial figure\n",
    "fig3d = plotly_3dplot(z_3d=chan1_data['Z']/1000, z_colour=chan2_data['Z'], #cmap=matplotlib_to_plotly(**cmap_dict),\n",
    "                            x= chan1_data['X'], y=chan1_data['Y'], width=1000, height=600,\n",
    "                            aspectratio_z=0.3, nticks_z=4, nticks_x=6, nticks_y=6,\n",
    "                            font_dict=font_dict)\n",
    "fig3d_wid = go.FigureWidget(fig3d)\n",
    "\n",
    "fig3d_wid.data[0].coloraxis = 'coloraxis1'\n",
    "fig3d_wid.layout.coloraxis1.cmin=cmin\n",
    "fig3d_wid.layout.coloraxis1.cmax=cmax\n",
    "fig3d_wid.update_layout(title=dict(text=f\"{chan1} [{unit_text1}]\", font=font_dict),\n",
    "                                  coloraxis1=dict(colorscale=matplotlib_to_plotly(**cmap_dict),#cmin=68500, cmax=69600,\n",
    "                                                  colorbar=dict(len=0.7, x=0.9, y=0.5, thickness=15,\n",
    "                                                                orientation='v', xanchor='center', \n",
    "                                                                yanchor='middle', title=f\"{chan2} [{unit_text2}]\",\n",
    "                                                               title_font=font_dict, title_side='right', tickfont=font_dict)),\n",
    "                                  scene=dict(xaxis=dict(title=dict(text=f\"X [{unit_dict['X']}]\", font=font_dict),\n",
    "                                                       tickfont=font_dict_axtick,),\n",
    "                                             yaxis=dict(title=dict(text=f\"Y [{unit_dict['Y']}]\", font=font_dict),\n",
    "                                                       tickfont=font_dict_axtick),\n",
    "                                             # xaxis_tickfont=font_dict,\n",
    "                                             # yaxis_tickfont=font_dict,\n",
    "                                             zaxis=dict(title=\"\", tickfont=font_dict_axtick,\n",
    "                                                        range=[vmin, vmax]),#to avoid overlapping zeroes\n",
    "                                             zaxis_tickvals = [0.4,0.5] #set tickvalues manually for z axis\n",
    "                                            )\n",
    "                                 )\n",
    "display(fig3d_wid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae5bef-981e-4926-9d1a-2188f68cac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d_wid.layout.scene.xaxis.title.text=''\n",
    "fig3d_wid.layout.scene.yaxis.title.text=''\n",
    "fig3d_wid.layout.coloraxis.showscale=False\n",
    "fig3d_wid.layout.title.text=''\n",
    "fig3d_wid.update_layout(\n",
    "    {\n",
    "        \"paper_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "        \"plot_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "    }\n",
    ")\n",
    "\n",
    "fig3d_wid.update_layout(#plot_bgcolor='rgb(12,163,135)',\n",
    "                  #paper_bgcolor='rgb(12,163,135)'\n",
    "                  #coloraxis={\"colorbar\": {\"x\": -0.2, \"len\": 0.5, \"y\": 0.8}}, #I think this is for contours\n",
    "                 scene = dict(\n",
    "                                xaxis = dict(\n",
    "                                     backgroundcolor=\"rgba(0, 0, 0,0)\",\n",
    "                                     gridcolor=\"gray\",\n",
    "                                     showbackground=True,\n",
    "                                     zerolinecolor=\"gray\",\n",
    "                                ),\n",
    "                                yaxis = dict(\n",
    "                                    backgroundcolor=\"rgba(0, 0, 0,0)\",\n",
    "                                    gridcolor=\"gray\",\n",
    "                                    showbackground=True,\n",
    "                                    zerolinecolor=\"gray\"\n",
    "                                ),\n",
    "                                zaxis = dict(\n",
    "                                    backgroundcolor=\"rgba(0, 0, 0,0)\",\n",
    "                                    gridcolor=\"gray\",\n",
    "                                    showbackground=True,\n",
    "                                    zerolinecolor=\"gray\",\n",
    "                                ),\n",
    "                 ),\n",
    "                 )\n",
    "fig3d_wid.write_image(f'{outputpath}/Imaging/interdigi_topofreq_3dplot_0002.png', scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb02c7e-2b6a-462c-a268-8292a803374f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate rolling average of window n to smoooth data a\n",
    "def rollavg_cumsum_edges(a,n):\n",
    "    assert n%2==1\n",
    "    if n == 1:\n",
    "        return a\n",
    "    else:\n",
    "        N = len(a)\n",
    "        cumsum_vec = np.cumsum(np.insert(np.pad(a,(n-1,n-1),'constant'), 0, 0)) \n",
    "        d = np.hstack((np.arange(n//2+1,n),np.ones(N-n)*n,np.arange(n,n//2,-1)))  \n",
    "        return (cumsum_vec[n+n//2:-n//2+1] - cumsum_vec[n//2:-n-n//2]) / d\n",
    "\n",
    "#find index in \"a\" closest to val\n",
    "def find_index(a, val):\n",
    "    return np.argmin(abs(a-val))\n",
    "\n",
    "folderpath_i = '/home/pranav/Work/Data/Murcia/AFM2/20240517 thiol interdigielec old_ctd/'\n",
    "filepath_i = f'{folderpath_i}/3dmode_ampz_glassonly_range15nm_0185.b.dy.ch1'\n",
    "# filepath_i = f'{folderpath_i}/3dmode_ampz_thiolonly_range10nm_0182.f.dy.ch15'\n",
    "spectro_data_i = wsxm_readchan(filepath_i, all_files=True, mute=False)\n",
    "chan = 'Amplitude'#'Topography', 'Normal force', 'Excitation frequency', 'Amplitude'\n",
    "\n",
    "amp_data = {}\n",
    "chan_dirs = list(spectro_data_i[chan].keys())\n",
    "for dir_i in chan_dirs:\n",
    "    im_data_test = spectro_data_i[chan][dir_i]\n",
    "    im_data_test['data']['Y'] = 1.9*im_data_test['data']['Y'] #PIEZO CALIBRATION CORRECTION! REMOVE LATER!\n",
    "    xx, yy, amp_data[dir_i] = get_imgdata(im_data_test)\n",
    "\n",
    "head_data = im_data_test['header']\n",
    "print(head_data['Y scanning direction'])\n",
    "\n",
    "zz = amp_data[chan_dirs[0]]\n",
    "plt.pcolormesh(xx,-yy,zz, cmap='afmhot', vmin=-0.2, vmax=0.2) #set color range here\n",
    "# plt.colorbar()\n",
    "plt.show()\n",
    "# plt.plot(zz.flatten())\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "sample_rate = float(head_data['Sampling frequency'].split(' ')[0])\n",
    "freq_drive = float(head_data['Resonance frequency'].split(' ')[0])\n",
    "freq_array, z_pow = signal.periodogram(zz, sample_rate, scaling='density') #power spectral density\n",
    "freq_array_shifted = freq_array + freq_drive\n",
    "ff, yy = np.meshgrid(freq_array_shifted, -im_data_test['data']['Y'])\n",
    "plt.pcolormesh(ff, yy, z_pow, cmap='afmhot', vmin=z_pow.min(), vmax=0.1*z_pow.max())\n",
    "# plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "split_num = 4 #powers of 2 eg.2,4,8,16\n",
    "smooth_window = 9\n",
    "pts = int(zz.shape[1]/split_num)\n",
    "z_pow_list = []\n",
    "for i in range(split_num):\n",
    "    for dir_i in chan_dirs[:2]:\n",
    "        amp_i = amp_data[dir_i][:,i*pts:(i+1)*pts] \n",
    "        freq_array, z_pow = signal.periodogram(amp_i, sample_rate, scaling='density') #power spectral density\n",
    "        freq_array_shifted = freq_array + freq_drive\n",
    "        z_pow_list.append(z_pow)\n",
    "        # print(freq_array.shape, z_pow.shape)\n",
    "    \n",
    "plt.show()\n",
    "z_pow_mean = np.mean(z_pow_list, axis=0)\n",
    "ff, yy = np.meshgrid(freq_array_shifted, -im_data_test['data']['Y'])\n",
    "plt.pcolormesh(ff, yy, z_pow_mean, cmap='afmhot', vmin=z_pow_mean.min(), vmax=0.1*z_pow_mean.max())\n",
    "# plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "spectro_data = spectro_data_i['Normal force']['Forward']['data']\n",
    "minarg = np.argmin(spectro_data['Z'][:,0])\n",
    "\n",
    " #plot spectra and fit at index\n",
    "z_list = [5.4, 6, 10]\n",
    "z_ind_list = [find_index(-im_data_test['data']['Y'], val) for val in z_list]\n",
    "    \n",
    "fit_results = {'Z':[], 'Normal force':[], 'Resonance frequency': [] , 'Q factor': [], 'FWHM': [], 'Area': [], 'Amp rms': []} \n",
    "color_list = iter(sns.color_palette())\n",
    "for i in range(z_pow_mean.shape[0]):\n",
    "    psd_final = z_pow_mean[i,:]\n",
    "    #smooth data\n",
    "    psd_smooth = rollavg_cumsum_edges(psd_final, smooth_window)\n",
    "\n",
    "    #guess = [0, 76000, 2000, 100000]\n",
    "    y_guess = 0 #psd_final.min()\n",
    "    f_guess = freq_array_shifted[psd_smooth.argmax()]\n",
    "    w_guess = 2*np.abs(freq_array_shifted[(np.abs(psd_smooth - psd_smooth.max()/2)).argmin()]-f_guess)\n",
    "    A_guess = np.pi*w_guess*psd_smooth.max()/2\n",
    "    guess = [y_guess, f_guess, w_guess, A_guess] #y0,f0,w,A\n",
    "    # print(guess)\n",
    "    #fit\n",
    "    popt, pcov = curve_fit(lorentzian, freq_array_shifted,psd_smooth,\n",
    "                        p0=guess, bounds=(0,np.inf))\n",
    "    #print(np.linalg.cond(pcov))\n",
    "    params = ['offset','resonance freq', 'fwhm', 'area']\n",
    "    fit_dict = dict(zip(params, popt))\n",
    "    # fit_dict['Q factor'] = fit_dict['resonance freq']/fit_dict['fwhm']    \n",
    "    if i > minarg:\n",
    "        q_factor = popt[1]/popt[2]\n",
    "        fit_results['Resonance frequency'].append(popt[1])\n",
    "        fit_results['FWHM'].append(popt[2])\n",
    "        fit_results['Area'].append(popt[3])\n",
    "        fit_results['Q factor'].append(q_factor)\n",
    "    else:\n",
    "        fit_results['Resonance frequency'].append(np.nan)\n",
    "        fit_results['FWHM'].append(np.nan)\n",
    "        fit_results['Area'].append(np.nan)\n",
    "        fit_results['Q factor'].append(np.nan)\n",
    "    fit_results['Z'].append(-im_data_test['data']['Y'][i])\n",
    "    fit_results['Normal force'].append(spectro_data['Z'][i,0])\n",
    "    \n",
    "    #calcualte rms amplitude for each line\n",
    "    amp_list = []\n",
    "    for dir_i in chan_dirs:\n",
    "        amp_i = amp_data[dir_i][i,:].flatten()\n",
    "        amp_list.append(amp_i)\n",
    "    amp_full = np.concatenate(amp_list)\n",
    "    amp_rms = np.sqrt(amp_full.dot(amp_full)/amp_full.size)\n",
    "    fit_results['Amp rms'].append(amp_rms)\n",
    "    \n",
    "    #plot only spectra naf fits corresponding to z_list indices\n",
    "    if i in z_ind_list:\n",
    "        color = next(color_list)\n",
    "        plt.plot(freq_array_shifted, psd_final, color=color, alpha=0.4)\n",
    "        plt.plot(freq_array_shifted, psd_smooth, ':', color=color,)\n",
    "        f_min, f_max = freq_array_shifted.min(), freq_array_shifted.max()\n",
    "        f_ext = 0.1*(f_max-f_min)\n",
    "        freq_fit_range = np.linspace(f_min-f_ext, f_max+f_ext, 100000)\n",
    "        z_val = -im_data_test['data']['Y'][i]\n",
    "        plt.plot(freq_fit_range,lorentzian(freq_fit_range, *popt), '-', color=color, label=f'{z_val:,.2f} nm')\n",
    "        plt.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "fit_df = pd.DataFrame(fit_results)\n",
    "fit_df['Resonance frequency'] = fit_df['Resonance frequency'] - 89673 #SHIFT FREQUENCY\n",
    "fit_df_long = pd.melt(fit_df, id_vars=['Z'], value_vars=fit_df.columns.drop('Z'))\n",
    "fig, _ = plotly_multiyplot(data=fit_df_long, multiy_col='variable', x='Z', y='value',\n",
    "                           yvars=['Resonance frequency', 'FWHM', 'Normal force', 'Amp rms'], font_dict=font_dict) \n",
    "display(fig)\n",
    "display(fit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a6112-773f-4ae6-8f22-cdeb9d9ff795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.widgets import Slider\n",
    "\n",
    "mapa = np.loadtxt('data/Mapa3M3alargadotodo.txt')\n",
    "X=mapa[1:,0]\n",
    "Y=mapa[1:,1]\n",
    "F = mapa[0,2:]\n",
    "Z0=mapa[1:,2]\n",
    "df0 = pd.DataFrame({'X':X, 'Y':Y, 'Z':Z0})\n",
    "z_pivot0 = df0.pivot(index='Y', columns='X', values='Z')\n",
    "\n",
    "x_val = z_pivot0.columns.values\n",
    "y_val = z_pivot0.index.values\n",
    "\n",
    "xx, yy = np.meshgrid(x_val,y_val)\n",
    "\n",
    "# The parametrized function to be plotted\n",
    "def update_data(frequency):\n",
    "    ind = np.argmin(abs(F-frequency))\n",
    "    Z=mapa[1:,ind+2]\n",
    "    print(ind, frequency)\n",
    "    df = pd.DataFrame({'X':X, 'Y':Y, 'Z':Z})\n",
    "    z_pivot = df.pivot(index='Y', columns='X', values='Z')\n",
    "    return z_pivot.values\n",
    "\n",
    "# Create the figure and the line that we will manipulate\n",
    "fig, ax = plt.subplots()\n",
    "cplot = ax.pcolormesh(xx, yy, update_data(F[0]), cmap='viridis')\n",
    "cbar = plt.colorbar(cplot)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "\n",
    "# Make a horizontal slider to control the frequency.\n",
    "axfreq = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "freq_slider = Slider(\n",
    "    ax=axfreq,\n",
    "    label='Frequency [Hz]',\n",
    "    valmin=F.min(),\n",
    "    valmax=F.max(),\n",
    "    valinit=F[0],\n",
    ")\n",
    "\n",
    "def update_plot(val):\n",
    "    new_z = update_data(val)\n",
    "    cplot.set_array(new_z.ravel())\n",
    "    \n",
    "    # Manually update the color limits. Set cmin, cmax to fixed values if you don't want to update colours\n",
    "    cmin, cmax = np.nanmin(new_z), np.nanmax(new_z)\n",
    "    cplot.set_clim(vmin=cmin, vmax=cmax)\n",
    "    \n",
    "    cbar.update_normal(cplot)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "freq_slider.on_changed(update_plot) # register the update function with each slider\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba0d75-946e-4ee9-8622-343df9094fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8afc40-c30f-4516-8f75-01a5f52a8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "plt.close()\n",
    "file_i = 'interdigThiols_tipSi3nN_a_0003'\n",
    "file_df =  dash0_filedict['full']\n",
    "filepath_i = folderpath + '/' + file_df_spectro.loc[(file_df_spectro.file==file_i)].iloc[0].loc['name']\n",
    "spectro_data_i = wsxm_readspectra(filepath_i, all_files=True, mute=True)\n",
    "chan_i = 'Amplitude'\n",
    "curv_ind = 4\n",
    "segment = 'approach'\n",
    "amp_data = spectro_data_i[chan_i]['curves'][curv_ind]['data']\n",
    "plt.figure()\n",
    "plt.plot(amp_data[segment]['x'], amp_data[segment]['y'])\n",
    "\n",
    "amp_sobel = np.gradient(amp_data[segment]['y']) #sobel transform ndimage.sobel\n",
    "plt.plot(amp_data[segment]['x'], amp_sobel)\n",
    "# amp_sobel2 = ndimage.sobel(amp_sobel) #sobel transform\n",
    "# plt.plot(spectro_data_chani['x'], amp_sobel2)\n",
    "# plt.show()\n",
    "ind_max = np.argmax(amp_sobel)\n",
    "sobel_perc = np.percentile(amp_sobel, 95)\n",
    "# plt.hlines(sobel_perc, 0,100)\n",
    "# plt.hlines(amp_sobel[ind_max], 0,100)\n",
    "# ind1 = ind_max+np.argmin(abs(amp_sobel[ind_max:]-sobel_perc))\n",
    "# plt.vlines(spectro_data_chani['x'][ind1], -0.1,0.05)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2) # Create a KMeans instance with 2 clusters: kmeans\n",
    "kmeans.fit(amp_sobel.reshape(-1, 1)) \n",
    "centroids = kmeans.cluster_centers_\n",
    "low_cluster, high_cluster = (0, 1) if centroids[0] < centroids[1] else (1, 0) #Get higher value clusters\n",
    "labels = kmeans.labels_\n",
    "high_cluster_data = amp_sobel[labels == high_cluster]\n",
    "high_cluster_indices = np.where(labels.reshape(amp_sobel.shape) == high_cluster)[0]\n",
    "\n",
    "plt.plot(amp_data[segment]['x'][high_cluster_indices], amp_sobel[high_cluster_indices], 'r')\n",
    "\n",
    "p, res, rank, sing, rcond = np.polyfit(amp_data[segment]['x'][high_cluster_indices],\n",
    "                                       amp_data[segment]['y'][high_cluster_indices], 1, full=True)\n",
    "poly = np.poly1d(p)\n",
    "fit_data = {'x': amp_data[segment]['x'][high_cluster_indices], 'y': poly(amp_data[segment]['x'][high_cluster_indices])}\n",
    "plt.plot(fit_data['x'], fit_data['y'], ':r')\n",
    "print(p)\n",
    "# slop_max = amp_sobel[ind_max]\n",
    "# poly = np.poly1d([-slop_max,1.25])\n",
    "# plt.plot(spectro_data_chani['x'][high_cluster_indices], poly(spectro_data_chani['x'][high_cluster_indices]), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba44347-bb7b-4a02-b181-23586d1d21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dashboard 4: Spectroscopy data viewer\n",
    "\n",
    "\n",
    "#close dashboard-4 figure if already open\n",
    "for fignum_i in plt.get_fignums():\n",
    "    figlab_i = plt.figure(fignum_i).get_label()\n",
    "    if figlab_i == 'dash4':\n",
    "        plt.close(figlab_i) \n",
    "    \n",
    "fig4, ax4 = plt.subplots(1,1, figsize=(10.5,4), num='dash4',layout='constrained')\n",
    "ax2_spec = [ax2[1], ax2[1].twinx(), ax2[1].twinx()]\n",
    "ax2_spec[-1].spines['right'].set_position(('axes', 1.3))\n",
    "fig2.canvas.header_visible = False\n",
    "fig2.canvas.toolbar_position = 'bottom'\n",
    "\n",
    "#topography\n",
    "xx, yy, zz = get_imgdata(data_dict['Topography'][f'Image {img_dir} with Forward Ramps'])\n",
    "vmin, vmax = zz.min(), zz.max()\n",
    "pmesh_top2 = ax2[0].pcolormesh(xx,yy,zz, cmap='afmhot',vmin=chan_mins['Topography'],\n",
    "                                vmax=chan_maxs['Topography'])\n",
    "cb_top2 = plt.colorbar(pmesh_top2, ax=ax2[0])\n",
    "\n",
    "#spectroscopy\n",
    "spec_dir = 'approach'\n",
    "color_list = sns.color_palette()\n",
    "spec_line2 = {}\n",
    "for i, channel in enumerate(chan_list):\n",
    "    spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir)\n",
    "    df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel)\n",
    "    df_spectro['channel'] = channel\n",
    "    df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "    spec_line2[channel] = sns.lineplot(data=df_spectro_filt, x=\"x\", y=\"y\", ax=ax2_spec[i], color=color_list[i])\n",
    "    ax2_spec[i].set_ylabel(channel)\n",
    "    ax2_spec[i].yaxis.label.set_color(color_list[i])\n",
    "    ax2_spec[i].tick_params(axis='y', colors=color_list[i]) \n",
    "\n",
    "ax2_spec[0].set_xlabel('Z')\n",
    "\n",
    "#position lines on topo\n",
    "line_h2 = ax2[0].axhline(ymin, xmin, xmax, linestyle='solid', color='r')\n",
    "line_v2 = ax2[0].axvline(xmin, ymin, ymax, linestyle='solid', color='r')\n",
    "# plt.tight_layout()\n",
    "\n",
    "#widgets\n",
    "slide_x2 = widgets.IntSlider(value=xmin, min=xmin, max=xmax, step=(xmax-xmin)/x_num,\n",
    "                            description='x')\n",
    "slide_y2 = widgets.IntSlider(value=ymin, min=ymin, max=ymax, step=(ymax-ymin)/y_num,\n",
    "                            description='y')\n",
    "slide_zrange2 = widgets.IntSlider(value=zmax, min=zmin, max=zmax, step=(zmax-zmin)/z_num,\n",
    "                            description='z limit')\n",
    "slide_cb2 = widgets.FloatRangeSlider(value=[vmin, vmax], min=vmin, max=vmax,\n",
    "                                     step=(vmax-vmin)/100, description='color',readout=True)\n",
    "specdir_button2 = widgets.ToggleButtons(options=['approach', 'retract'], #CHANGE TO MULTIPLE SELECT!\n",
    "                                    # description='Channel:',\n",
    "                                     disabled=False)\n",
    "imgdir_button2 = widgets.ToggleButtons(options=['Forward', 'Backward'],\n",
    "                                    # description='Channel:',\n",
    "                                     disabled=False)\n",
    "param_dropdown2 = widgets.Dropdown(options=param_list,\n",
    "                                  value='Topography',disabled=False)\n",
    "dash2_output = widgets.Output()\n",
    "dash2_box1 = widgets.VBox([slide_x2, slide_y2, slide_zrange2, slide_cb2])\n",
    "dash2_box2 = widgets.VBox([param_dropdown2, imgdir_button2])\n",
    "dash2_box3 = widgets.VBox([specdir_button2])\n",
    "\n",
    "#update functions\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_x(change):\n",
    "    img_dir = imgdir_button2.value\n",
    "    spec_dir = specdir_button2.value\n",
    "    x_pt = change.new\n",
    "    y_pt = slide_y2.value\n",
    "\n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    for i, channel in enumerate(chan_list):\n",
    "        spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "        df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel)\n",
    "        df_spectro['channel'] = channel\n",
    "        df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "        spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "        ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    line_v2.set_xdata([x_pt]) #vertical line on topo\n",
    "    fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_y(change):\n",
    "    img_dir = imgdir_button2.value\n",
    "    spec_dir = specdir_button2.value\n",
    "    x_pt = slide_x2.value\n",
    "    y_pt = change.new\n",
    "    \n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    for i, channel in enumerate(chan_list):\n",
    "        spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "        df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel)\n",
    "        df_spectro['channel'] = channel\n",
    "        df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "        spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "        ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    line_h2.set_ydata([y_pt]) #horizontal line on topo\n",
    "    fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_zrange(change):\n",
    "    z_new = change.new\n",
    "    for i, channel in enumerate(chan_list):\n",
    "        ax2_spec[i].set_xlim(zmin, z_new)\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_param(change):\n",
    "    img_dir = imgdir_button2.value\n",
    "    if change.new == 'Topography':\n",
    "        xx, yy, zz = get_imgdata(data_dict[change.new][f'Image {img_dir} with Forward Ramps'])\n",
    "    else:\n",
    "        xx, yy, zz = get_imgdata(param_data_dict[change.new][imgdir_button2.value])\n",
    "    pmesh_top2.set_array(zz)\n",
    "    vmin, vmax = zz.min(), zz.max()\n",
    "    pmesh_top2.set_clim(vmin, vmax)\n",
    "    cb_top2.mappable.set_clim(vmin, vmax)\n",
    "    fig2.canvas.draw()\n",
    "\n",
    "    #reinitialize colorbar to new values of channel(works somehow)\n",
    "    slide_cb2.unobserve(dash2_update_colorbar, 'value')\n",
    "    slide_cb2.min, slide_cb2.max = -1e100, 1e100 #to avoid error of min, max classh from previous value\n",
    "    slide_cb2.step = (vmax-vmin)/100\n",
    "    slide_cb2.value = (vmin, vmax)\n",
    "    # slide_cb.min, slide_cb.max = chan_mins[channel], chan_maxs[channel]\n",
    "    slide_cb2.observe(dash2_update_colorbar, 'value')\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_imgdir(change):\n",
    "    img_dir = change.new\n",
    "    x_pt = slide_x2.value\n",
    "    y_pt = slide_y2.value\n",
    "    spec_dir = specdir_button2.value\n",
    "    vmin, vmax = slide_cb2.value\n",
    "    \n",
    "    if param_dropdown2.value == 'Topography':\n",
    "        xx, yy, zz = get_imgdata(data_dict[param_dropdown2.value][f'Image {img_dir} with Forward Ramps'])\n",
    "    else:\n",
    "        xx, yy, zz = get_imgdata(param_data_dict[param_dropdown2.value][img_dir])\n",
    "    pmesh_top2.set_array(zz)\n",
    "    pmesh_top2.set_clim(vmin,vmax)\n",
    "\n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    for i, channel in enumerate(chan_list):\n",
    "        spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "        df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel)\n",
    "        df_spectro['channel'] = channel\n",
    "        df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "        spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "        ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_specdir(change):\n",
    "    img_dir = imgdir_button2.value\n",
    "    x_pt = slide_x2.value\n",
    "    y_pt = slide_y2.value\n",
    "    spec_dir = change.new\n",
    "\n",
    "    # df_spectro_list, data_param_dict = [], {}\n",
    "    for i, channel in enumerate(chan_list):\n",
    "        spectro_data = wsxm_getspectro(data_dict, channel=channel, img_dir=img_dir, x=x_pt, y= y_pt)\n",
    "        df_spectro, data_param = wsxm_calcspectroparam(spectro_data, channel)\n",
    "        df_spectro['channel'] = channel\n",
    "        df_spectro_filt = df_spectro[df_spectro['segment'].isin([spec_dir])].reset_index(drop=True) #filter to selected direction\n",
    "        spec_line2[channel].get_lines()[0].set_data(df_spectro_filt['x'],df_spectro_filt['y'])\n",
    "        ax2_spec[i].set_ylim(df_spectro_filt['y'].min(), df_spectro_filt['y'].max())\n",
    "    fig2.canvas.draw()\n",
    "\n",
    "@dash2_output.capture()\n",
    "def dash2_update_colorbar(change):\n",
    "    vmin, vmax = change.new\n",
    "    img_dir = imgdir_button2.value\n",
    "    if param_dropdown2.value == 'Topography':\n",
    "        xx, yy, zz = get_imgdata(data_dict[param_dropdown2.value][f'Image {img_dir} with Forward Ramps'])\n",
    "    else:\n",
    "        xx, yy, zz = get_imgdata(param_data_dict[param_dropdown2.value][img_dir])\n",
    "    \n",
    "    if slide_cb2.min != zz.min() or  slide_cb2.max != zz.max():\n",
    "        #slider reset to channel values\n",
    "        vmin, vmax = zz.min(), zz.max()\n",
    "        slide_cb2.unobserve(dash2_update_colorbar, 'value')\n",
    "        slide_cb2.min, slide_cb2.max = -1e100, 1e100 #to avoid error of min, max classh from previous value\n",
    "        slide_cb2.min, slide_cb2.max = vmin, vmax\n",
    "        slide_cb2.step = (vmin - vmax)/100\n",
    "        slide_cb2.value = (vmin, vmax)\n",
    "        slide_cb2.observe(dash2_update_colorbar, 'value')\n",
    "    else:\n",
    "        pmesh_top2.set_clim(vmin, vmax)\n",
    "        cb_top2.mappable.set_clim(vmin, vmax)\n",
    "        fig2.canvas.draw()\n",
    "\n",
    "#update x,y cordinates by clicking inside the plot\n",
    "@dash2_output.capture()\n",
    "def dash2_onclick(event):\n",
    "    if event.inaxes == ax2[0]:\n",
    "        slide_x2.value = event.xdata\n",
    "        slide_y2.value = event.ydata\n",
    "\n",
    "# @dash2_output.capture()\n",
    "# def response(change):\n",
    "#     print(change)\n",
    "     \n",
    "slide_x2.observe(dash2_update_x, 'value')\n",
    "slide_y2.observe(dash2_update_y, 'value')\n",
    "slide_zrange2.observe(dash2_update_zrange, 'value')\n",
    "slide_cb2.observe(dash2_update_colorbar,'value')\n",
    "param_dropdown2.observe(dash2_update_param, 'value')\n",
    "imgdir_button2.observe(dash2_update_imgdir, 'value')\n",
    "specdir_button2.observe(dash2_update_specdir, 'value')\n",
    "dash2_cid = fig2.canvas.mpl_connect('button_press_event', dash2_onclick)\n",
    "\n",
    "display(dash2_box1)\n",
    "display(dash2_box2)\n",
    "display(dash2_box3)\n",
    "display(dash2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb738c24-4282-48dc-bb0a-3e860780b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/interdigThiols_tipSi3nN_b_0023_Excitation frequency.f.curves'\n",
    "# filepath = 'data/interdigThiolsHeated_tipNweSi3nN_a_0031_Excitation frequency.f.stp'\n",
    "test_data = wsxm_readcurves(filepath)\n",
    "print(test_data.keys())\n",
    "test_chan = 'Excitation frequency' #'Normal force', 'Amplitude', 'Excitation frequency', 'Phase'\n",
    "curv_num = 1\n",
    "print(test_data[test_chan]['curves'][curv_num]['data'].keys())\n",
    "\n",
    "spectro_data = test_data[test_chan]['curves'][curv_num]['data']\n",
    "test_spectro, test_param = wsxm_calcspectroparam(spectro_data, test_chan)\n",
    "# print(test_param)\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=test_spectro, x=\"x\", y=\"y\", hue=\"segment\", ax=ax)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles, labels=labels) #remove legend title\n",
    "\n",
    "#show calculations in plot for checking\n",
    "# plt.hlines(test_param['Adhesion']['zero'], test_spectro['x'].min(), \n",
    "#            test_spectro['x'].max(), linestyles='dashed', colors='r')\n",
    "# plt.hlines(test_param['Adhesion']['min'], test_spectro['x'].min(), \n",
    "#            test_spectro['x'].max(), linestyles='dashed', colors='r')\n",
    "# plt.plot(test_param['Snap-in distance']['x'], test_param['Snap-in distance']['y'],\n",
    "#          'r', linestyle='solid',linewidth=2)\n",
    "# plt.plot(test_param['Stiffness']['x'], test_param['Stiffness']['y'],\n",
    "#          'r', linestyle='solid',linewidth=2)\n",
    "\n",
    "plt.show()\n",
    "# test_data[test_chan]['curves'][curv_num]['header']\n",
    "# print(test_spectro.max())\n",
    "# test_spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c0360-746b-4a3a-bf26-ec89aade9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close()\n",
    "filepath = 'data/interdigThiols_tipSi3nN_b_0030.b.dy.top'\n",
    "test_data = wsxm_readchan(filepath, all_files=True)\n",
    "test_chan = 'Topography'#'Topography', 'Normal force', 'Excitation frequency', 'Amplitude'\n",
    "test_dir = 'Backward'\n",
    "im_data_test = test_data[test_chan][test_dir]\n",
    "# xx = im_data_test['X'].reshape(128,128)\n",
    "# yy = im_data_test['Y'].reshape(128,128)\n",
    "# zz = im_data_test['Z'].reshape(128,128)\n",
    "xx, yy, zz = get_imgdata(im_data_test)\n",
    "plt.pcolormesh(xx,yy,zz, cmap='afmhot')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(zz.min(), zz.max())\n",
    "# test_data.keys()\n",
    "# test_data[test_chan][test_dir]['header']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8a55d-3444-4a0e-a836-9c156374f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'Topography' #'Excitation frequency', 'Normal force', 'Amplitude', 'Topography'\n",
    "chan_dir = 'Image Forward with Backward Ramps' #'Image Forward with Forward Ramps', 'Image Backward with Backward Ramps', 'Image Backward with Forward Ramps', 'Image Forward with Backward Ramps'\n",
    "img_dir = chan_dir.split(' ')[1]\n",
    "data_dict_chan = data_dict[channel][chan_dir]\n",
    "# im_data = data_dict_chan['data']\n",
    "header_dict = data_dict_chan['header']\n",
    "x_num = int(header_dict['Number of rows'])\n",
    "y_num = int(header_dict['Number of rows'])\n",
    "chan_list = data_dict.keys()\n",
    "\n",
    "pt_x, pt_y, pt_z = 1, 120, 0\n",
    "style = 'XY'\n",
    "\n",
    "# test_data = wsxm_readcurves(filepath)\n",
    "#plot AFM Z image\n",
    "# im_data = test_data['Channel']['data']\n",
    "xx, yy, zz = get_imgdata(data_dict_chan, style, pt_x, pt_y, pt_z) #im_data['X'].reshape(128,128)\n",
    "# yy = im_data['Y'].reshape(128,128)\n",
    "# zz = data_dict_chan['data']['Z'] #im_data['Z'].reshape(128,128)\n",
    "# zz = data_dict_chan['data']['ZZ'][pt_z,:,:]#1st index:xy sections, 2nd index:xz sections, 3rd index: yz sections\n",
    "\n",
    "#TODO: change and check how forward backward in z (or x) can be consistently plotted\n",
    "print(zz.min(),zz.max(), zz.max()-zz.min())\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx,yy,zz, cmap='afmhot')\n",
    "plt.colorbar()\n",
    "\n",
    "# if header_dict['Spectroscopy direction'] == 'Forward': #CHECK THIS\n",
    "#     segment\n",
    "#obtain and plot spectroscopy data\n",
    "chan_spectro = 'Normal force'\n",
    "# spec_params = ['Adhesion', 'Snap-in distance', 'Stiffness'] #check keys of FUNC_DICT\n",
    "#CHECK x and y in all functions!!!\n",
    "spectro_data = wsxm_getspectro(data_dict, channel=chan_spectro,\n",
    "                               img_dir=img_dir, x=pt_x, y=pt_y)\n",
    "df_spectro, data_param = wsxm_calcspectroparam(spectro_data, chan_spectro)\n",
    "\n",
    "# print(fd)\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=df_spectro, x=\"x\", y=\"y\", hue=\"segment\", ax=ax)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles, labels=labels) #remove legend title\n",
    "\n",
    "#show calculations in plot for checking\n",
    "plt.hlines(data_param['Adhesion']['zero'], df_spectro['x'].min(), \n",
    "           df_spectro['x'].max(), linestyles='dashed', colors='r')\n",
    "plt.hlines(data_param['Adhesion']['min'], df_spectro['x'].min(), \n",
    "           df_spectro['x'].max(), linestyles='dashed', colors='r')\n",
    "plt.plot(data_param['Snap-in distance']['x'], data_param['Snap-in distance']['y'],\n",
    "         'r', linestyle='solid',linewidth=2)\n",
    "plt.plot(data_param['Stiffness']['x'], data_param['Stiffness']['y'],\n",
    "         'r', linestyle='solid',linewidth=2)\n",
    "# acq_pt = test_data['Curves'][3]['header']['Acquisition point'].strip('()').split(',')\n",
    "# plt.scatter(float(acq_pt[0]), float(acq_pt[1]),color = 'green')\n",
    "plt.show()\n",
    "# header_dict\n",
    "# #plot Curves\n",
    "# test_df = pd.DataFrame.from_dict(test_data['Curves'][3]['data'])\n",
    "# sns.lineplot(data=test_df, x=\"Z\", y=\"Excitation frequency\", hue=\"Segment\")\n",
    "# plt.show()\n",
    "\n",
    "# spec_params = ['Adhesion', 'Snap-in distance', 'Stiffness'] #check keys of FUNC_DICT\n",
    "img_specparams = calc_spectro_prop(data_dict, chan_spectro, img_dir)\n",
    "img_adh = img_specparams['Snap-in distance']\n",
    "plt.pcolormesh(xx,yy,img_adh, cmap='afmhot',vmin=None, vmax=0.08)\n",
    "plt.colorbar()\n",
    "#plot histogram of parameter\n",
    "plt.figure()\n",
    "sns.histplot(img_adh.flatten(),binrange=(0,0.08))\n",
    "plt.show()\n",
    "# header_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad64c31-06da-4042-ba99-fe747b7f4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f370c71-f31a-4383-823a-1f3d75e41880",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['data/20240202_laser_off_128pts_58lps_0002.f.dy.ch15', \n",
    "         'data/20240202_laser_on_128pts_58lps_0003.f.dy.ch15']\n",
    "data_dict = {}\n",
    "rms_min = np.inf\n",
    "for file in files:\n",
    "    data_dict[file] = {}\n",
    "    data_dict[file]['Frequency'], data_dict[file]['PSD'], data_dict[file]['Z rms'] = get_psd(file)\n",
    "    if data_dict[file]['Z rms'] < rms_min:\n",
    "        rms_min = data_dict[file]['Z rms']\n",
    "        off_file = file\n",
    "\n",
    "on_file = [n for n in files if n != off_file][0]\n",
    "data_dict[off_file]['Label'] = 'Laser ON'\n",
    "data_dict[on_file]['Label'] = 'Laser OFF'\n",
    "\n",
    "#plot data images\n",
    "# for file in files:\n",
    "#     plt.plot(data_dict[file]['Frequency'], data_dict[file]['PSD'], label = data_dict[file]['PSD'])\n",
    "# plt.show()\n",
    "    \n",
    "\n",
    "#z_pow = 2*(z_fftx_avg[64:]**2)/(15000*128)\n",
    "#freq_drive = float(head_data['Resonance frequency'].split(' ')[0])\n",
    "#freq_array_real = freq_array_shift[64:] + freq_drive\n",
    "freq_final = data_dict[on_file]['Frequency']\n",
    "psd_final = data_dict[on_file]['PSD'] - data_dict[off_file]['PSD']\n",
    "plt.plot(freq_final, psd_final)\n",
    "#plt.show()\n",
    "\n",
    "#guess = [0, 76000, 2000, 100000]\n",
    "y_guess = psd_final.min()\n",
    "f_guess = freq_final[psd_final.argmax()]\n",
    "w_guess = 2*np.abs(freq_final[(np.abs(psd_final - psd_final.max()/2)).argmin()]-f_guess)\n",
    "A_guess = np.pi*w_guess*psd_final.max()/2\n",
    "guess = [y_guess, f_guess, w_guess, A_guess] #y0,f0,w,A\n",
    "#fit\n",
    "popt, pcov = curve_fit(lorentzian, freq_final,psd_final,\n",
    "                    p0=guess, bounds=(0,np.inf))\n",
    "#print(np.linalg.cond(pcov))\n",
    "params = ['offset','resonance freq', 'fwhm', 'area']\n",
    "fit_dict = dict(zip(params, popt))\n",
    "fit_dict['Q factor'] = fit_dict['resonance freq']/fit_dict['fwhm']\n",
    "\n",
    "#plot fit\n",
    "f_min, f_max = freq_final.min(), freq_final.max()\n",
    "f_ext = 0.1*(f_max-f_min)\n",
    "freq_fit_range = np.linspace(f_min-f_ext, f_max+f_ext, 100000)\n",
    "plt.plot(freq_fit_range,lorentzian(freq_fit_range, *popt))\n",
    "plt.show()\n",
    "\n",
    "print(fit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed95f0c-22a2-45d5-b390-5c5e738ce011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q = head_data['Quality factor (Q)']\n",
    "k_cant = 2 # N/m\n",
    "T = 300 #K\n",
    "kb = 1.380649e-23 #J/K\n",
    "V_rms = np.sqrt(fit_dict['area'])\n",
    "corr_fac = 4/3 #Butt-Jaschke correction for thermal noise\n",
    "sens = np.sqrt(corr_fac*kb*T/k_cant)/V_rms/1e-9 #nm/V \n",
    "print(V_rms, sens)\n",
    "print(np.sqrt(data_dict[on_file]['Z rms']**2 - data_dict[off_file]['Z rms']**2))\n",
    "# z = im_data['Z']\n",
    "# print(np.sqrt(z.dot(z)/z.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa26187-2312-4123-ba4c-26a9069e2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1D Fourier Transform of image and average along Y axis.\n",
    "# z_fftx = np.abs(np.fft.fft(zz))\n",
    "# z_fftx_shift = np.fft.fftshift(z_fftx)\n",
    "# z_fftx_avg = np.average(z_fftx_shift, axis=0)\n",
    "\n",
    "# num_pts = len(z_fftx_avg)\n",
    "# sample_rate = 2*num_pts*float(head_data['X-Frequency'].split(' ')[0])\n",
    "# freq_array = np.fft.fftfreq(len(z_fftx_avg), 1 / sample_rate)\n",
    "# freq_array_shift = np.fft.fftshift(freq_array)\n",
    "# ff, _ = np.meshgrid(freq_array_shift, freq_array_shift)\n",
    "# plt.pcolormesh(ff, yy, z_fftx_shift, cmap='afmhot')\n",
    "# plt.show()\n",
    "# plt.plot(freq_array_shift, z_fftx_avg)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbd303-0a03-4e80-bc4a-940920af7fc7",
   "metadata": {},
   "source": [
    "## CANTILEVER SIMULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05fca8-84f9-48d1-9388-8a704c8ad52a",
   "metadata": {},
   "source": [
    "#### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7221bc0-b55f-41b2-ba15-52510b0d78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False # save plot\n",
    "kc = 2#27 #cantilever spring constant (N/m)\n",
    "fc = 70e3#300e3 #cantilever resonance frequency (Hz)\n",
    "Qc = 130#470 #cantilever Q factor (free)\n",
    "fd_ini = fc - 0e3 #drive frequency (Hz)\n",
    "F0 = 1*1.53846154e-10 #drive amplitude (m)\n",
    "\n",
    "d0_far = 15e-9 #tip-sample rest distance, far (m)\n",
    "d0_near = 2e-9 #tip-sample rest distance, near (m)\n",
    "d0_pts = 1 #number of points for force-distance\n",
    "d0_list = np.linspace(d0_far, d0_near, d0_pts) #[8e-9, 7e-9, 6e-9] #tip-sample distance, rest (m)\n",
    "# d0_list = np.concatenate((np.linspace(d0_far, d0_near, d0_pts-1, endpoint=False),\n",
    "#                           np.linspace(d0_near, d0_far, d0_pts)), axis=None)\n",
    "spectrodir_list = np.array(['approach']*(d0_pts-1) + ['retract']*d0_pts) #spectroscopy direction\n",
    "# d0_list = d0_far + (d0_near - d0_far) * (np.linspace(0, 1, d0_pts))**(1/4) # = np.logspace(np.log(d0_far)/np.log(3),np.log(d0_near)/np.log(3),d0_pts, base=3)\n",
    "\n",
    "theta_s = 0 #contact angle with sample (deg)\n",
    "theta_t = 0 #contact angle with tip (deg)\n",
    "humid = 0.8 #humidity\n",
    "T_temp = 298 #Temperature (K)\n",
    "surf_ten = 72e-3 #surface tension (N/m)\n",
    "dens = 1000 #density (kg/m3)\n",
    "mol_wt = 18e-3 #molecular wt (kg/mol)\n",
    "R_gas = 8.314 #Ideal gas constant (J/K⋅mol)\n",
    "\n",
    "R_t = 20e-9 #tip radius (m)\n",
    "R_s = 1e9 #sample radius (m)\n",
    "R = 1/((1/R_t)+(1/R_s)) #effective Derjaguin radius (m) #CHECK FACTOR OF TWO\n",
    "# t_factor = 1+np.cos(theta_s*np.pi/180) #factor to adjust H and Y linearly relative to theta_s=0 values\n",
    "H = 1*64e-21 #Hamaker constant (J)\n",
    "Y = 1*31e-3 #surface energy of sample (J/m2)\n",
    "# a0 = 1e-10 #intermolecular distance (m)\n",
    "E_s = 70e9 #elastic modulus of sample (Pa)\n",
    "nu_s = 0.3 #poisson ratio of sample\n",
    "E_t = 130e9 #elastic modulus of tip (Pa)\n",
    "nu_t = 0.3 #poisson ratio of tip\n",
    "E = 1/(((1-nu_s**2)/E_s)+((1-nu_t**2)/E_t))\n",
    "\n",
    "a0 = np.sqrt(H/(24*np.pi*Y)) #intermolecular distance (obtained by balancing vdW and  DMT adhesion)\n",
    "wc = 2*np.pi*fc #angular resonance frequency of cantilever\n",
    "mc = kc/(wc**2) #cantilever mass\n",
    "wd_ini = 2*np.pi*fd_ini #angular drive frequency\n",
    "gamma = wc/Qc #damping coefficient, b/m (dimensionless)\n",
    "amp_res = F0/(mc*gamma*wc) #theoretical free amplitude at resonance (far away)\n",
    "amp_ini = F0/(mc*np.sqrt((wc**2-wd_ini**2)**2+(gamma*wc)**2)) #theoretical free amplitude at fd_ini (far away)\n",
    "phase_ini = np.arctan2(gamma*wd_ini, wc**2-wd_ini**2)*180/np.pi if wc != wd_ini else 90\n",
    "# freq_res = 300 #frequency resolution (Hz)\n",
    "# phase_res = 0.1 #phase resolution (deg)\n",
    "\n",
    "c_theta = (np.cos(theta_s*np.pi/180)+np.cos(theta_t*np.pi/180))/2 #effective contact angle\n",
    "mol_vol = mol_wt/dens #molar volume\n",
    "kelv_len = (surf_ten*mol_vol)/(R_gas*T_temp) #kelvin length\n",
    "rm_eq = -kelv_len/np.log(humid) #equilibrium meniscus radius (for constant pressure)\n",
    "# d_jumpin_ini = 2*c_theta*rm_eq #jumpin distance (assumption)\n",
    "d_jumpin_ini = np.polyval(cap_fit_dict[humid]['cond_distance'], theta_s)\n",
    "vol_bridge_ini = np.polyval(cap_fit_dict[humid]['cond_volume'], theta_s)\n",
    "# print(rm_eq)\n",
    "\n",
    "#numerical method parameters\n",
    "# t0 = 0 #readjust this!\n",
    "# v0 = 0 #check readjustment!\n",
    "# x0 = F0/(mc*gamma*wc) #theoretical free amplitude at resonance (far away)\n",
    "fs = 500*fc #10*wc*np.pi/(phase_res*180)  # Sampling frequency in Hz\n",
    "dt = 1/fs #1/fd/20\n",
    "n_osci = 1000#int(fd/freq_res) #number of oscillations\n",
    "ss_osci = 50#100#int(n_osci/3) #number of steady state osci at end\n",
    "t_end = n_osci/fd_ini #0.006 #dt*n_samples\n",
    "# phase_tol = 0.1 #tolerance for zero phase (deg)\n",
    "fd_step = 10 #initial freq step size (Hz) to calculate bounds for wd in bisection section (PLL simulation)\n",
    "fd_tol = 1 #tolerance for freq convergence\n",
    "phase_zero = 0.1 #tolerance for zero phase (deg)\n",
    "freq_window = 20*fd_ini/ss_osci #Hz for finding resonance peak\n",
    "# print(freq_window)\n",
    "#macro variables for faster numerical calculation\n",
    "wc2 = wc**2\n",
    "F02 = F0/mc\n",
    "F_el0 = (4/3)*E*np.sqrt(R)\n",
    "F_vdw_adh = -H*R/(6*(a0**2))\n",
    "F_vdw0 = -H*R/6\n",
    "F_cap0 = -2*np.pi*surf_ten*R\n",
    "F_cap_adh = F_cap0*((2*c_theta)-(a0/rm_eq)) if humid != 0 else 0\n",
    "# F_cap_adh = -4*np.pi*surf_ten*R*c_theta if humid != 0 else 0\n",
    "# d_i = 0 \n",
    "\n",
    "#create header data using above parameters, to be used when saving simulation data later\n",
    "header_info = {\n",
    "    'Spring constant [N/m]': kc,\n",
    "    'Resonance frequency [Hz]': fc,\n",
    "    'Quality factor []': Qc,\n",
    "    'Cantilever mass [kg]': mc,\n",
    "    'Drive frequency [Hz]': fd_ini,\n",
    "    'Drive ampltude [m]': F0,\n",
    "    'Free resonance amplitude [m]': amp_res,\n",
    "    'Free initial amplitude [m]': amp_ini,\n",
    "    'Free initial phase [°]': phase_ini,\n",
    "    'Tip radius [m]': R_t,\n",
    "    'Sample radius [m]': R_s,\n",
    "    'Derjaguin radius [m]': R,\n",
    "    'Hamaker constant [J]': H,\n",
    "    'Tip contact angle [°]': theta_t,\n",
    "    'Sample contact angle [°]': theta_s,\n",
    "    'Humidity []': humid,\n",
    "    'Temperature [K]': T_temp,\n",
    "    'Liquid surface tension [N/m]': surf_ten,\n",
    "    'Liquid density [kg/m3]': dens,\n",
    "    'Liquid molar mass [kg/mol]': mol_wt,\n",
    "    'Kelvin length [m]': kelv_len,\n",
    "    'Equilibrium meniscus radius [m]': rm_eq,\n",
    "    'Capillary condensation distance [m]': d_jumpin_ini,\n",
    "    'Capillary condensation volume [m3]': vol_bridge_ini,\n",
    "    'Sample surface energy [J/m2]': Y,\n",
    "    'Intermolecular distance [m]': a0,\n",
    "    'Tip poisson ratio': nu_t,\n",
    "    'Sample poisson ratio': nu_s,\n",
    "    'Tip elastic modulus [Pa]': E_t,\n",
    "    'Sample elastic modulus [Pa]': E_s,\n",
    "    'Effective elastic modulus [Pa]': E,\n",
    "    'Distance range [m]': f'{d0_near:.1e} - {d0_far:.1e}',\n",
    "    'Number of distance points []': d0_pts,\n",
    "    'Sampling frequency [Hz]': fs,\n",
    "    'Number of oscillations []': n_osci,\n",
    "    'Steady state oscillations []': ss_osci,\n",
    "    'Total oscillation time [s]': t_end,    \n",
    "}\n",
    "header_strings = [f\"{key}: {value}\" for key, value in header_info.items()]\n",
    "header_df = pd.DataFrame(header_strings, columns=['Header'])\n",
    "\n",
    "# Functions relevant for simulations defined below\n",
    "\n",
    "#Runge-Kutta method for 2nd order differential equation, coupled as 2 first order differential eqs.\n",
    "@njit\n",
    "def RungeKuttaCoupled(x, y, z, dx, dydx, dzdx, d0, wd, \n",
    "                      approach, d_rupt, d_jumpin, vol_bridge):#**kwargs):\n",
    "    # Compute the Runge-Kutta steps\n",
    "    k1 = dx * dydx(x, y, z, d0, wd, approach, \n",
    "                   d_rupt, d_jumpin, vol_bridge)#**kwargs)\n",
    "    h1 = dx * dzdx(x, y, z)\n",
    "    k2 = dx * dydx(x + dx / 2., y + k1 / 2., z + h1 / 2., d0, wd, approach, \n",
    "                   d_rupt, d_jumpin, vol_bridge)#**kwargs)\n",
    "    h2 = dx * dzdx(x + dx / 2., y + k1 / 2., z + h1 / 2.)\n",
    "    k3 = dx * dydx(x + dx / 2., y + k2 / 2., z + h2 / 2., d0, wd, approach, \n",
    "                   d_rupt, d_jumpin, vol_bridge)#**kwargs)\n",
    "    h3 = dx * dzdx(x + dx / 2., y + k2 / 2., z + h2 / 2.)\n",
    "    k4 = dx * dydx(x + dx, y + k3, z + h3, d0, wd, approach, \n",
    "                   d_rupt, d_jumpin, vol_bridge)#**kwargs)\n",
    "    h4 = dx * dzdx(x + dx, y + k3, z + h3)\n",
    "\n",
    "    # 4th order estimate\n",
    "    y4 = y + 1. / 6. * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    z4 = z + 1. / 6. * (h1 + 2 * h2 + 2 * h3 + h4)\n",
    "    \n",
    "    # Using additional coefficients for the 5th order estimate\n",
    "    # b_star = [16 / 135, 0, 6656 / 12825, 28561 / 56430, -9 / 50, 2 / 55]\n",
    "    # y5 = y + b_star[0] * k1 + b_star[2] * k2 + b_star[3] * k3 + b_star[4] * k4\n",
    "    # z5 = z + b_star[0] * h1 + b_star[2] * h2 + b_star[3] * h3 + b_star[4] * h4\n",
    "\n",
    "    # # Calculate the error\n",
    "    # error_y = np.abs(y5 - y4)\n",
    "    # error_z = np.abs(z5 - z4)\n",
    "\n",
    "    # Update the new values for y and z using the 4th order estimate\n",
    "    y = y4\n",
    "    z = z4\n",
    "    x = x + dx\n",
    "\n",
    "    return x, y, z#, error_y, error_z\n",
    "\n",
    "#tip-sample interaction force vs distance\n",
    "@njit\n",
    "def force_ts(d, approach, d_rupt, d_jumpin, vol_bridge):\n",
    "    if d >= a0:\n",
    "        F_vdw = F_vdw0/(d**2)#-H*R/(6*(d**2))\n",
    "        F_elas = 0\n",
    "        if approach == True: #approach cycle\n",
    "            if d < d_jumpin: #liquid neck exists when closer than jumpin distance\n",
    "                # vol_near = np.pi*R*((4*(rm_eq*c_theta)**2)-(d**2))\n",
    "                # # d_rupt = (1+(0.5*np.arccos(c_theta)))*(vol_near**(1/3)) #Lian et. al. (1993)\n",
    "                # d_rupt = (1+(np.arccos(c_theta)/4))*((vol_near**(1/3)) - ((vol_near**(2/3))/(5*R))) #Willett et. al. (2000)\n",
    "                # F_cap = F_cap0*((2*c_theta)-(d/rm_eq)) #constant pressure\n",
    "                F_cap = 2*F_cap0*c_theta*(1-(d/np.sqrt((d**2)+(vol_bridge/(np.pi*R))))) #constant volume\n",
    "                # print('cp')\n",
    "            else:\n",
    "                F_cap = 0\n",
    "        else: #retract cycle\n",
    "            if d < d_rupt:\n",
    "                F_cap = 2*F_cap0*c_theta*(1-(d/np.sqrt((d**2)+(vol_bridge/(np.pi*R))))) #constant volume\n",
    "                # print('cv')\n",
    "            else:\n",
    "                F_cap = 0\n",
    "    else:\n",
    "        # print('adh')\n",
    "        F_vdw = F_vdw_adh #-H*R/(6*(a0**2)) #vdW adhesion\n",
    "        F_elas = F_el0*(a0-d)**(3/2) #CHECK THIS\n",
    "        F_cap = F_cap_adh #capillary adhesion\n",
    "        # F_cap = F_cap0*((2*c_theta)-(a0/rm_eq))\n",
    "\n",
    "    # d_near = 1e-9\n",
    "\n",
    "        # print('rupture', d_rupt, d_rupt2)\n",
    "    # else: #no liquid neck assumed\n",
    "    #     vol_bridge = 0\n",
    "    #     d_rupt = 3e-9\n",
    "    \n",
    "    # if d_rupt < d_jumpin: #no liquid neck assumed here\n",
    "    #     d_jumpin = 0\n",
    "        \n",
    "    # d = np.linspace(d_near, d_rupt+1e-9, 100)\n",
    "    \n",
    "    # print(d_jumpin, d_rupt, rm_eq, vol_bridge)\n",
    "\n",
    "    \n",
    "    \n",
    "    # F_cap_cp = -2*np.pi*surf_ten*R*((2*c_theta)-(d/rm_eq))\n",
    "    # F_cap_cv = -4*np.pi*surf_ten*c_theta*R*(1-(d/np.sqrt((d**2)+(vol_near/(np.pi*R)))))\n",
    "    \n",
    "    # F_cap_cp[np.argwhere(d>d_jumpin)] = 0\n",
    "    # F_cap_cv[np.argwhere(d>d_rupt)] = 0    \n",
    "    F_ts = F_vdw + F_elas + F_cap\n",
    "    return F_ts, F_vdw, F_elas, F_cap\n",
    "    # return F_cap\n",
    "\n",
    "#calculate rupture distance and volume of liquid bridge\n",
    "@njit\n",
    "def calculate_rupture(d):\n",
    "    if d < a0:\n",
    "        d = a0\n",
    "    \n",
    "    #variable condensaion volume (depends on d)\n",
    "    # vol_bridge = np.pi*R*((4*(rm_eq*c_theta)**2)-(d**2))\n",
    "\n",
    "    #fixed condensation volume (run liquid neck simulaiton below)\n",
    "    vol_bridge = vol_bridge_ini\n",
    "    \n",
    "    # vol_bridge = np.pi*R*((4*(rm_eq*c_theta)**2)-(a0**2))\n",
    "    # d_rupt = (1+(0.5*np.arccos(c_theta)))*(vol_bridge**(1/3)) #Lian et. al. (1993)\n",
    "    d_rupt = (1+(np.arccos(c_theta)/4))*((vol_bridge**(1/3)) - ((vol_bridge**(2/3))/(5*R))) #Willett et. al. (2000)\n",
    "    # print(d, a0, d_jumpin_ini, d_rupt)\n",
    "    if d_rupt < d_jumpin_ini or d > d_jumpin_ini: #no liquid neck assumed here\n",
    "        # print('here')\n",
    "        d_jumpin = 0\n",
    "        d_rupt = 0\n",
    "    else:\n",
    "        # print('there')\n",
    "        d_jumpin = d_jumpin_ini\n",
    "    \n",
    "    # print(d_rupt, d_jumpin, vol_bridge)\n",
    "    return d_rupt, d_jumpin, vol_bridge\n",
    "\n",
    "@njit\n",
    "def dvdt(t, v, x, d0, wd, approach, d_rupt, d_jumpin, vol_bridge):#**kwargs):\n",
    "    # d0 = kwargs['d0']\n",
    "    # wd = kwargs['wd']\n",
    "    # print(d0, wd)\n",
    "    # global d0_i\n",
    "    # global wd\n",
    "    # d0 = d0_list[d0_i]\n",
    "    d_t = d0 + x #instantaneous tip sample distance\n",
    "    F_ts, _, _, _ = force_ts(d_t, approach, d_rupt, d_jumpin, vol_bridge)\n",
    "    # if d_t >= a0:\n",
    "    #     F_vdw = -H*R/(6*(d_t**2))\n",
    "    #     F_elas = 0\n",
    "    # else:\n",
    "    #     F_vdw = -H*R/(6*(a0**2))\n",
    "    #     F_elas = (4/3)*E*np.sqrt(R)*(a0-d_t)**(3/2) #CHECK THIS\n",
    "    # F_ts = F_vdw + F_elas\n",
    "    return -(wc2*x)-(gamma*v)+(F_ts/mc)+(F02*np.cos(wd*t))\n",
    "\n",
    "# def dvdt_free(t, v, x):\n",
    "#     global d0_i\n",
    "#     d0 = d0_list[d0_i]\n",
    "#     d_t = d0 + x #instantaneous tip sample distance\n",
    "#     F_ts = force_ts(d_t)\n",
    "#     # if d_t >= a0:\n",
    "#     #     F_vdw = -H*R/(6*(d_t**2))\n",
    "#     #     F_elas = 0\n",
    "#     # else:\n",
    "#     #     F_vdw = -H*R/(6*(a0**2))\n",
    "#     #     F_elas = (4/3)*E*np.sqrt(R)*(a0-d_t)**(3/2) #CHECK THIS\n",
    "#     # F_ts =  F_vdw + F_elas\n",
    "#     return -(wc2*x)-(gamma*v)+(F_ts/mc)#+((F0/mc)*np.cos(wd*t))\n",
    "\n",
    "@njit\n",
    "def dxdt(t, v, x):\n",
    "    return v\n",
    "\n",
    "# @njit\n",
    "# def get_fft(input_array):\n",
    "#     fft_out = np.fft.fft(input_array)\n",
    "#     return np.fft.fftshift(fft_out) \n",
    "\n",
    "# @njit\n",
    "# def get_fft_freq(num_samples, delta_t):\n",
    "#     freq_out = np.fft.fftfreq(num_samples, delta_t)\n",
    "#     return np.fft.fftshift(freq_out) \n",
    "\n",
    "@njit\n",
    "def main_computation(v, x, t0, t_end, dt, d0, wd):\n",
    "    len_full = int(t_end/dt)\n",
    "    t = t0\n",
    "    t_list = np.zeros(len_full, dtype=np.float64)\n",
    "    v_list = np.zeros(len_full, dtype=np.float64)\n",
    "    x_list = np.zeros(len_full, dtype=np.float64)\n",
    "    # test_list = []\n",
    "    t_list[0] = t\n",
    "    v_list[0] = v\n",
    "    x_list[0] = x\n",
    "    i = 1\n",
    "    v_old = -1\n",
    "    v_sign = 1\n",
    "    d_rupt, d_jumpin, vol_bridge = 0, d_jumpin_ini, 0 #CHECK THIS\n",
    "    while t <= t_end + t0:\n",
    "        if v >= 0: #retract cycle\n",
    "            approach = False\n",
    "            if v_sign == -1: #lower turning point\n",
    "                d_rupt, d_jumpin, vol_bridge = calculate_rupture(d=d0+x)\n",
    "                # test_list.append((t,x))\n",
    "        else: #approach cycle\n",
    "            approach = True\n",
    "        t, v, x = RungeKuttaCoupled(t, v, x, dt, dvdt, dxdt, d0, wd, \n",
    "                                    approach, d_rupt, d_jumpin, vol_bridge)\n",
    "        t_list[i] = t\n",
    "        v_list[i] = v\n",
    "        x_list[i] = x\n",
    "        v_sign = np.sign(v_old*v)\n",
    "        v_old = v\n",
    "        i += 1\n",
    "    return t_list, v_list, x_list, d_rupt, d_jumpin, vol_bridge#, test_list\n",
    "\n",
    "#solve\n",
    "# @njit\n",
    "def solve_harmonic(v, x, t0, d0, wd):#**kwargs):\n",
    "    # t = t0 #kwargs['t0']#t0\n",
    "    # len_full = int(t_end/dt)\n",
    "    # t_list = np.zeros(len_full, dtype=np.float64) #[t]\n",
    "    # v_list = np.zeros(len_full, dtype=np.float64) #[v]\n",
    "    # x_list = np.zeros(len_full, dtype=np.float64) #[x]\n",
    "    # t_list[0] = t\n",
    "    # v_list[0] = v\n",
    "    # x_list[0] = x\n",
    "    # # err_v_list = [0]\n",
    "    # # err_x_list = [0]\n",
    "    # print('start', d0, wd, t0, t_end)\n",
    "    # i = 1\n",
    "    # while t <= t_end+t0: #kwargs['t0']:\n",
    "    #     t, v, x = RungeKuttaCoupled(t, v, x, dt, dvdt, dxdt, d0, wd)#**kwargs)  #, err_v, err_x     \n",
    "    #     # t_list.append(t)\n",
    "    #     # v_list.append(v)\n",
    "    #     # x_list.append(x)\n",
    "    #     t_list[i] = t\n",
    "    #     v_list[i] = v\n",
    "    #     x_list[i] = x\n",
    "    #     i += 1\n",
    "    #     # err_v_list.append(err_v)\n",
    "    #     # err_x_list.append(err_x)\n",
    "    # print('fin', d0, wd, t)\n",
    "    # ss_osci = 100 #number of steady state osci at end\n",
    "    # wd = kwargs['wd']\n",
    "    # t_list = np.array(t_list)\n",
    "    # v_list = np.array(v_list)\n",
    "    # x_list = np.array(x_list)\n",
    "    t_list, v_list, x_list, d_rupt, d_jumpin, vol_bridge = main_computation(v, x, t0, t_end, dt, d0, wd)\n",
    "    # print(test_list)\n",
    "    fd = wd/(2*np.pi)\n",
    "    ss_index = -int(ss_osci*fs/fd)\n",
    "    ss_t_list = t_list[ss_index:]\n",
    "    ss_x_list = x_list[ss_index:]\n",
    "    ss_v_list = v_list[ss_index:]\n",
    "    n_samples = len(ss_t_list)\n",
    "    \n",
    "    # x_list = F0*np.cos(wd*np.array(t_list))\n",
    "    # FT_omega = np.zeros(n_samples, dtype=np.float64) \n",
    "    # with objmode(FT_omega='float64[:]'): \n",
    "    FT_omega = np.fft.fftfreq(n_samples, ss_t_list[1] - ss_t_list[0])\n",
    "    FT_omega = np.fft.fftshift(FT_omega)\n",
    "    # FT = np.zeros(n_samples, dtype=np.complex128) \n",
    "    # with objmode(FT='complex128[:]'):        \n",
    "    FT = np.fft.fft(ss_x_list)\n",
    "    FT = np.fft.fftshift(FT)\n",
    "    # FT_omega = get_fft_freq(n_samples, ss_t_list[1] - ss_t_list[0])\n",
    "    # FT = get_fft(ss_x_list)\n",
    "    \n",
    "    FT_amplitude = np.abs(FT)*2/n_samples\n",
    "    \n",
    "    # fpeak_range = (int(n_samples/2) + np.argmin(np.abs(FT_omega[int(n_samples/2):]-(fd-freq_window))),\n",
    "    #                int(n_samples/2) + np.argmin(np.abs(FT_omega[int(n_samples/2):]-(fd+freq_window))))\n",
    "    fpeak_range = (int(n_samples/2) + np.argmin(np.abs(FT_omega[int(n_samples/2):]-(fd-freq_window))), -1)\n",
    "    # print(fpeak_range, n_samples/2)\n",
    "    f_index = fpeak_range[0] + np.argmax(FT_amplitude[fpeak_range[0]: fpeak_range[1]])\n",
    "    # f_index = int(n_samples/2) + np.argmax(FT_amplitude[int(n_samples/2):])\n",
    "    amplitude = FT_amplitude[f_index]\n",
    "    deflection = np.mean(ss_x_list)\n",
    "    d_lower_turn = np.min(ss_x_list) + d0\n",
    "    # print(FT_omega[f_index])\n",
    "\n",
    "    x_drive = F0*np.cos(wd*np.array(ss_t_list))\n",
    "    # FTdrive = np.zeros(n_samples, dtype=np.complex128) \n",
    "    # with objmode(FT_drive='complex128[:]'):\n",
    "    FT_drive = np.fft.fft(x_drive)\n",
    "    FT_drive = np.fft.fftshift(FT_drive)\n",
    "    # FT_drive = get_fft(x_drive)\n",
    "    phase = np.angle(FT_drive[f_index])-np.angle(FT[f_index])\n",
    "    # phase = np.pi\n",
    "    # Normalize phase to be within [0, 2π]\n",
    "    phase = np.mod(phase, 2 * np.pi)    \n",
    "    # Adjust phase to be within [0, π]\n",
    "    if phase > np.pi:\n",
    "        phase -= np.pi\n",
    "    phase = phase*180/np.pi #in degrees\n",
    "    #set initial conditions for next iteration\n",
    "    # x = amplitude\n",
    "    # v = 0\n",
    "    # t_end += n_osci/fd #final time\n",
    "\n",
    "    #plot simulated data\n",
    "    # Find peaks and valleys\n",
    "    # peaks, _ = find_peaks(ss_x_list)   \n",
    "    # valleys, _ = find_peaks(-ss_x_list)\n",
    "    # amppeak_t_list = ss_t_list[peaks]\n",
    "    # FT_amppeak = np.fft.fft(ss_x_list[peaks]-np.mean(ss_x_list[peaks]))\n",
    "    # FT_amppeak = np.fft.fftshift(FT_amppeak)\n",
    "    # FT_amppeak_omega = np.fft.fftfreq(len(amppeak_t_list), amppeak_t_list[1] - amppeak_t_list[0])\n",
    "    # FT_amppeak_omega = np.fft.fftshift(FT_amppeak_omega)\n",
    "    # print(d0, FT_omega[f_index], FT_amplitude[f_index])\n",
    "    # custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "    # sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "    # sns.set_context(context='paper', font_scale=0.8)\n",
    "    # fig, ax = plt.subplots(1, 1, figsize=(6,3), dpi=300)#(3, 3.5))#, dpi=300)\n",
    "    # ax.plot(t_list*1000, x_list/1e-9, color='blue')\n",
    "    # ax.axhline(0, linestyle=':', color='k')\n",
    "    # #ax[0].plot([test_i[0] for test_i in test_list], [test_i[1] for test_i in test_list], 'x', color='red')\n",
    "    # ax.plot(ss_t_list*1000, (ss_x_list+d0)/1e-9, color='blue')\n",
    "    # ax.plot(ss_t_list[peaks]*1000, (ss_x_list[peaks]+d0)/1e-9, color='red')\n",
    "    # ax.plot(ss_t_list[valleys]*1000, (ss_x_list[valleys]+d0)/1e-9, color='red')\n",
    "    # # ax[0].plot(ss_t_list, x_drive, color='red')\n",
    "    # ax.axhline((d0+deflection)/1e-9, linestyle=':', color='k')\n",
    "    # # ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "    # # ax[0][0].set_ylim(-1.1*amp_ini, 1.1*amp_ini)\n",
    "    # # ax[0][1].plot(ss_t_list, ss_x_list+d0, color='yellow') #lower turning point distance\n",
    "    # ax.axhline(d_jumpin_ini/1e-9, linestyle='--', color='k')\n",
    "    # ax.set_ylim(-0.1, 1.05*(d0_far+amp_ini)/1e-9)\n",
    "    # ax.set_xlabel('Time (ms)')\n",
    "    # ax.set_ylabel('Distance (nm)')\n",
    "    # ax.set_ylabel('Deflection (nm)')\n",
    "    # ax.set_xlim(-0.05, 2)\n",
    "    # ax[0][1].ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "    #ax[1].plot(t_list, v_list, color='blue')\n",
    "    # ax[1][1].plot(FT_omega, FT_amplitude, color='blue')\n",
    "    # ax[1][1].plot(FT_omega[f_index], FT_amplitude[f_index], 'x', color='red')\n",
    "    # ax2 = ax[1][1].twinx()\n",
    "    # ax2.plot(FT_amppeak_omega, FT_amppeak, color='yellow')\n",
    "    # ax2.set_yscale('log')\n",
    "    # ax[1].set_xlim(-5*fc, 5*fc)\n",
    "    # ax[1][1].set_xlim(0, 2.1*fc)\n",
    "    # ax[1][1].set_yscale('log')\n",
    "    # ax[1][1].ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "    # ax[2].plot(x_list, v_list, color='blue')\n",
    "    # ax[1][0].plot(ss_x_list, ss_v_list, color='yellow', linewidth=0.5)\n",
    "    # fig.tight_layout()\n",
    "    # plt.rcParams['svg.fonttype'] = 'none'\n",
    "    # fig.savefig(f'data/osciplot_thetas{theta_s:}_humid{humid:.2f}_d0{d0:1.2e}_amp{amplitude:1.2e}.png', dpi=300, bbox_inches='tight')\n",
    "    # fig.savefig(f'data/initialosciplot.png', dpi=300, bbox_inches='tight')\n",
    "    # plt.show()\n",
    "    \n",
    "    return amplitude, phase, deflection, d_lower_turn, d_rupt, d_jumpin, vol_bridge #t_list, v_list, x_list#, err_v_list, err_x_list\n",
    "\n",
    "print(\"Resonance amplitude:\", amp_res)\n",
    "print(\"Initial amplitude:\", amp_ini)\n",
    "print(\"Drive frequency:\", fd_ini)\n",
    "print(\"Humidity:\", humid)\n",
    "print(\"Sample contact angle:\", theta_s)\n",
    "\n",
    "# d0_plotarray1 = np.linspace(-1e-9, d0_list[0], 50)\n",
    "# force_data = [force_ts(d0_plot_i) for d0_plot_i in d0_plotarray1]\n",
    "# d0_plotarray2 = np.linspace(a0, d0_list[0], 50)\n",
    "# dF_vdw = 2*H*R/(6*(d0_plotarray2**3))\n",
    "# delta_f = fc*(1-np.sqrt(1+(dF_vdw/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "\n",
    "# fig1, ax1 = plt.subplots(1, 2, figsize=(15,5))\n",
    "# ax1[0].plot(d0_plotarray1, force_data,  label='freq shift')\n",
    "# ax1[1].plot(d0_plotarray2, fc+delta_f, label='freq shift')\n",
    "# ax1[0].set_xlabel(\"d\")\n",
    "# ax1[1].set_xlabel(\"d\")\n",
    "# ax1[0].set_ylabel(\"force\")\n",
    "# ax1[1].set_ylabel(\"frequency shift\")\n",
    "# plt.show()\n",
    "\n",
    "# plot tip-sample interaction force\n",
    "d_near_list = [-.1e-9]#[-1e-9, 0.5e-9, 1e-9, 1.4e-9]\n",
    "force_ts_plotdata = {'d': [], 'd_near': [], 'direction':[], 'F_ts': [], 'F_vdw': [], 'F_elas': [], 'F_cap': []}\n",
    "\n",
    "for d_near in d_near_list:\n",
    "    d_plt = np.linspace(d_near, 6e-9, 1000)\n",
    "    d_rupt_plt, d_jumpin_plt, vol_bridge_plt = calculate_rupture(d=d_near) #[calculate_rupture(d=d_i) for d_i in d_plt]\n",
    "    for d_i in d_plt:\n",
    "        approach_plt = True #approach\n",
    "        force_total_a, force_vdw_a, force_elas_a, force_cap_a = force_ts(d_i, approach_plt, d_rupt_plt, d_jumpin_plt, vol_bridge_plt)\n",
    "        force_ts_plotdata['d'].append(d_i)\n",
    "        force_ts_plotdata['d_near'].append(d_near)\n",
    "        force_ts_plotdata['direction'].append('approach')\n",
    "        force_ts_plotdata['F_ts'].append(force_total_a)\n",
    "        force_ts_plotdata['F_vdw'].append(force_vdw_a)\n",
    "        force_ts_plotdata['F_elas'].append(force_elas_a)\n",
    "        force_ts_plotdata['F_cap'].append(force_cap_a)\n",
    "        approach_plt = False #retract\n",
    "        force_total_r, force_vdw_r, force_elas_r, force_cap_r  = force_ts(d_i, approach_plt, d_rupt_plt, d_jumpin_plt, vol_bridge_plt)\n",
    "        force_ts_plotdata['d'].append(d_i)\n",
    "        force_ts_plotdata['d_near'].append(d_near)\n",
    "        force_ts_plotdata['direction'].append('retract')\n",
    "        force_ts_plotdata['F_ts'].append(force_total_r)\n",
    "        force_ts_plotdata['F_vdw'].append(force_vdw_r)\n",
    "        force_ts_plotdata['F_elas'].append(force_elas_r)\n",
    "        force_ts_plotdata['F_cap'].append(force_cap_r)\n",
    "# print(theta_s, H,Y,a0)\n",
    "# force_ts_plotdatadf = pd.DataFrame(force_ts_plotdata)\n",
    "force_ts_plotdatadf = pd.melt(pd.DataFrame(force_ts_plotdata), id_vars=['d', 'd_near', 'direction'],\n",
    "                              value_vars=['F_ts', 'F_vdw', 'F_elas', 'F_cap'],\n",
    "                              var_name='force_type', value_name='force_value')\n",
    "force_ts_plotdatadf['d'] = force_ts_plotdatadf['d']/1e-9\n",
    "force_ts_plotdatadf['force_value']=force_ts_plotdatadf['force_value']/1e-9\n",
    "with sns.color_palette():\n",
    "    g = sns.relplot(data=force_ts_plotdatadf, x='d', y='force_value', style='direction', hue='force_type',\n",
    "                    col='d_near', kind='line', hue_order=['F_cap', 'F_vdw', 'F_elas', 'F_ts'])#, palette='flare')\n",
    "g.axes[0][0].axhline(0, linestyle=':', color='k')\n",
    "g.axes[0][0].set_xlabel('Distance (nm)')\n",
    "g.axes[0][0].set_ylabel('Force (nN)')\n",
    "plt.show()\n",
    "\n",
    "# save interaction plot\n",
    "if save == True:\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    file_suffix = f'thetas_{theta_s}_humidity_{humid:.2f}_hamaker_{H:1.2e}_tipradius_{R_t:1.1e}_kc_{kc:.0f}_elasticmods_{E_s:1.1e}_{timestamp}'\n",
    "    g.figure.savefig(f'data/interactionforce_plot_{file_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    print('saved', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10eaea-789b-4040-b007-9d6f9c2756cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forcets_datalist = []\n",
    "# force_ts_plotdatadf['Contact angle'] = theta_s\n",
    "# forcets_datalist.append(force_ts_plotdatadf)\n",
    "# forcets_fulldf = pd.concat(forcets_datalist)\n",
    "# forcets_fulldf\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "# g.figure.savefig(f'data/interactionforce_plot.svg',bbox_inches='tight')\n",
    "force_ts_filt = forcets_fulldf.query(\"`force_type`=='F_ts' and `force_value`<10 and `direction`=='approach'\")\n",
    "force_ts_filt_0 = force_ts_filt[force_ts_filt['Contact angle']==0]\n",
    "forcegrad_ts_0 = -np.gradient(force_ts_filt_0['force_value'], force_ts_filt_0['d'])\n",
    "# plt.plot(force_ts_filt['d'], force_ts_filt['force_value'], label='Force')\n",
    "plt.plot(force_ts_filt_0['d'], forcegrad_ts_0, label='Force gradient')\n",
    "\n",
    "force_ts_filt_90 = force_ts_filt[force_ts_filt['Contact angle']==90]\n",
    "forcegrad_ts_90 = -np.gradient(force_ts_filt_90['force_value'], force_ts_filt_90['d'])\n",
    "# plt.plot(force_ts_filt['d'], force_ts_filt['force_value'], label='Force')\n",
    "plt.plot(force_ts_filt_90['d'], forcegrad_ts_90, label='Force gradient')\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel('Distance (nm)')\n",
    "plt.ylabel('Force gradient (N/m)')\n",
    "plt.gcf().savefig(f'data/forcegrad_tsonly_0and90_plot.svg', bbox_inches='tight')\n",
    "# plt.xlim(0.2, 6.3)\n",
    "# plt.ylim(-25,0.2)\n",
    "# plt.legend(loc='lower right')\n",
    "# g = sns.lineplot(data=force_ts_filt, x='d', y='force_value', style='direction', hue='Contact angle', palette=[colors[0], colors[1]])#, legend=False)\n",
    "# g.axhline(0, linestyle=':', color='k')\n",
    "# g.set_xlabel('Distance (nm)')\n",
    "# g.set_ylabel('Force (nN)')\n",
    "# g.figure.savefig(f'data/force_tsonly_0and90_plot.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6375e-dd47-4fc1-81aa-4fe2c1494f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tip-sample interaction force\n",
    "d_near_list = np.linspace(a0, 6e-9, 100)#[-1e-9, 0.5e-9, 1e-9, 1.4e-9]\n",
    "color_list = sns.color_palette('flare',101)\n",
    "eng_diss_list = []\n",
    "for j, d_near in enumerate(d_near_list):\n",
    "    force_ts_plotdata = {'d': [], 'd_near': [], 'direction':[], 'F_ts': [], \n",
    "                         'F_vdw': [], 'F_elas': [], 'F_cap': []}\n",
    "    d_plt = np.linspace(d_near, 6e-9, 100)\n",
    "    d_rupt_plt, d_jumpin_plt, vol_bridge_plt = calculate_rupture(d=d_near) #[calculate_rupture(d=d_i) for d_i in d_plt]\n",
    "    for d_i in d_plt:\n",
    "        approach_plt = True #approach\n",
    "        force_total_a, force_vdw_a, force_elas_a, force_cap_a = force_ts(d_i, approach_plt, d_rupt_plt, d_jumpin_plt, vol_bridge_plt)\n",
    "        force_ts_plotdata['d'].append(d_i)\n",
    "        force_ts_plotdata['d_near'].append(d_near)\n",
    "        force_ts_plotdata['direction'].append('approach')\n",
    "        force_ts_plotdata['F_ts'].append(force_total_a)\n",
    "        force_ts_plotdata['F_vdw'].append(force_vdw_a)\n",
    "        force_ts_plotdata['F_elas'].append(force_elas_a)\n",
    "        force_ts_plotdata['F_cap'].append(force_cap_a)\n",
    "        approach_plt = False #retract\n",
    "        force_total_r, force_vdw_r, force_elas_r, force_cap_r  = force_ts(d_i, approach_plt, d_rupt_plt, d_jumpin_plt, vol_bridge_plt)\n",
    "        force_ts_plotdata['d'].append(d_i)\n",
    "        force_ts_plotdata['d_near'].append(d_near)\n",
    "        force_ts_plotdata['direction'].append('retract')\n",
    "        force_ts_plotdata['F_ts'].append(force_total_r)\n",
    "        force_ts_plotdata['F_vdw'].append(force_vdw_r)\n",
    "        force_ts_plotdata['F_elas'].append(force_elas_r)\n",
    "        force_ts_plotdata['F_cap'].append(force_cap_r)\n",
    "# print(theta_s, H,Y,a0)\n",
    "# force_ts_plotdatadf = pd.DataFrame(force_ts_plotdata)\n",
    "    force_ts_plotdatadf = pd.melt(pd.DataFrame(force_ts_plotdata), id_vars=['d', 'd_near', 'direction'],\n",
    "                                  value_vars=['F_ts', 'F_vdw', 'F_elas', 'F_cap'],\n",
    "                                  var_name='force_type', value_name='force_value')\n",
    "    # with sns.color_palette():\n",
    "    #     g = sns.relplot(data=force_ts_plotdatadf, x='d', y='force_value', style='direction', hue='force_type',\n",
    "    #                     kind='line', hue_order=['F_ts'])#, palette='flare')\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    force_ts_app = force_ts_plotdatadf[(force_ts_plotdatadf['force_type'] == 'F_ts') & \\\n",
    "    (force_ts_plotdatadf['direction'] == 'approach')]['force_value']\n",
    "    d0_app = force_ts_plotdatadf[(force_ts_plotdatadf['force_type'] == 'F_ts') & \\\n",
    "    (force_ts_plotdatadf['direction'] == 'approach')]['d']\n",
    "    force_ts_ret = force_ts_plotdatadf[(force_ts_plotdatadf['force_type'] == 'F_ts') & \\\n",
    "    (force_ts_plotdatadf['direction'] == 'retract')]['force_value']\n",
    "    d0_ret = force_ts_plotdatadf[(force_ts_plotdatadf['force_type'] == 'F_ts') & \\\n",
    "    (force_ts_plotdatadf['direction'] == 'retract')]['d']\n",
    "\n",
    "    plt.plot(d0_app, force_ts_app, '-', color=color_list[j])\n",
    "    plt.plot(d0_ret, force_ts_ret, '--', color=color_list[j])\n",
    "    \n",
    "    eng_app = simpson(y=force_ts_app, x=d0_app)\n",
    "    eng_ret = simpson(y=force_ts_ret, x=d0_ret)\n",
    "    eng_diss = eng_ret-eng_app\n",
    "    eng_diss_list.append(eng_diss)\n",
    "    # for d0_i in d_plt:\n",
    "    #     # d0_i = 1e-9\n",
    "    #     d0_i_ind_app = np.argmin(abs(d0_app-d0_i))\n",
    "    #     d0_i_ind_ret = np.argmin(abs(d0_app-d0_i))\n",
    "    #     # print(d0_i_ind_app, len(d0_app), len(force_ts_app))\n",
    "    #     eng_app = simpson(y=force_ts_app[d0_i_ind_app:], x=d0_app[d0_i_ind_app:])\n",
    "    #     eng_ret = simpson(y=force_ts_ret[d0_i_ind_ret:], x=d0_ret[d0_i_ind_ret:])\n",
    "    #     eng_diss = eng_ret-eng_app\n",
    "    #     eng_diss_list.append(eng_diss)\n",
    "    # print(eng_app, eng_ret, eng_ret-eng_app)\n",
    "# plt.plot(d0_app[d0_i_ind_app:], force_ts_app[d0_i_ind_app:])\n",
    "# plt.plot(d0_ret[d0_i_ind_ret:], force_ts_ret[d0_i_ind_ret:])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(d_near_list, eng_diss_list)\n",
    "plt.xlabel('d')\n",
    "plt.ylabel('energy diss')\n",
    "plt.show()\n",
    "\n",
    "df_engdiss = pd.DataFrame({'d':d_near_list, 'eng_diss':eng_diss_list})\n",
    "df_engdiss['theta_s'] = theta_s\n",
    "\n",
    "# #combine data frames\n",
    "# df_engdiss_full = pd.DataFrame() #initialize. comment when first set of data obtained\n",
    "df_engdiss_full = pd.concat([df_engdiss_full, df_engdiss])\n",
    "df_engdiss_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4c0ee-a578-48f7-9d2a-ddb7aca388f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot energy dissipation plots\n",
    "df_engdiss_full['theta_s'] = df_engdiss_full['theta_s'].astype('category') #makes colors more uniform\n",
    "sns.lineplot(data=df_engdiss_full, x='d', y='eng_diss', hue='theta_s', palette='flare')\n",
    "plt.xlim(0,2.0e-9)\n",
    "# plt.axhline(-1e-18)\n",
    "plt.show()\n",
    "\n",
    "#TODO: calculated amp in liquid\n",
    "#TODO: calculated theoretical freq shift from energy balance (check below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047e904-60f2-4527-a0e5-c166cb997afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1 = force_ts_plotdatadf[(force_ts_plotdatadf['force_type'] == 'F_vdw') & \\\n",
    "(force_ts_plotdatadf['direction'] == 'approach')]['force_value']\n",
    "dydx1 = np.gradient(test1, d_plt[1]-d_plt[0])\n",
    "test2 = force_ts_plotdatadf[(force_ts_plotdatadf['force_type'] == 'F_vdw') & \\\n",
    "(force_ts_plotdatadf['direction'] == 'retract')]['force_value']\n",
    "dydx2 = np.gradient(test2, d_plt[1]-d_plt[0])\n",
    "plt.plot(d_plt, -dydx1)\n",
    "plt.plot(d_plt, -dydx2)\n",
    "# plt.xlim(0.5e-9,5e-9)\n",
    "# plt.ylim(-5,20)\n",
    "plt.show()\n",
    "# force_ts_plotdatadf\n",
    "\n",
    "fshift1 = fc*(1-np.sqrt(1+(dydx1/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "fshift2 = fc*(1-np.sqrt(1+(dydx2/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "plt.plot(d_plt, fshift1)\n",
    "plt.plot(d_plt, fshift2)\n",
    "# plt.xlim(0.5e-9,5e-9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a09c42-dcdc-4d5e-94d1-b092c0879326",
   "metadata": {},
   "source": [
    "#### Spectroscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f318224-dae4-4806-a3de-9b16114cd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "# d0_far = 12e-9 #tip-sample rest distance, far (m)\n",
    "# d0_near = 2.5e-9 #tip-sample rest distance, near (m)\n",
    "# d0_pts = 20 #number of points for force-distance\n",
    "# d0_list = np.linspace(d0_far, d0_near, d0_pts) #[8e-9, 7e-9, 6e-9] #tip-sample distance, rest (m)\n",
    "# d0_list = d0_far + (d0_near - d0_far) * (np.linspace(0, 1, d0_pts))**(1/3) # = np.logspace(np.log(d0_far)/np.log(3),np.log(d0_near)/np.log(3),d0_pts, base=3)   \n",
    "\n",
    "# t0 = (phase_ini*np.pi/180)/wd_ini #if abs(phase_ini) > phase_zero else 0 #readjust this!\n",
    "# v0 = 0 #check readjustment!\n",
    "# x0 = amp_ini  #F0/(mc*gamma*wc) #theoretical free amplitude at resonance (far away)\n",
    "\n",
    "# t_list = [t0]\n",
    "# v_list = [v0]\n",
    "# x_list = [x0]\n",
    "\n",
    "# err_v_list = [0]\n",
    "# err_x_list = [0]\n",
    "# v_free_list = [v0]\n",
    "# x_free_list = [x0]\n",
    "\n",
    "# t = t0\n",
    "# v = v0\n",
    "# x = x0\n",
    "\n",
    "# t_free = t0\n",
    "# v_free = v0\n",
    "# x_free = x0\n",
    "\n",
    "# while t <= t_end:\n",
    "    \n",
    "#     t, v, x = RungeKuttaCoupled(t, v, x, dt, dvdt, dxdt)\n",
    "    \n",
    "#     t_list.append(t)\n",
    "#     v_list.append(v)\n",
    "#     x_list.append(x)\n",
    "\n",
    "# fs = 10*fd  # Sampling frequency in Hz (steady state osci)\n",
    "# dt = 1/fs #time step\n",
    "# ss_osci = 400 #number of steady state osci at end\n",
    "# t_end += ss_osci/fd #final time\n",
    "# colors = plt.cm.Wistia_r(np.linspace(0,1,len(d0_list)))\n",
    "# fig1, ax1 = plt.subplots(2, 2, figsize=(12,12))\n",
    "# @njit\n",
    "def run_simulation(params):\n",
    "    # print(x0, v0)\n",
    "    # print(kc, fc, wd_ini)\n",
    "    # get the start time\n",
    "    # exec_time = time.time()\n",
    "    # print('here')\n",
    "    phase_tol = params['phase_tol']\n",
    "    # global phase\n",
    "    # phase = 90\n",
    "    v = 0 #v0\n",
    "    x = amp_ini #x0\n",
    "    t = (phase_ini*np.pi/180)/wd_ini #t0\n",
    "    wd = wd_ini\n",
    "    simu_datadict = {'d': [], 'amplitude': [], 'phase': [], 'frequency': [], \n",
    "                     'deflection': [], 'd lower turn': [], 'direction': [], 'rupture distance': [],\n",
    "                    'jumpin distance': [], 'bridge volume': []}\n",
    "    # simu_datadict = [[], [], [], [], []]\n",
    "\n",
    "    # print('start')\n",
    "    for i, d0_i in enumerate(d0_list):\n",
    "        # while t <= t_end:\n",
    "        #     # t_free, v_free, x_free = RungeKuttaCoupled(t_free, v_free, x_free, dt, dvdt_free, dxdt)\n",
    "        #     # v_free_list.append(v_free)\n",
    "        #     # x_free_list.append(x_free)\n",
    "    \n",
    "        #     t, v, x, err_v, err_x = RungeKuttaCoupled(t, v, x, dt, dvdt, dxdt)        \n",
    "        #     t_list.append(t)\n",
    "        #     v_list.append(v)\n",
    "        #     x_list.append(x)\n",
    "        #     err_v_list.append(err_v)\n",
    "        #     err_x_list.append(err_x)\n",
    "        # # print('rk done')\n",
    "        # print(x,v,t)\n",
    "        amplitude, phase, deflection, d_lower_turn, d_rupt, d_jumpin, vol_bridge = solve_harmonic(v, x, t0=t, d0=d0_i, wd=wd) #, err_v_list, err_x_list\n",
    "        # print('yo')\n",
    "        # #set initial conditions for next iteration\n",
    "        # x = amplitude\n",
    "        # v = 0    \n",
    "        # def func_harm(wd_x):\n",
    "        #     global amplitude\n",
    "        #     global phase\n",
    "        #     amplitude, phase, t_list, v_list, x_list = solve_harmonic(v, x, d0=d0_i, wd=wd_x)\n",
    "        #     print('brent', amplitude, phase, phase-90, (wd_x/(2*np.pi))-fc)\n",
    "        #     return phase-90        \n",
    "        wd_up = wd\n",
    "        wd_low = wd-(2*np.pi*fd_step) if phase >=90 else wd+(2*np.pi*fd_step)\n",
    "        # wd_up = wd+(2*np.pi*fd_step)\n",
    "        # wd_low = wd-(2*np.pi*fd_step)\n",
    "\n",
    "        # func_harm = lambda wd_x: solve_harmonic(v, x, d0=d0_i, wd=wd_x)\n",
    "        # wd = brentq(func_harm, wd_up, wd_low, xtol=1)\n",
    "        # print(d0_i, wd/(2*np.pi), wd_up/(2*np.pi), wd_low/(2*np.pi))\n",
    "        #set initial conditions for next iteration\n",
    "        # x = amplitude\n",
    "        # v = 0  \n",
    "        # # wd_low = wd-(2*np.pi*fd_step)\n",
    "        phase_up = phase\n",
    "        if abs(phase-90) >= phase_tol:\n",
    "            # wd_low = wd+(2*np.pi*fd_step) if phase >=90 else wd-(2*np.pi*fd_step)\n",
    "            # wd_low = wd+(2*np.pi*fd_step)\n",
    "            # wd = wd_low\n",
    "            harm_output = solve_harmonic(v, x, t0=t, d0=d0_i, wd=wd_low)\n",
    "            # x = amplitude\n",
    "            # v = 0\n",
    "            phase_low = harm_output[1]\n",
    "            print('ini', phase_low, phase_up, wd_low/(2*np.pi), wd_up/(2*np.pi))\n",
    "        #iter_max = 5\n",
    "        iter_i = 0\n",
    "        reini_count = 1\n",
    "        while abs(phase-90) >= phase_tol:\n",
    "            print(phase_tol)\n",
    "            iter_i += 1\n",
    "            # print('bisection', amplitude, phase, phase-90, (wd/(2*np.pi))-fc, (wd_up/(2*np.pi))-fc, (wd_low/(2*np.pi))-fc)\n",
    "            phase_opp_sign =  np.sign((phase_up-90)*(phase_low-90))\n",
    "            \n",
    "            # if iter_i > 5:\n",
    "            if phase_opp_sign == 1:\n",
    "                phasemin_check = np.array([[abs(phase_up-90), phase_up, wd_up], \n",
    "                                           [abs(phase_low-90), phase_low, wd_low]])\n",
    "                phasemin_sort = phasemin_check[phasemin_check[:,0].argsort()]\n",
    "                phase_up, wd_up = phasemin_sort[0][1], phasemin_sort[0][2]\n",
    "                # wd_up = wd\n",
    "                # phase_up = phase\n",
    "                wd_low = wd_up-(2*np.pi*fd_step*(reini_count**2)) if phase_up >=90 else wd_up+(2*np.pi*fd_step*(reini_count**2))\n",
    "                harm_output = solve_harmonic(v, x, t0=t, d0=d0_i, wd=wd_low)\n",
    "                phase_low = harm_output[1]\n",
    "                if abs(phase_low-90) < phase_tol:\n",
    "                    amplitude, phase = harm_output[0], harm_output[1]\n",
    "                    fd = wd/(2*np.pi) #update frequency value\n",
    "                    simu_datadict['d'].append(d0_i)\n",
    "                    simu_datadict['amplitude'].append(amplitude)\n",
    "                    simu_datadict['phase'].append(phase)\n",
    "                    simu_datadict['frequency'].append(fd)\n",
    "                    simu_datadict['deflection'].append(deflection)\n",
    "                    # exec_time_new = time.time()\n",
    "                    # exec_time_diff = exec_time_new-exec_time\n",
    "                    print('RESULT', d0_i, amplitude, phase, fc-fd, phase_tol)#, exec_time_diff)# freq_peak-FT_omega[f_index]) (max(ss_x_list)-min(ss_x_list))/2\n",
    "                    # ax1[0][1].plot(t_list[-n_samples:], x_list[-n_samples:], label=\"cantilever\", color=colors[d0_i])\n",
    "                    # exec_time = exec_time_new\n",
    "                    \n",
    "                    #set initial conditions for next iteration\n",
    "                    x = amplitude\n",
    "                    v = 0  \n",
    "                    break\n",
    "                # wd, phase = wd_low, phase_low\n",
    "                print('reinit', phase_up, phase_low, reini_count)\n",
    "                reini_count += 1\n",
    "                continue\n",
    "            \n",
    "            reini_count = 1\n",
    "            wd_old = wd\n",
    "            phase_old = phase\n",
    "            wd = (wd_up + wd_low)/2 #bisection\n",
    "            # iter_i = 0\n",
    "            print('bisection', amplitude, phase, phase-90, (wd/(2*np.pi))-fc, (wd_up/(2*np.pi))-fc, (wd_low/(2*np.pi))-fc)\n",
    "            # else:\n",
    "            # # wd = wd-(2*np.pi*fd_step) if phase >=90 else wd+(2*np.pi*fd_step) #binary search\n",
    "            #     wd = wd_low - (phase_low * (wd_low - wd_up) / (phase_low - phase_up)) #secant method\n",
    "            #     print('secant', amplitude, phase, phase-90, (wd/(2*np.pi))-fc, (wd_up/(2*np.pi))-fc, (wd_low/(2*np.pi))-fc)\n",
    "            amplitude, phase, deflection, d_rupt, d_jumpin, vol_bridge = solve_harmonic(v, x, t0=t, d0=d0_i, wd=wd) #err_v_list, err_x_list\n",
    "            phase_step = abs(phase_old-phase)\n",
    "            print('step', iter_i, phase_step, (wd_old/(2*np.pi))-fc, (wd/(2*np.pi))-fc, phase_up, phase_low)\n",
    "\n",
    "            if abs(wd_old-wd) < fd_tol*2*np.pi:\n",
    "                print('break')\n",
    "                break\n",
    "            # if phase >= 90:\n",
    "            #     print('greater', phase)\n",
    "            #     fd_step = 2*fd_step\n",
    "            #     x = amplitude\n",
    "            #     v = 0\n",
    "            # else:\n",
    "            #     print('lesser', phase)\n",
    "            #     fd_step = fd_step/4\n",
    "            #     wd = wd_old\n",
    "            #     phase = phase_old            \n",
    "                \n",
    "            # wd_up, wd_low = wd_low, wd\n",
    "            # phase_up, phase_low = phase_low-90, phase-90\n",
    "            #if phase_step < phase_tol:\n",
    "            # phase_opp_sign = (phase_old-90)*(phase-90) #find if first two phase steps are above and below 90 (for bisection method)\n",
    "            # if iter_i == 1 and np.sign(phase_opp_sign) == 1:\n",
    "            #     wd_up = wd\n",
    "            #     wd_low = wd-(2*np.pi*fd_step) if phase >=90 else wd+(2*np.pi*fd_step)\n",
    "            #     iter_i = 0\n",
    "            #     continue\n",
    "            # else:\n",
    "            # if phase_step < phase_tol:\n",
    "            \n",
    "            # else:\n",
    "            # if iter_i > 5: #bisection\n",
    "            if phase >=90:\n",
    "                wd_up = wd\n",
    "                phase_up = phase\n",
    "            else:\n",
    "                wd_low = wd\n",
    "                phase_low = phase\n",
    "            # else: #secant\n",
    "            #     if (phase_old < 90 and phase < 90 and phase < phase_old) or (phase_old > 90 and phase > 90 and phase > phase_old):\n",
    "            #         print('reset')\n",
    "            #         wd_up = wd\n",
    "            #         phase_up = phase -90\n",
    "            #         wd_low = wd-(2*np.pi*fd_step) if phase >=90 else wd+(2*np.pi*fd_step)\n",
    "            #         harm_output = solve_harmonic(v, x, d0=d0_i, wd=wd_low)\n",
    "            #         phase_low = harm_output[1] - 90\n",
    "            #     else:\n",
    "            #         wd_up, wd_low = wd_low, wd\n",
    "            #         phase_up, phase_low = phase_low-90, phase-90\n",
    "            # #set initial conditions for next iteration\n",
    "            # x = amplitude\n",
    "            # v = 0\n",
    "        \n",
    "        # t_end += n_osci/fd #final time\n",
    "        # # t_free = t0\n",
    "        # # v_free = v0\n",
    "        # # x_free = x0\n",
    "        # # v = 0\n",
    "        \n",
    "        # # ss_osci = 100 #number of steady state osci at end\n",
    "        # ss_index = -int(ss_osci*fs/fd)\n",
    "        # ss_t_list = t_list[ss_index:]\n",
    "        # ss_x_list = x_list[ss_index:]\n",
    "        # n_samples = len(ss_t_list)\n",
    "        # # plt.plot(t_list, x_list, ':', label=\"steady\", color=\"yellow\")\n",
    "        # # plt.xlabel(\"Time\")\n",
    "        # # plt.ylabel(\"Position\")\n",
    "        # # plt.legend(loc=\"best\")\n",
    "        # # plt.show()\n",
    "        \n",
    "        # # x_list = F0*np.cos(wd*np.array(t_list))\n",
    "        # FT_omega = np.fft.fftfreq(n_samples, ss_t_list[1] - ss_t_list[0])\n",
    "        # FT = np.fft.fft(ss_x_list)\n",
    "        # FT_omega = np.fft.fftshift(FT_omega)\n",
    "        # FT = np.fft.fftshift(FT)\n",
    "        # FT_amplitude = np.abs(FT)*2/n_samples\n",
    "        # # plt.subplot(1,1,1)\n",
    "        # ax1[0][0].plot(FT_omega, FT_amplitude, '.-', color=colors[d0_i])\n",
    "        # # plt.plot(FT_omega[peak_ind], FT_amplitude[peak_ind], \"x\")\n",
    "        # # plt.grid(True)\n",
    "        # # ax2[0].set_xlim(0,2*fc)\n",
    "        # ax1[0][0].set_xlim(fc-3000, fc+3000)#(fc-freq_window,fc+freq_window)\n",
    "        # # plt.title('Fourier Transform')\n",
    "        # # plt.tight_layout()\n",
    "        # # plt.show()\n",
    "        \n",
    "        # # index, = np.where(np.isclose(FT_omega, fd, atol=100))\n",
    "        # f_index = int(n_samples/2) + np.argmax(FT_amplitude[int(n_samples/2):]) #np.argmin(abs(FT_omega-fd))\n",
    "        # # print(f_index, FT_omega[f_index], n_samples) #FT_omega[index[0]],\n",
    "        # ax1[0][0].plot(FT_omega[f_index], FT_amplitude[f_index], \"x\", color=colors[d0_i])\n",
    "        # amplitude = FT_amplitude[f_index] #np.abs(FT[f_index])*2/n_samples\n",
    "    \n",
    "        # x_drive = F0*np.cos(wd*np.array(ss_t_list))\n",
    "        # FT_drive = np.fft.fft(x_drive)\n",
    "        # FT_drive = np.fft.fftshift(FT_drive)\n",
    "        # phase = (np.angle(FT_drive[f_index])-np.angle(FT[f_index]))*180/np.pi\n",
    "        # fd_old = fd\n",
    "        fd = wd/(2*np.pi) #update frequency value\n",
    "        # fd_step = 10*abs(fd_old-fd) #dynamically update frequency step for faster convergence\n",
    "        # n_samples = int(fs*n_osci/fd)\n",
    "        # FT_omega_free = np.fft.fftfreq(n_samples, t_list[1] - t_list[0])\n",
    "        # FT_free = np.fft.fft(x_free_list[-n_samples:]-np.mean(x_free_list[-n_samples:]))\n",
    "        # FT_omega_free = np.fft.fftshift(FT_omega_free)\n",
    "        # FT_free = np.fft.fftshift(FT_free)\n",
    "        # # plt.plot(t_list[-n_samples:], x_free_list[-n_samples:], label=\"cantilever\", color=\"blue\")\n",
    "        # # plt.show()\n",
    "        # f_index_free = np.argmin(abs(FT_omega_free-fc))\n",
    "        # fwindow_ind = int(freq_window/(FT_omega_free[1]-FT_omega_free[0]))\n",
    "        # FT_amplitude_free = np.abs(FT_free)*2/n_samples\n",
    "        # peak_ind, _ = find_peaks(FT_amplitude_free[f_index_free-fwindow_ind:f_index_free+fwindow_ind])#, prominence=F0)#, width=20)\n",
    "        # peak_ind = peak_ind + f_index_free-fwindow_ind\n",
    "        # # plt.subplot(1,2,1)\n",
    "        # ax1[0].plot(FT_omega_free, FT_amplitude_free, '.-', color=colors[d0_i])\n",
    "        # ax1[0].plot(FT_omega_free[peak_ind], FT_amplitude_free[peak_ind], \"x\", color=colors[d0_i])\n",
    "        # ax1[0].grid(True)\n",
    "        # # ax1[0].set_xlim(0,2*fc)\n",
    "        # ax1[0].set_xlim(fc-freq_window,fc+freq_window)\n",
    "    \n",
    "        # ax1[1].plot(t_list[-n_samples:], x_free_list[-n_samples:], label=d0_i, color=colors[d0_i])\n",
    "        # plt.title('Fourier Transform')\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "        # print(peak_ind)\n",
    "        # freq_peak = FT_omega_free[peak_ind[-1]]\n",
    "        # print((max(ss_x_list)-min(ss_x_list))/2, fc-freq_peak, 2*Qc/wc)\n",
    "        spectrodir_i = spectrodir_list[i]\n",
    "        simu_datadict['d'].append(d0_i)\n",
    "        simu_datadict['amplitude'].append(amplitude)\n",
    "        simu_datadict['phase'].append(phase)\n",
    "        simu_datadict['frequency'].append(fd)\n",
    "        simu_datadict['deflection'].append(deflection)\n",
    "        simu_datadict['direction'].append(spectrodir_i)\n",
    "        simu_datadict['rupture distance'].append(d_rupt)\n",
    "        simu_datadict['jumpin distance'].append(d_jumpin)\n",
    "        simu_datadict['bridge volume'].append(vol_bridge)\n",
    "        simu_datadict['d lower turn'].append(d_lower_turn)\n",
    "        # simu_datadict[0].append(d0_i)\n",
    "        # simu_datadict[1].append(amplitude)\n",
    "        # simu_datadict[2].append(phase)\n",
    "        # simu_datadict[3].append(fd)\n",
    "        # simu_datadict[4].append(deflection)\n",
    "        # exec_time_new = time.time()\n",
    "        # exec_time_diff = exec_time_new-exec_time\n",
    "        # print('RESULT', d0_i, amplitude, phase, fc-fd, deflection)#, exec_time_diff)# freq_peak-FT_omega[f_index]) (max(ss_x_list)-min(ss_x_list))/2\n",
    "        # ax1[0][1].plot(t_list[-n_samples:], x_list[-n_samples:], label=\"cantilever\", color=colors[d0_i])\n",
    "        # exec_time = exec_time_new\n",
    "        \n",
    "        #set initial conditions for next iteration\n",
    "        x = deflection + amplitude if (d0_i+deflection-a0) > amplitude else (d0_i+deflection-a0)\n",
    "        v = 0\n",
    "        t = (phase*np.pi/180)/wd #if abs(phase) > phase_zero else 0\n",
    "    return simu_datadict\n",
    "\n",
    "# results = run_simulation(params=1e6)\n",
    "if __name__ == \"__main__\":\n",
    "    params = [\n",
    "        # {'phase_tol': 1},\n",
    "        {'phase_tol': 1e6},\n",
    "        # (1e6)\n",
    "        ]\n",
    "\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        results = pool.map(run_simulation, params)\n",
    "\n",
    "print('finished')\n",
    "simu_results = results\n",
    "spectro_datadf = pd.DataFrame(simu_results[0]) \n",
    "# spectro_datadf['d lower turn'] = spectro_datadf['d'] + spectro_datadf['deflection'] - spectro_datadf['amplitude']\n",
    "# plt.legend(loc=\"best\")\n",
    "# xdrive_list = F0*np.cos(wd*np.array(t_list))\n",
    "# ax1[0][1].plot(t_list, xdrive_list, label=\"drive\", color=\"red\")\n",
    "\n",
    "# ax1[1][0].plot(err_v_list)\n",
    "# ax1[1][1].plot(err_x_list)\n",
    "# # ax2[0].set_xlim(fc-1000, fc+1000)\n",
    "# plt.show()\n",
    "# plt.subplot(1,1,1)\n",
    "# plt.title(\"Cantilever oscillation\")\n",
    "# plt.plot(t_list, x_list, label=\"cantilever\", color=\"blue\")\n",
    "# plt.plot(t_list, xdrive_list, label=\"drive\", color=\"red\")\n",
    "# plt.show()\n",
    "fig2, ax2 = plt.subplots(2, 2, figsize=(12,10))\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='amplitude', hue='direction', \n",
    "             legend='auto', ax=ax2[0][0], sort=False, estimator=None, marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='phase', hue='direction',\n",
    "             legend=False, ax=ax2[0][1], sort=False, estimator=None, marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='deflection', hue='direction',\n",
    "             legend=False, ax=ax2[1][0], sort=False, estimator=None, marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='d lower turn', hue='direction',\n",
    "             legend=False, ax=ax2[1][1], sort=False, estimator=None, marker='.', markeredgewidth=0)\n",
    "ax2_00_ylim = ax2[0][0].get_ylim()\n",
    "d0_list_unique = np.unique(d0_list)\n",
    "ax2[0][0].plot(d0_list_unique, d0_list_unique, linestyle='--', color='gray')\n",
    "ax2[0][0].set_ylim(*ax2_00_ylim)\n",
    "ax2_10_ylim = ax2[1][0].get_ylim()\n",
    "ax2[1][0].plot(d0_list_unique, -d0_list_unique, linestyle='--', color='gray')\n",
    "ax2[1][0].set_ylim(*ax2_10_ylim)\n",
    "ax2[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "ax2[1][1].axhline(d_jumpin_ini, linestyle='--', color='gray')\n",
    "plt.show()\n",
    "\n",
    "if save == True:\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    file_suffix = f'thetas_{theta_s}_humidity_{humid:.2f}_ampfree_{amp_ini:1.1e}_fd_{fd_ini:.0f}_kc_{kc:.0f}_d0pts_{d0_pts}_{timestamp}'\n",
    "    header_df.to_csv(f'data/tapping_spectrodata_{file_suffix}.csv', index=False, header=False)\n",
    "    spectro_datadf.to_csv(f'data/tapping_spectrodata_{file_suffix}.csv', index=False, mode='a')\n",
    "    fig2.savefig(f'data/tapping_spectroplot_{file_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    print('saved', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2330864-5fcc-4be3-9e15-e56e72ab0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_datadf_filt = spectro_datadf[spectro_datadf['direction']=='retract']\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "ax.plot(spectro_datadf_filt['d']/1e-9, spectro_datadf_filt['amplitude']/1e-9, '.-', color=colors[0])\n",
    "# ax2 = ax.twinx()\n",
    "ax.plot(spectro_datadf_filt['d']/1e-9, spectro_datadf_filt['d lower turn']/1e-9, '-', color=colors[1])\n",
    "ax.axhline(d_jumpin_ini/1e-9, linestyle='--', color='gray')\n",
    "ax.set_xlabel('Distance (nm)')\n",
    "ax.set_ylabel('Amplitude (nm)')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(spectro_datadf_filt['d']/1e-9, spectro_datadf_filt['phase'], '.-', color=colors[2])\n",
    "ax2.set_ylabel('Phase (°)')\n",
    "fig.savefig(f'data/ampvsdistance_withphase_humid{humid:.2f}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "# ax.plot(spectro_datadf_filt['d']/1e-9, spectro_datadf_filt['amplitude']/1e-9, '.-')\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.plot(spectro_datadf_filt['d']/1e-9, spectro_datadf_filt['phase'], '.-', color='red')\n",
    "# ax.set_xlabel('Distance (nm)')\n",
    "# ax.set_ylabel('Amplitude (nm)')\n",
    "# ax2.set_ylabel('Phase (°)')\n",
    "# # fig.savefig(f'data/ampvsdistance_humid{humid:.2f}.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57f85f-a023-4168-8628-24afde3156b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(2, 2, figsize=(12,10))\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='amplitude', #hue='sweep direction', \n",
    "             legend='auto', ax=ax2[0][0], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='phase', #hue='sweep direction',\n",
    "             legend=False, ax=ax2[0][1], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='deflection', #hue='sweep direction',\n",
    "             legend=False, ax=ax2[1][0], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=spectro_datadf, x='d', y='d lower turn', #hue='sweep direction',\n",
    "             legend=False, ax=ax2[1][1], marker='.', markeredgewidth=0)\n",
    "ax2_00_ylim = ax2[0][0].get_ylim()\n",
    "ax2[0][0].plot(d0_list, d0_list, linestyle='--', color='gray')\n",
    "ax2[0][0].set_ylim(*ax2_00_ylim)\n",
    "ax2_10_ylim = ax2[1][0].get_ylim()\n",
    "ax2[1][0].plot(d0_list, -d0_list, linestyle='--', color='gray')\n",
    "ax2[1][0].set_ylim(*ax2_10_ylim)\n",
    "ax2[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "plt.show()\n",
    "fig2.savefig(f'data/cantisimu_spectroplot_{file_suffix}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc4e9f-25b5-4865-99e0-732d5f3951c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_datadict = simu_results[0]\n",
    "fig2, ax2 = plt.subplots(2, 3, figsize=(18,8))\n",
    "sns.lineplot(data=spectro_datadict, x='d', y='amplitude', ax=ax2[0][0], marker='.', markeredgewidth=0)\n",
    "# plt.show()\n",
    "sns.lineplot(data=spectro_datadict, x='d', y='phase', ax=ax2[0][1], marker='.', markeredgewidth=0)\n",
    "# plt.show()\n",
    "sns.lineplot(data=spectro_datadict, x='d', y='deflection', ax=ax2[0][2], marker='.', markeredgewidth=0)\n",
    "\n",
    "sns.lineplot(data=spectro_datadict, x='d', y='frequency', ax=ax2[1][0])\n",
    "dF_vdw = 2*H*R/(6*(np.array(spectro_datadict['d'])**3))\n",
    "delta_f = fc*(1-np.sqrt(1+(dF_vdw/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "ax2[1][0].plot(spectro_datadict['d'], fc+delta_f, ':', label='fit')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "force_list = []\n",
    "d1_range = -0.05e-9, max(spectro_datadict['d'])\n",
    "spectro_datadict['d1'] = np.linspace(d1_range[0],d1_range[1],50)\n",
    "for d_t in spectro_datadict['d1']:\n",
    "    if d_t >= a0:\n",
    "        F_vdw = -H*R/(6*(d_t**2))\n",
    "        F_elas = 0\n",
    "    else:\n",
    "        F_vdw = -H*R/(6*(a0**2))\n",
    "        F_elas = (4/3)*E*np.sqrt(R)*(a0-d_t)**(3/2) #CHECK THIS\n",
    "    F_ts = F_vdw + F_elas\n",
    "    force_list.append(F_ts)\n",
    "\n",
    "# F_vdw = -H*R/(6*(np.array(spectro_datadict['d'])**2))\n",
    "ax2[1][1].plot(spectro_datadict['d1'], force_list)\n",
    "ax2[1][1].set_xlabel(\"d\")\n",
    "ax2[1][1].set_ylabel(\"force\")\n",
    "for ax_i in ax2.flatten():\n",
    "    ax_i.set_xlim(*d1_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab315f-5b7a-4577-b7bd-52cdc4a4b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_datadict = simu_results[0]\n",
    "fig2, ax2 = plt.subplots(2, 2, figsize=(10,8))\n",
    "sns.lineplot(data=spectro_datadict, x='d', y='amplitude', ax=ax2[0][0], marker='.', markeredgewidth=0)\n",
    "# plt.show()\n",
    "sns.lineplot(data=spectro_datadict, x='d', y='phase', ax=ax2[0][1], marker='.', markeredgewidth=0)\n",
    "# plt.show()\n",
    "sns.lineplot(data=spectro_datadict, x='d', y='frequency', ax=ax2[1][0])\n",
    "dF_vdw = 2*H*R/(6*(np.array(spectro_datadict['d'])**3))\n",
    "delta_f = fc*(1-np.sqrt(1+(dF_vdw/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "ax2[1][0].plot(spectro_datadict['d'], fc+delta_f, ':', label='fit')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "force_list = []\n",
    "d1_range = -0.05e-9, max(spectro_datadict['d'])\n",
    "spectro_datadict['d1'] = np.linspace(d1_range[0],d1_range[1],50)\n",
    "for d_t in spectro_datadict['d1']:\n",
    "    if d_t >= a0:\n",
    "        F_vdw = -H*R/(6*(d_t**2))\n",
    "        F_elas = 0\n",
    "    else:\n",
    "        F_vdw = -H*R/(6*(a0**2))\n",
    "        F_elas = (4/3)*E*np.sqrt(R)*(a0-d_t)**(3/2) #CHECK THIS\n",
    "    F_ts = F_vdw + F_elas\n",
    "    force_list.append(F_ts)\n",
    "\n",
    "# F_vdw = -H*R/(6*(np.array(spectro_datadict['d'])**2))\n",
    "ax2[1][1].plot(spectro_datadict['d1'], force_list)\n",
    "ax2[1][1].set_xlabel(\"d\")\n",
    "ax2[1][1].set_ylabel(\"force\")\n",
    "for ax_i in ax2.flatten():\n",
    "    ax_i.set_xlim(*d1_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec07c7-1986-44f6-98de-2c4722baeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectro_datadf = pd.DataFrame(simu_results[0])\n",
    "# spectro_datadf['d']\n",
    "# spectro_datadf[spectro_datadf['d'] == d0_list[1]]['amplitude'].iloc[0]\n",
    "# len(np.array(['Forward']*(fd_pts-1) + ['Backward']*fd_pts))\n",
    "# np.logspace(np.log(fd_low)/np.log(10), np.log(fd_up)/np.log(10), 10)[::-1]\n",
    "# F_cap0/rm_eq\n",
    "freqresp_spectro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d31765-fb69-4561-a597-a541066a047a",
   "metadata": {},
   "source": [
    "#### Frequency Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190c2e0-75e1-4cf9-a9cc-4feb385e49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "# get the start time\n",
    "exec_time = time.time()\n",
    "# kc = 40 #cantilever spring constant (N/m)\n",
    "# fc = 350e3 #cantilever resonance frequency (Hz)\n",
    "# Qc = 400 #cantilever Q factor (free)\n",
    "# d0_far = 12e-9 #tip-sample rest distance, far (m)\n",
    "# d0_near = 2.5e-9 #tip-sample rest distance, near (m)\n",
    "# d0_pts = 10 #number of points for force-distance\n",
    "# d0_list = np.linspace(d0_far, d0_near, d0_pts) #[8e-9, 7e-9, 6e-9] #tip-sample distance, rest (m)\n",
    "# # d0_list = d0_far + (d0_near - d0_far) * (np.linspace(0, 1, d0_pts))**(1/3) # = np.logspace(np.log(d0_far)/np.log(3),np.log(d0_near)/np.log(3),d0_pts, base=3)\n",
    "# fd_ini = 70e3 #drive frequency (Hz)\n",
    "fd_low, fd_up = fd_ini, 301000#71000 #fd_ini + 2*(fc-fd_ini)\n",
    "fd_pts = int(fd_up-fd_low)\n",
    "fd_list = np.concatenate((np.linspace(fd_low, fd_up, fd_pts-1, endpoint=False),\n",
    "                          np.linspace(fd_up, fd_low, fd_pts)), axis=None)\n",
    "# fd_list = np.concatenate((np.logspace(np.log(fd_low)/np.log(10), np.log(fd_up)/np.log(10), fd_pts-1, endpoint=False),\n",
    "#                           np.logspace(np.log(fd_low)/np.log(10), np.log(fd_up)/np.log(10), fd_pts)[::-1]), axis=None)\n",
    "sweep_list = np.array(['Forward']*(fd_pts-1) + ['Backward']*fd_pts) #frequency sweep direction\n",
    "# fd_list = np.linspace(fd_low, fd_up, fd_pts)\n",
    "# fd_list = [fd_low, 68105.31026903474]\n",
    "# fd_list = np.logspace(np.log(fd_low)/np.log(10), np.log(fd_up)/np.log(10), fd_pts) \n",
    "# F0 = 10e-10 #drive amplitude (m)\n",
    "# d0_far = 10e-9 #tip-sample rest distance, far (m)\n",
    "# d0_near = 7e-9 #tip-sample rest distance, near (m)\n",
    "# d0_pts = 40 #number of points for force-distance\n",
    "# d0_list = np.linspace(d0_far, d0_near, d0_pts) #[8e-9, 7e-9, 6e-9] #tip-sample distance, rest (m)\n",
    "# # d0_list = d0_far + (d0_near - d0_far) * (np.linspace(0, 1, d0_pts))**(2) #np.logspace(np.log(d0_far)/np.log(3),np.log(d0_near)/np.log(3),d0_pts, base=3)\n",
    "# R = 20e-9 #tip radius (m)\n",
    "# H = 7.1e-20 #Hamaker constant (J)\n",
    "# Y = 35e-3 #surface energy of sample (mJ/m2)\n",
    "# # a0 = 1e-10 #intermolecular distance (m)\n",
    "# E_s = 1.2e9 #elastic modulus of sample (Pa)\n",
    "# nu_s = 0.3 #poisson ratio of sample\n",
    "# E_t = 130e9 #elastic modulus of tip (Pa)\n",
    "# nu_t = 0.3 #poisson ratio of tip\n",
    "# E = 1/(((1-nu_s**2)/E_s)+((1-nu_t**2)/E_t))\n",
    "\n",
    "# a0 = np.sqrt(H/(24*np.pi*Y)) #intermolecular distance (obtained by balancing vdW and  DMT adhesion)\n",
    "# wc = 2*np.pi*fc #angular resonance frequency of cantilever\n",
    "# mc = kc/(wc**2) #cantilever mass\n",
    "# # wd_ini = 2*np.pi*fd_ini #angular drive frequency\n",
    "# gamma = wc/Qc #damping coefficient, b/m (dimensionless)\n",
    "\n",
    "# # freq_res = 300 #frequency resolution (Hz)\n",
    "# # phase_res = 0.1 #phase resolution (deg)\n",
    "\n",
    "# #numerical method parameters\n",
    "# t0 = 0 #readjust this!\n",
    "# t0 = -wd_ini/(phase_ini*np.pi/180) if abs(phase_ini) > phase_zero else 0 #readjust this!\n",
    "# v0 = 0 #check readjustment!\n",
    "# x0 = amp_ini  #F0/(mc*gamma*wc) #theoretical free amplitude at resonance (far away)\n",
    "# x0 = 0 #F0/(mc*gamma*wc) #theoretical free amplitude at resonance (far away)\n",
    "# fs = 500*fc #10*wc*np.pi/(phase_res*180)  # Sampling frequency in Hz\n",
    "# dt = 1/fs #1/fd/20\n",
    "# n_osci = 1000#int(fd/freq_res) #number of oscillations\n",
    "# ss_osci = 100#int(n_osci/3) #number of steady state osci at end\n",
    "# t_end = n_osci/fd_ini #0.006 #dt*n_samples\n",
    "\n",
    "# fd_step = 10 #initial freq step size (Hz) to calculate bounds for wd in bisection section (PLL simulation)\n",
    "\n",
    "# # freq_window = 10000 #Hz for finding resonance peak\n",
    "\n",
    "# #macro variables for faster numerical calculation\n",
    "# wc2 = wc**2\n",
    "# F02 = F0/mc\n",
    "# F_el0 = (4/3)*E*np.sqrt(R)\n",
    "# F_vdw_adh = -H*R/(6*(a0**2))\n",
    "# F_vdw0 = -H*R/6\n",
    "# d_i = 0 \n",
    "\n",
    "# #Runge-Kutta method for 2nd order differential equation, coupled as 2 first order differential eqs.\n",
    "# def RungeKuttaCoupled(x, y, z, dx, dydx, dzdx, **kwargs):\n",
    "#     # Compute the Runge-Kutta steps\n",
    "#     k1 = dx * dydx(x, y, z, **kwargs)\n",
    "#     h1 = dx * dzdx(x, y, z)\n",
    "#     k2 = dx * dydx(x + dx / 2., y + k1 / 2., z + h1 / 2., **kwargs)\n",
    "#     h2 = dx * dzdx(x + dx / 2., y + k1 / 2., z + h1 / 2.)\n",
    "#     k3 = dx * dydx(x + dx / 2., y + k2 / 2., z + h2 / 2., **kwargs)\n",
    "#     h3 = dx * dzdx(x + dx / 2., y + k2 / 2., z + h2 / 2.)\n",
    "#     k4 = dx * dydx(x + dx, y + k3, z + h3, **kwargs)\n",
    "#     h4 = dx * dzdx(x + dx, y + k3, z + h3)\n",
    "\n",
    "#     # 4th order estimate\n",
    "#     y4 = y + 1. / 6. * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "#     z4 = z + 1. / 6. * (h1 + 2 * h2 + 2 * h3 + h4)\n",
    "    \n",
    "#     # Using additional coefficients for the 5th order estimate\n",
    "#     # b_star = [16 / 135, 0, 6656 / 12825, 28561 / 56430, -9 / 50, 2 / 55]\n",
    "#     # y5 = y + b_star[0] * k1 + b_star[2] * k2 + b_star[3] * k3 + b_star[4] * k4\n",
    "#     # z5 = z + b_star[0] * h1 + b_star[2] * h2 + b_star[3] * h3 + b_star[4] * h4\n",
    "\n",
    "#     # # Calculate the error\n",
    "#     # error_y = np.abs(y5 - y4)\n",
    "#     # error_z = np.abs(z5 - z4)\n",
    "\n",
    "#     # Update the new values for y and z using the 4th order estimate\n",
    "#     y = y4\n",
    "#     z = z4\n",
    "#     x = x + dx\n",
    "\n",
    "#     return x, y, z#, error_y, error_z\n",
    "\n",
    "# #tip-sample interaction force vs distance\n",
    "# def force_ts(d):\n",
    "#     if d >= a0:\n",
    "#         F_vdw = F_vdw0/(d**2)#-H*R/(6*(d**2))\n",
    "#         F_elas = 0\n",
    "#     else:\n",
    "#         F_vdw = F_vdw_adh #-H*R/(6*(a0**2)) #vdW adhesion\n",
    "#         F_elas = F_el0*(a0-d)**(3/2) #CHECK THIS\n",
    "#     return F_vdw + F_elas\n",
    "\n",
    "# def dvdt(t, v, x, **kwargs):\n",
    "#     d0 = kwargs['d0']\n",
    "#     wd = kwargs['wd']\n",
    "#     d_t = d0 + x #instantaneous tip sample distance\n",
    "#     F_ts = force_ts(d_t)\n",
    "\n",
    "#     return -(wc2*x)-(gamma*v)+(F_ts/mc)+(F02*np.cos(wd*t))\n",
    "\n",
    "    \n",
    "# def dxdt(t, v, x):\n",
    "#     return v\n",
    "\n",
    "# #solve \n",
    "# def solve_harmonic(v, x, **kwargs):\n",
    "#     t = t0    \n",
    "#     t_list = [t]\n",
    "#     v_list = [v]\n",
    "#     x_list = [x]\n",
    "#     # err_v_list = [0]\n",
    "#     # err_x_list = [0]\n",
    "    \n",
    "#     while t <= t_end:\n",
    "#         t, v, x = RungeKuttaCoupled(t, v, x, dt, dvdt, dxdt, **kwargs)  #, err_v, err_x     \n",
    "#         t_list.append(t)\n",
    "#         v_list.append(v)\n",
    "#         x_list.append(x)\n",
    "#         # err_v_list.append(err_v)\n",
    "#         # err_x_list.append(err_x)\n",
    "    \n",
    "#     # ss_osci = 100 #number of steady state osci at end\n",
    "#     wd = kwargs['wd']\n",
    "#     fd = wd/(2*np.pi)\n",
    "#     ss_index = -int(ss_osci*fs/fd)\n",
    "#     ss_t_list = t_list[ss_index:]\n",
    "#     ss_x_list = x_list[ss_index:]\n",
    "#     n_samples = len(ss_t_list)\n",
    "    \n",
    "#     # x_list = F0*np.cos(wd*np.array(t_list))\n",
    "#     FT_omega = np.fft.fftfreq(n_samples, ss_t_list[1] - ss_t_list[0])\n",
    "#     FT = np.fft.fft(ss_x_list)\n",
    "#     FT_omega = np.fft.fftshift(FT_omega)\n",
    "#     FT = np.fft.fftshift(FT)\n",
    "#     FT_amplitude = np.abs(FT)*2/n_samples\n",
    "\n",
    "#     f_index = int(n_samples/2) + np.argmax(FT_amplitude[int(n_samples/2):])\n",
    "#     amplitude = FT_amplitude[f_index]\n",
    "\n",
    "#     x_drive = F0*np.cos(wd*np.array(ss_t_list))\n",
    "#     FT_drive = np.fft.fft(x_drive)\n",
    "#     FT_drive = np.fft.fftshift(FT_drive)\n",
    "#     phase = np.angle(FT_drive[f_index])-np.angle(FT[f_index])\n",
    "#     # Normalize phase to be within [0, 2π]\n",
    "#     phase = np.mod(phase, 2 * np.pi)    \n",
    "#     # Adjust phase to be within [0, π]\n",
    "#     if phase > np.pi:\n",
    "#         phase -= np.pi\n",
    "#     phase = phase*180/np.pi #in degrees\n",
    "#     #set initial conditions for next iteration\n",
    "#     # x = amplitude\n",
    "#     # v = 0\n",
    "#     # t_end += n_osci/fd #final time\n",
    "\n",
    "#     return amplitude, phase, t_list, v_list, x_list#, err_v_list, err_x_list\n",
    "    \n",
    "def run_simulation(params):\n",
    "    # print(x0, v0)\n",
    "    # print(kc, fc, wd_ini)\n",
    "    # phase_tol = params['phase_tol']\n",
    "    # global phase\n",
    "    # phase = 90\n",
    "    d0_i = params['d0']\n",
    "    \n",
    "    #get initial condition from spectroscopy simulation earlier. RUN THAT FIRST!\n",
    "    # x = amp_res if (d0_i-a0) > amp_res else (d0_i-a0)\n",
    "    \n",
    "    amp_i = spectro_datadf[(spectro_datadf['d'] == d0_i) & (spectro_datadf['direction'] == 'approach')]['amplitude'].iloc[0]\n",
    "    phase_i = spectro_datadf[(spectro_datadf['d'] == d0_i) & (spectro_datadf['direction'] == 'approach')]['phase'].iloc[0]\n",
    "    defl_i = spectro_datadf[(spectro_datadf['d'] == d0_i) & (spectro_datadf['direction'] == 'approach')]['deflection'].iloc[0]\n",
    "    # print(amp_i, defl_i, amp_i+defl_i, phase_i)\n",
    "    x =  defl_i + amp_i#x0 #if d0_i >= x0 else d0_i\n",
    "    t = (phase_i*np.pi/180)/wd_ini #if abs(phase_i) > phase_zero else 0\n",
    "    v = 0 #v0\n",
    "    # wd = wd_ini\n",
    "    simu_datadict = {'d': [], 'amplitude': [], 'phase': [], 'frequency': [], \n",
    "                     'deflection': [], 'sweep direction': [], 'rupture distance': [],\n",
    "                    'jumpin distance': [], 'bridge volume': []}\n",
    "    osci_dict = {'d': [], 't':[], 'x': [], 'v': []}\n",
    "    # print('start')\n",
    "    for j, fd_j in enumerate(fd_list):\n",
    "        wd = 2*np.pi*fd_j\n",
    "        x_old = x\n",
    "        # print('guess', x, t, v)\n",
    "        amplitude, phase, deflection, d_rupt, d_jumpin, vol_bridge = solve_harmonic(v, x, t0=t, d0=d0_i, wd=wd) #, err_v_list, err_x_list\n",
    "        #set initial conditions for next iteration\n",
    "        # x = amp_res if (d0_i-a0) > amp_res else (d0_i-a0) #+ (amplitude-x_old)**2\n",
    "        x = deflection + amplitude if (d0_i+deflection-a0) > amplitude else (d0_i+deflection-a0)\n",
    "        v = 0\n",
    "        t = (phase*np.pi/180)/wd #if abs(phase) > phase_zero else 0\n",
    "\n",
    "        sweep_j = sweep_list[j]\n",
    "        simu_datadict['d'].append(d0_i)\n",
    "        simu_datadict['amplitude'].append(amplitude)\n",
    "        simu_datadict['phase'].append(phase)\n",
    "        simu_datadict['frequency'].append(fd_j)\n",
    "        simu_datadict['deflection'].append(deflection)\n",
    "        simu_datadict['sweep direction'].append(sweep_j)\n",
    "        simu_datadict['rupture distance'].append(d_rupt)\n",
    "        simu_datadict['jumpin distance'].append(d_jumpin)\n",
    "        simu_datadict['bridge volume'].append(vol_bridge)\n",
    "        # osci_dict['d'] = osci_dict['d'] + [d0_i]*len(t_list)\n",
    "        # osci_dict['t'] = osci_dict['t'] + t_list\n",
    "        # osci_dict['x'] = osci_dict['x'] + x_list\n",
    "        # osci_dict['v'] = osci_dict['v'] + v_list\n",
    "        \n",
    "        # print('RESULT', d0_i, amplitude, phase, fc-fd_j, exec_time_diff)# freq_peak-FT_omega[f_index]) (max(ss_x_list)-min(ss_x_list))/2\n",
    "        # ax1[0][1].plot(t_list[-n_samples:], x_list[-n_samples:], label=\"cantilever\", color=colors[d0_i])\n",
    "        # exec_time = exec_time_new\n",
    "        # print('RESULT', d0_i, fd_j, t, amplitude, phase, deflection, d0_i+deflection-amplitude)\n",
    "    return simu_datadict, osci_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    d0_list_simu = d0_list[:d0_pts:4] #d0_list[:] #[d0_list[-10]] #d0_list[-10:]\n",
    "    # d0_list_simu = d0_list[:2]\n",
    "    # d0_list_simu = d0_list_simu[:-10]\n",
    "    # d0_list_simu = d0_list[:d0_pts]\n",
    "    # d0_list_simu = d0_list_simu[-20:-1]\n",
    "    params = [{'d0': d0_i} for d0_i in d0_list_simu]\n",
    "    # params = [\n",
    "    #     {'d0': 0.1,},\n",
    "    #     # {'phase_tol': 1e6},\n",
    "    #     ]\n",
    "\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        results = pool.map(run_simulation, params)\n",
    "\n",
    "print('finished')\n",
    "print(d0_list_simu)\n",
    "exec_time_new = time.time()\n",
    "exec_time_diff = exec_time_new-exec_time\n",
    "print('time diff1', exec_time_diff)\n",
    "exec_time = exec_time_new\n",
    "\n",
    "freqresp_fulldf = pd.concat([pd.DataFrame(results_i[0]) for results_i in results], \n",
    "                           ignore_index=True)\n",
    "# freqresp_fulldf.reset_index(drop=True, inplace=True)\n",
    "# exec_time_new = time.time()\n",
    "# exec_time_diff = exec_time_new-exec_time\n",
    "# print('time diff2', exec_time_diff)\n",
    "# exec_time = exec_time_new\n",
    "\n",
    "osci_datadict = pd.concat([pd.DataFrame(results_i[1]) for results_i in results])\n",
    "\n",
    "#tip sample distance at lower turning point of oscilation\n",
    "freqresp_fulldf['d lower turn'] = freqresp_fulldf['d'] + freqresp_fulldf['deflection'] - freqresp_fulldf['amplitude']\n",
    "\n",
    "freqresp_spectro = {'d': [], 'amplitude': [], 'frequency': [], 'deflection': [], \n",
    "                    'd lower turn':[], 'sweep direction': [], 'rupture distance': [],\n",
    "                   'jumpin distance': [], 'bridge volume': []}\n",
    "for d0_i in d0_list_simu:\n",
    "    temp1 = freqresp_fulldf[freqresp_fulldf['d']== d0_i]\n",
    "    for sweep_i in temp1['sweep direction'].unique():\n",
    "        temp2 = temp1[temp1['sweep direction']== sweep_i]\n",
    "        temp2['phasecross'] = np.sign((temp2['phase']-90)*(temp2['phase']-90).shift(-1))\n",
    "        cross_ind = temp2['phasecross'].loc[lambda x: x==-1].index\n",
    "        # print(cross_ind)\n",
    "        if len(cross_ind) > 0:\n",
    "            cross_ind1 = cross_ind[0]\n",
    "            freq_i = np.mean([temp2['frequency'].loc[cross_ind1], temp2['frequency'].loc[cross_ind1+1]])\n",
    "            amp_i = np.mean([temp2['amplitude'].loc[cross_ind1], temp2['amplitude'].loc[cross_ind1+1]])\n",
    "            defl_i = np.mean([temp2['deflection'].loc[cross_ind1], temp2['deflection'].loc[cross_ind1+1]])\n",
    "            dlowturn_i = np.mean([temp2['d lower turn'].loc[cross_ind1], temp2['d lower turn'].loc[cross_ind1+1]])\n",
    "            d_rupt_i = np.mean([temp2['rupture distance'].loc[cross_ind1], temp2['rupture distance'].loc[cross_ind1+1]])\n",
    "            d_jumpin_i = np.mean([temp2['jumpin distance'].loc[cross_ind1], temp2['jumpin distance'].loc[cross_ind1+1]])\n",
    "            vol_bridge_i = np.mean([temp2['bridge volume'].loc[cross_ind1], temp2['bridge volume'].loc[cross_ind1+1]])\n",
    "        else:\n",
    "            freq_i = fc #temp2['frequency'].iloc[-1]\n",
    "            amp_i = 0 #temp2['amplitude'].iloc[-1]\n",
    "            defl_i = 0 #temp2['deflection'].iloc[-1]\n",
    "            dlowturn_i = 0\n",
    "            d_rupt_i = 0\n",
    "            d_jumpin_i = 0\n",
    "            vol_bridge_i = 0\n",
    "        freqresp_spectro['d'].append(d0_i)\n",
    "        freqresp_spectro['amplitude'].append(amp_i)\n",
    "        freqresp_spectro['frequency'].append(freq_i-fc)\n",
    "        freqresp_spectro['deflection'].append(defl_i)\n",
    "        freqresp_spectro['d lower turn'].append(dlowturn_i)\n",
    "        freqresp_spectro['sweep direction'].append(sweep_i)\n",
    "        freqresp_spectro['rupture distance'].append(d_rupt_i)\n",
    "        freqresp_spectro['jumpin distance'].append(d_jumpin_i)\n",
    "        freqresp_spectro['bridge volume'].append(vol_bridge_i)\n",
    "freqresp_spectro_df = pd.DataFrame(freqresp_spectro)\n",
    "\n",
    "fig4, ax4 = plt.subplots(2, 2, figsize=(12,10))\n",
    "sns.lineplot(data=freqresp_spectro_df, x='d', y='amplitude', hue='sweep direction', \n",
    "             legend='auto', ax=ax4[0][0], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=freqresp_spectro_df, x='d', y='frequency', hue='sweep direction',\n",
    "             legend=False, ax=ax4[0][1], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=freqresp_spectro_df, x='d', y='deflection', hue='sweep direction',\n",
    "             legend=False, ax=ax4[1][0], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=freqresp_spectro_df, x='d', y='d lower turn', hue='sweep direction',\n",
    "             legend=False, ax=ax4[1][1], marker='.', markeredgewidth=0)\n",
    "ax4_00_ylim = ax4[0][0].get_ylim()\n",
    "ax4[0][0].plot(d0_list_simu, d0_list_simu, linestyle='--', color='gray')\n",
    "ax4[0][0].set_ylim(*ax4_00_ylim)\n",
    "ax4_10_ylim = ax4[1][0].get_ylim()\n",
    "ax4[1][0].plot(d0_list_simu, -d0_list_simu, linestyle='--', color='gray')\n",
    "ax4[1][0].set_ylim(*ax4_10_ylim)\n",
    "ax4[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "ax4[1][1].axhline(d_jumpin_ini, linestyle='--', color='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig3, ax3 = plt.subplots(2, 2, figsize=(12,10))\n",
    "# sns.lineplot(data=freqresp_datadict, x='frequency', y='amplitude', hue='d', palette='flare', \n",
    "#              sort=False, estimator=None, legend=False, ax=ax3[0][0], marker='.', markeredgewidth=0)\n",
    "# sns.lineplot(data=freqresp_datadict, x='frequency', y='phase', hue='d', palette='flare', \n",
    "#              sort=False, estimator=None, legend=False, ax=ax3[0][1], marker='.', markeredgewidth=0)\n",
    "# sns.lineplot(data=freqresp_datadict, x='frequency', y='deflection', hue='d', palette='flare', \n",
    "#              sort=False, estimator=None, legend=False, ax=ax3[1][0], marker='.', markeredgewidth=0)\n",
    "# sns.lineplot(data=freqresp_datadict, x='frequency', y='d lower turn', hue='d', palette='flare', \n",
    "#              sort=False, estimator=None, legend=False, ax=ax3[1][1], marker='.', markeredgewidth=0)\n",
    "g1 = sns.relplot(data=freqresp_fulldf, x='frequency', y='amplitude', col='sweep direction', hue='d', palette='flare', \n",
    "             kind='line', sort=False, estimator=None, legend=False)#, marker='.', markeredgewidth=0)\n",
    "for ax_i in g1.axes.flatten():\n",
    "    ax_i.axvline(fc, linestyle='--', color='gray')\n",
    "g2 = sns.relplot(data=freqresp_fulldf, x='frequency', y='phase', col='sweep direction', hue='d',palette='flare', \n",
    "                kind='line', sort=False, estimator=None, legend=False)#, ax=ax3[1])#, marker='.', markeredgewidth=0)\n",
    "for ax_i in g2.axes.flatten():\n",
    "    ax_i.axhline(90, linestyle='--', color='gray')\n",
    "g3 = sns.relplot(data=freqresp_fulldf, x='frequency', y='deflection', col='sweep direction', hue='d',palette='flare', \n",
    "                 kind='line', sort=False, estimator=None, legend=False)#, ax=ax3[2])#, marker='.', markeredgewidth=0)\n",
    "g4 = sns.relplot(data=freqresp_fulldf, x='frequency', y='d lower turn', col='sweep direction', hue='d',palette='flare', \n",
    "                 kind='line', sort=False, estimator=None, legend=False)#, ax=ax3[3])#, marker='.', markeredgewidth=0)\n",
    "for ax_i in g4.axes.flatten():\n",
    "    ax_i.axhline(a0, linestyle='--', color='gray')\n",
    "    ax_i.axhline(d_jumpin_ini, linestyle='--', color='gray')\n",
    "# ax3[0][1].axhline(90, linestyle='--', color='k')\n",
    "# ax3[1][1].axhline(a0, linestyle='--', color='k')\n",
    "# handles, labels = ax3[0].get_legend_handles_labels()\n",
    "# new_labels = [f\"{float(label):.2e}\" for label in labels]\n",
    "# ax3[0].legend(handles, new_labels, title = 'd')\n",
    "# sns.move_legend(ax3[0], \"upper left\", bbox_to_anchor=(2.3, 1))\n",
    "plt.show()\n",
    "\n",
    "# sns.lineplot(data=osci_datadict, x='t', y='x')\n",
    "# plt.show()\n",
    "\n",
    "# exec_time_new = time.time()\n",
    "# exec_time_diff = exec_time_new-exec_time\n",
    "# print('time diff3', exec_time_diff)\n",
    "# exec_time = exec_time_new\n",
    "if save == True:\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    file_suffix = f'thetas_{theta_s}_humidity_{humid:.2f}_ampres_{amp_res:1.1e}_kc_{kc:.0f}_fd_{fd_ini:.0f}_fdpts_{fd_pts}_{timestamp}'\n",
    "    header_df.to_csv(f'data/noncontact_spectrodata_{file_suffix}.csv', index=False, header=False)\n",
    "    freqresp_spectro_df.to_csv(f'data/noncontact_spectrodata_{file_suffix}.csv', index=False, mode='a')\n",
    "    fig4.savefig(f'data/noncontact_spectroplot_{file_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    header_df.to_csv(f'data/freqresp_fulldfdata_{file_suffix}.csv', index=False, header=False)\n",
    "    freqresp_fulldf.to_csv(f'data/freqresp_fulldfdata_{file_suffix}.csv', index=False, mode='a')\n",
    "    g1.figure.savefig(f'data/freqresp_ampplot_{file_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    g2.figure.savefig(f'data/freqresp_phaseplot_{file_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    g3.figure.savefig(f'data/freqresp_deflplot_{file_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    g4.figure.savefig(f'data/freqresp_dlowplot_{file_suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    print('saved', timestamp)\n",
    "# exec_time_new = time.time()\n",
    "# exec_time_diff = exec_time_new-exec_time\n",
    "# print('time diff4', exec_time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa34648-a219-43dd-b198-05e4c819660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = d0_list[:d0_pts]\n",
    "for d0_i in test[-25:-1]:\n",
    "    print(d0_i)\n",
    "    test2 = spectro_datadf[(spectro_datadf['d'] == d0_i) & (spectro_datadf['direction'] == 'approach')]['amplitude'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739153b-eb86-4b04-be3b-89e0e2aeee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqresp_datadict = simu_results\n",
    "d0_unique = freqresp_fulldf['d'].unique()\n",
    "d0_select = d0_unique[-3] #[d0_unique[36]] d0_unique\n",
    "print(d0_select, len(d0_unique))\n",
    "d0_selectind = freqresp_fulldf['d'].isin([d0_select])\n",
    "freqresp_df_filt = freqresp_fulldf[d0_selectind]\n",
    "\n",
    "fig3, ax3 = plt.subplots(2, 2, figsize=(12,10))\n",
    "ax3[0][0].axvline(fc, linestyle='--', color='gray')\n",
    "ax3[0][1].axvline(fc, linestyle='--', color='gray')\n",
    "ax3[0][1].axhline(90, linestyle='--', color='gray')\n",
    "ax3[1][0].axhline(-d0_select, linestyle='--', color='gray')\n",
    "ax3[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "sns.lineplot(data=freqresp_df_filt, x='frequency', y='amplitude', hue='sweep direction',# hue='d', palette='flare', \n",
    "             sort=False, estimator=None, legend='auto', ax=ax3[0][0])#, marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=freqresp_df_filt, x='frequency', y='phase', hue='sweep direction',# hue='d',palette='flare', \n",
    "             sort=False, estimator=None, legend=False, ax=ax3[0][1])#, marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=freqresp_df_filt, x='frequency', y='deflection', hue='sweep direction',# hue='d',palette='flare', \n",
    "             sort=False, estimator=None, legend=False, ax=ax3[1][0], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=freqresp_df_filt, x='frequency', y='d lower turn', hue='sweep direction',# hue='d',palette='flare', \n",
    "             sort=False, estimator=None, legend=False, ax=ax3[1][1], marker='.', markeredgewidth=0)\n",
    "# handles, labels = ax3[0].get_legend_handles_labels()\n",
    "# new_labels = [f\"{float(label):.2e}\" for label in labels]\n",
    "# ax3[0].legend(handles, new_labels, title = 'd')\n",
    "# sns.move_legend(ax3[0], \"upper left\", bbox_to_anchor=(2.3, 1))\n",
    "plt.show()\n",
    "\n",
    "# fig4, ax4 = plt.subplots(1, 3, figsize=(18,5))\n",
    "# sns.lineplot(data=freqresp_spectro_df, x='d', y='amplitude', hue='sweep direction', \n",
    "#              legend='auto', ax=ax4[0], marker='.', markeredgewidth=0)\n",
    "# sns.lineplot(data=freqresp_spectro_df, x='d', y='frequency', hue='sweep direction',\n",
    "#              legend=False, ax=ax4[1], marker='.', markeredgewidth=0)\n",
    "# sns.lineplot(data=freqresp_spectro_df, x='d', y='deflection', hue='sweep direction',\n",
    "#              legend=False, ax=ax4[2], marker='.', markeredgewidth=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e0b57-e5fb-4508-a051-5ee1ef0d4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqresp_datadict = simu_results\n",
    "fig3, ax3 = plt.subplots(1, 2, figsize=(10,5))\n",
    "sns.lineplot(data=freqresp_datadict, x='frequency', y='amplitude', hue='d', palette='flare', legend=False, ax=ax3[0]) # marker='.', markeredgewidth=0,\n",
    "sns.lineplot(data=freqresp_datadict, x='frequency', y='phase', hue='d', palette='flare', legend=False, ax=ax3[1])  #marker='.', markeredgewidth=0,\n",
    "ax3[1].axhline(90, linestyle='--', color='k')\n",
    "# handles, labels = ax3[0].get_legend_handles_labels()\n",
    "# new_labels = [f\"{float(label):.2e}\" for label in labels]\n",
    "# ax3[0].legend(handles, new_labels, title = 'd')\n",
    "# sns.move_legend(ax3[0], \"upper left\", bbox_to_anchor=(2.3, 1))\n",
    "plt.show()\n",
    "\n",
    "fig4, ax4 = plt.subplots(1, 2, figsize=(12,5))\n",
    "sns.lineplot(data=freqresp_spectro, x='d', y='amplitude', legend=False, ax=ax4[0], marker='.')\n",
    "sns.lineplot(data=freqresp_spectro, x='d', y='frequency', legend=False, ax=ax4[1], marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a82db-e08d-4370-b2d7-e22756acaa00",
   "metadata": {},
   "source": [
    "#### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd855303-cd6a-4716-bbde-26ce63a2849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_folderpath = '/home/pranav/Work/Data/Murcia/Cantilever simulation/'\n",
    "simu_freqresp_files = ['cantisimu_freqresp_fulldfdata_thetas_0_humidity_0.00_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-162600.csv',\n",
    "                       'cantisimu_freqresp_fulldfdata_thetas_0_humidity_0.50_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-155858.csv',\n",
    "                       'cantisimu_freqresp_fulldfdata_thetas_45_humidity_0.50_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-180904.csv',\n",
    "                       'cantisimu_freqresp_fulldfdata_thetas_90_humidity_0.50_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-174014.csv'\n",
    "                      ]\n",
    "simu_spectro_files = ['cantisimu_freqresp_spectrodata_thetas_0_humidity_0.00_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-162600.csv',\n",
    "                      'cantisimu_freqresp_spectrodata_thetas_0_humidity_0.50_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-155858.csv',\n",
    "                      'cantisimu_freqresp_spectrodata_thetas_45_humidity_0.50_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-180904.csv',\n",
    "                      'cantisimu_freqresp_spectrodata_thetas_90_humidity_0.50_ampfree_1.4e-09_fd_68000_kc_2_fdpts_2000_240808-174014.csv'\n",
    "                     ]\n",
    "simu_spectro_tapping_files = ['cantisimu_spectrodata_thetas_0_humidity_0.00_ampfree_1.0e-08_fd_70000_kc_2_d0pts_50_240808-171952.csv',\n",
    "                              'cantisimu_spectrodata_thetas_0_humidity_0.50_ampfree_1.0e-08_fd_70000_kc_2_d0pts_50_240808-174652.csv',\n",
    "                              'cantisimu_spectrodata_thetas_45_humidity_0.50_ampfree_1.0e-08_fd_70000_kc_2_d0pts_50_240808-174752.csv',\n",
    "                              'cantisimu_spectrodata_thetas_90_humidity_0.50_ampfree_1.0e-08_fd_70000_kc_2_d0pts_50_240808-165924.csv'\n",
    "                             ]\n",
    "\n",
    "# simu_freqresp_df = pd.read_csv(f'{simu_folderpath}/{simu_freqresp_files[0]}', header=36)\n",
    "# simu_spectro_df = pd.read_csv(f'{simu_folderpath}/{simu_spectro_files[0]}', header=36)\n",
    "# simu_spectro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cb268-4812-49e6-a184-f406a44c11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tapping mode data analysis\n",
    "\n",
    "simu_tapping_spectrodf_list = []\n",
    "simu_tapping_setpointdf_list = []\n",
    "amplitude_setpoint_list = np.linspace(0.9, 0.6, 20)\n",
    "for simu_spectro_file_i in simu_spectro_tapping_files:\n",
    "    simu_spectro_df_i = pd.read_csv(f'{simu_folderpath}/{simu_spectro_file_i}', header=36)\n",
    "    simu_spectro_df_i['label'] = ','.join(simu_spectro_file_i.split('_')[3:7])\n",
    "    simu_spectro_df_i['amp_ratio'] = simu_spectro_df_i['amplitude']/simu_spectro_df_i['amplitude'].loc[0]\n",
    "    simu_tapping_spectrodf_list.append(simu_spectro_df_i)\n",
    "    for amp_setpoint_i in amplitude_setpoint_list:\n",
    "        simu_tapping_setpointdf_i = simu_spectro_df_i.iloc[(simu_spectro_df_i['amp_ratio']-amp_setpoint_i).abs().argsort()[:1]]\n",
    "        simu_tapping_setpointdf_i['Amplitude setpoint'] = amp_setpoint_i\n",
    "        simu_tapping_setpointdf_list.append(simu_tapping_setpointdf_i)\n",
    "    \n",
    "simu_tapping_spectro_df_all = pd.concat(simu_tapping_spectrodf_list)\n",
    "simu_tapping_setpointdf_all = pd.concat(simu_tapping_setpointdf_list)\n",
    "print('tapping mode')\n",
    "\n",
    "sns.lineplot(data=simu_tapping_setpointdf_all, x='Amplitude setpoint', y='d lower turn', hue='label',\n",
    "             legend='auto', marker='.', markeredgewidth=0)\n",
    "plt.show()\n",
    "\n",
    "plot_drange = (6e-9, 15e-9)\n",
    "fig2, ax2 = plt.subplots(2, 2, figsize=(12,10))\n",
    "g1 = sns.lineplot(data=simu_tapping_spectro_df_all, x='d', y='amplitude', hue='label', \n",
    "             legend='auto', ax=ax2[0][0], marker='.', markeredgewidth=0)\n",
    "g2 = sns.lineplot(data=simu_tapping_spectro_df_all, x='d', y='phase', hue='label', \n",
    "             legend=False, ax=ax2[0][1], marker='.', markeredgewidth=0)\n",
    "g3 = sns.lineplot(data=simu_tapping_spectro_df_all, x='d', y='deflection', hue='label',\n",
    "             legend=False, ax=ax2[1][0], marker='.', markeredgewidth=0)\n",
    "g4 = sns.lineplot(data=simu_tapping_spectro_df_all, x='d', y='d lower turn', hue='label',\n",
    "             legend=False, ax=ax2[1][1], marker='.', markeredgewidth=0)\n",
    "for ax_i in [g1, g2, g3, g4]:\n",
    "    ax_i.set_xlim(*plot_drange)\n",
    "plot_d0list = simu_tapping_spectro_df_all['d'].unique()\n",
    "ax2_00_ylim = ax2[0][0].get_ylim()\n",
    "ax2[0][0].plot(plot_d0list, plot_d0list, linestyle='--', color='gray')\n",
    "ax2[0][0].set_ylim(*ax2_00_ylim)\n",
    "ax2_10_ylim = ax2[1][0].get_ylim()\n",
    "ax2[1][0].plot(plot_d0list, -plot_d0list, linestyle='--', color='gray')\n",
    "ax2[1][0].set_ylim(*ax2_10_ylim)\n",
    "# ax2[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec5e4e-64d7-4e98-b8de-b65e549b077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate frequency shift for non-linear spring interaction using energies\n",
    "\n",
    "amp_init = 10e-9\n",
    "liq_wall = 1.5e-9\n",
    "# d0_plotarray1 = np.linspace(-1e-9, d0_list[0], 50)\n",
    "# force_data = [force_ts(d0_plot_i) for d0_plot_i in d0_plotarray1]\n",
    "d0_plotarray1 = np.linspace(15e-9, 6e-9, 100)\n",
    "dF_vdw1 = 2*H*R/(6*(d0_plotarray1**3))\n",
    "delta_f1 = fc*(1-np.sqrt(1+(dF_vdw1/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "\n",
    "# d0_plotarray3 = np.linspace(10e-9, 1e-9, 100)\n",
    "# dF_cap = np.array([-F_cap0/rm_eq]*100)\n",
    "# delta_f2 = fc*(1-np.sqrt(1+(dF_cap/kc)))\n",
    "\n",
    "d0_plotarray2 = np.linspace(15e-9, 6e-9, 100)\n",
    "freqshift_array = []\n",
    "for d0_i in d0_plotarray2:\n",
    "    amp_i = min([amp_init, d0_i-liq_wall])\n",
    "    d_t_array_i = np.linspace(d0_i-amp_i, d0_i+amp_i, 100)\n",
    "    dx_i = np.abs(np.linspace(-amp_i, amp_i, 100))\n",
    "    dF_vdw_i = 2*H*R/(6*(d_t_array_i**3))\n",
    "    # print(max(dF_vdw_i), min(dF_vdw_i))\n",
    "    # F_vdw_i = H*R/(6*(d_t_array_i**2))\n",
    "    osci_eng = simpson(y=dF_vdw_i*dx_i, x=d_t_array_i)\n",
    "    # print(d0_i, osci_eng)\n",
    "    k_eff = 1*osci_eng/(amp_i**2)\n",
    "    delta_f = fc*(1-np.sqrt(1+(k_eff/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "    freqshift_array.append(delta_f)\n",
    "    # print(d0_i, amp_i, d0_i-amp_i, osci_eng, k_eff, delta_f)\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(10,5))\n",
    "# ax1[0].plot(d0_plotarray1, force_data,  label='freq shift')\n",
    "ax1.plot(d0_plotarray1, delta_f1, label='linear')\n",
    "# ax1.plot(d0_plotarray3, delta_f2, label='linear capil')\n",
    "ax1.plot(d0_plotarray2, freqshift_array, label='non-linear')\n",
    "# ax1[0].set_xlabel(\"d\")\n",
    "ax1.set_xlabel(\"d\")\n",
    "# ax1[0].set_ylabel(\"force\")\n",
    "ax1.set_ylabel(\"frequency shift\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbfdea0-2a3d-46ca-b975-92ac85182cc2",
   "metadata": {},
   "source": [
    "##### Non-contact spectroscopy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d067230-aa1c-49b3-88a6-7069c3ea2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-contact mode simulation data analysis\n",
    "\n",
    "simudata_inipath = Path(r'/home/pranav/Work/Data/Murcia/Cantilever simulation/')#Analysis/20240811 parametric study/non-contact mode/'\n",
    "# label_name = 'Sample contact angle' #choose from header names in simulation data\n",
    "# label_name2 = 'Label'\n",
    "\n",
    "noncontact_spectro_files = list(filedialog.askopenfilenames(title='Choose spectroscopy file', \n",
    "                                                            initialdir=simudata_inipath, filetypes=(('data', '*.csv'),)))\n",
    "simudata_folderpath = Path(noncontact_spectro_files[0]).parent\n",
    "# noncontact_spectro_files = ['data/noncontact_spectrodata_novdw_thetas_0_humidity_0.50_ampres_1.0e-08_kc_2_fd_67000_fdpts_4000_240817-104321.csv',\n",
    "#                             'data/noncontact_spectrodata_novdw_thetas_90_humidity_0.50_ampres_1.0e-08_kc_2_fd_67000_fdpts_4000_240817-094520.csv',\n",
    "#                             'data/noncontact_spectrodata_novdw_thetas_60_humidity_0.50_ampres_1.0e-08_kc_2_fd_67000_fdpts_4000_240817-084449.csv',\n",
    "#                            ]\n",
    "simu_spectrodf_list = []\n",
    "simu_noncontact_setpointdf_list = []\n",
    "amplitude_setpoint_list = np.linspace(0.99, 0.7, 10)\n",
    "header_lines = 37\n",
    "for simu_spectro_file_i in noncontact_spectro_files:\n",
    "    simu_spectro_file_i = Path(simu_spectro_file_i)\n",
    "    if simu_spectro_file_i.name.find('tapping') != -1:\n",
    "        spectro_mode_i = 'tapping'\n",
    "    if simu_spectro_file_i.name.find('noncontact') != -1:\n",
    "        spectro_mode_i = 'noncontact'\n",
    "    # spectro_mode_i = simu_spectro_file_i.name.split('_')[0] #tapping or non-contact\n",
    "    simu_spectro_df_i = pd.read_csv(simu_spectro_file_i, header=header_lines)\n",
    "    simu_spectro_df_i['Mode'] = spectro_mode_i\n",
    "    header_dict_i = {}\n",
    "    # with open(simu_spectro_file_i, \"r\") as f_j:\n",
    "    with simu_spectro_file_i.open(mode=\"r\") as f_j:\n",
    "        for j in range(header_lines): #header lines\n",
    "            line_j = next(f_j).strip().split(':')\n",
    "            key_j = line_j[0].split('[')[0].strip()\n",
    "            val_j = line_j[1].strip()\n",
    "            try:\n",
    "                header_dict_i[key_j] = float(val_j)\n",
    "            except:\n",
    "                header_dict_i[key_j] = val_j\n",
    "    # simu_spectro_df_i[label_name] = round(header_dict_i[label_name], 10)#','.join(simu_spectro_file_i.split('_')[3:7])\n",
    "    # simu_spectro_df_i[label_name] = int(header_dict_i[label_name])\n",
    "    # label_val = os.path.basename(simu_spectro_file_i).split('_')[2]\n",
    "    # simu_spectro_df_i[label_name2] = label_val if label_val != 'thetas' else 'withvdw'\n",
    "    if spectro_mode_i == 'tapping':\n",
    "        simu_spectro_df_i['sweep direction'] = ''\n",
    "        dir_label_i = 'direction'\n",
    "        simu_spectro_df_i['stability'] = 'stable'\n",
    "    elif spectro_mode_i == 'noncontact':\n",
    "        simu_spectro_df_i['phase'] = 90\n",
    "        simu_spectro_df_i['direction'] = ''\n",
    "        dir_label_i = 'sweep direction' #used below to get setpoint plots\n",
    "\n",
    "    simu_spectro_df_i['Capillary condensation distance'] =  header_dict_i['Capillary condensation distance']\n",
    "    amp_res_i = header_dict_i['Free resonance amplitude']\n",
    "    amp_i = simu_spectro_df_i['amplitude']\n",
    "    mc_i = header_dict_i['Cantilever mass']\n",
    "    kc_i = header_dict_i['Spring constant']\n",
    "    Qc_i = header_dict_i['Quality factor']\n",
    "    fc_i = header_dict_i['Resonance frequency']\n",
    "    freq_i = fc_i + simu_spectro_df_i['frequency']\n",
    "\n",
    "    simu_spectro_df_i['Free resonance amplitude'] = amp_res_i\n",
    "    simu_spectro_df_i['Spring constant'] = kc_i\n",
    "    simu_spectro_df_i['Sample contact angle'] = int(header_dict_i['Sample contact angle'])\n",
    "    simu_spectro_df_i['Humidity'] = header_dict_i['Humidity']\n",
    "    \n",
    "    # simu_spectro_df_i['energy_dissipated'] = (mc_i*(np.pi**2)*((freq_i**2)+(fc_i**2)))*((amp_res_i**2)-(amp_i**2))\n",
    "    simu_spectro_df_i['energy_dissipated'] = (np.pi*kc_i/Qc_i)*((amp_i*amp_res_i)-((amp_i**2)*freq_i/fc_i))\n",
    "    simu_spectro_df_i['amp_ratio'] = simu_spectro_df_i['amplitude']/simu_spectro_df_i['amplitude'].loc[0]\n",
    "    ampinliq_app_i = simu_spectro_df_i['Capillary condensation distance'] - simu_spectro_df_i['d lower turn']\n",
    "    simu_spectro_df_i['amp_in_liq'] = ampinliq_app_i#/simu_spectro_df_i['amplitude']\n",
    "    simu_spectro_df_i['amp_in_liq'] = simu_spectro_df_i['amp_in_liq'].where(simu_spectro_df_i['amp_in_liq'] >= 0, 0)\n",
    "    simu_spectro_df_i['amp_in_liq_ratio'] = simu_spectro_df_i['amp_in_liq']/simu_spectro_df_i['amplitude']\n",
    "    \n",
    "    simu_spectrodf_list.append(simu_spectro_df_i)\n",
    "\n",
    "    for sweep_dir_i in simu_spectro_df_i[dir_label_i].unique():\n",
    "        if sweep_dir_i != '':\n",
    "            simu_spectro_df_filt_i = simu_spectro_df_i[simu_spectro_df_i[dir_label_i]==sweep_dir_i]\n",
    "            simu_spectro_df_filt_i = simu_spectro_df_filt_i[simu_spectro_df_filt_i['stability']=='stable'] #only consider stable points\n",
    "            for amp_setpoint_i in amplitude_setpoint_list:\n",
    "                simu_noncontact_setpointdf_i = simu_spectro_df_filt_i.iloc[(simu_spectro_df_filt_i['amp_ratio']-\\\n",
    "                                                                            amp_setpoint_i).abs().argsort()[:1]]\n",
    "                simu_noncontact_setpointdf_i['Amplitude setpoint'] = round(amp_setpoint_i, 2)\n",
    "                simu_noncontact_setpointdf_list.append(simu_noncontact_setpointdf_i)\n",
    "\n",
    "simu_spectro_df_all = pd.concat(simu_spectrodf_list)\n",
    "# simu_spectro_df_all[label_name] = simu_spectro_df_all[label_name].astype('category') #makes colors more uniform\n",
    "simu_noncontact_setpointdf_all = pd.concat(simu_noncontact_setpointdf_list)\n",
    "# simu_noncontact_setpointdf_all[label_name] = simu_noncontact_setpointdf_all[label_name].astype('category') #makes colors more uniform\n",
    "print('non-contact mode: loaded files.')# Label:', label_name)\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "# print(noncontact_spectro_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e09d8b-9559-4193-89aa-576e80d55dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_drange = None#(10e-9, 13e-9)\n",
    "# plot_freqrange = None#(-400, 10)\n",
    "\n",
    "# sns.relplot(data=simu_noncontact_setpointdf_all, x=label_name, y='frequency', hue='Amplitude setpoint', col='sweep direction',\n",
    "#                  kind='line', legend='full', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': plot_freqrange}) #style=label_name2)\n",
    "# sns.relplot(data=simu_spectro_df_all, x='d', y='amp_in_liq', hue=label_name, col='sweep direction', #style=label_name2,\n",
    "#                  kind='line', legend='auto', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': None})\n",
    "\n",
    "# sns.relplot(data=simu_noncontact_setpointdf_all, x='Amplitude setpoint', y='amp_in_liq_ratio', hue=label_name, col='sweep direction', #style=label_name2,\n",
    "#                  kind='line', legend='auto', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': None})\n",
    "\n",
    "# sns.relplot(data=simu_noncontact_setpointdf_all, x='energy_dissipated', y='amp_in_liq', hue=label_name, col='sweep direction', #style=label_name2,\n",
    "#                  kind='line', legend='auto', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': None})\n",
    "\n",
    "# # g8 = sns.relplot(data=simu_spectro_df_all, x='d', y='frequency', hue=label_name, col='sweep direction', style=label_name2,\n",
    "# #                  kind='line', legend='auto', palette=color_palette, facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "# plt.show()\n",
    "\n",
    "#save plots\n",
    "# timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "# file_suffix = 'effectofvdw_' if ((plot_drange==None) and (plot_freqrange==None) and (plot_amprange==None)) else 'filt_effectofvdw_'\n",
    "# g1.figure.savefig(f'{simudata_folderpath}/setpoint_amp_frequency_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g8.figure.savefig(f'{simudata_folderpath}/frequency_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    \n",
    "simu_spectro_df_filt = simu_spectro_df_all[simu_spectro_df_all['sweep direction']=='Backward']\n",
    "\n",
    "#estimate frequency shift for non-linear spring interaction using energies\n",
    "\n",
    "# amp_init = 10e-9\n",
    "# liq_wall = 0.1e-9\n",
    "\n",
    "H = 64e-21\n",
    "R = 20e-9\n",
    "kc = 2\n",
    "fc = 70e3\n",
    "\n",
    "# d0_plotarray1 = np.linspace(-1e-9, d0_list[0], 50)\n",
    "# force_data = [force_ts(d0_plot_i) for d0_plot_i in d0_plotarray1]\n",
    "# d0_plotarray1 = np.linspace(15e-9, 6e-9, 100)\n",
    "# dF_vdw1 = 2*H*R/(6*(d0_plotarray1**3))\n",
    "# delta_f1 = fc*(1-np.sqrt(1+(dF_vdw1/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "\n",
    "# d0_plotarray3 = np.linspace(10e-9, 1e-9, 100)\n",
    "# dF_cap = np.array([-F_cap0/rm_eq]*100)\n",
    "# delta_f2 = fc*(1-np.sqrt(1+(dF_cap/kc)))\n",
    "\n",
    "d0_plotarray2 = simu_spectro_df_filt['d'] #np.linspace(15e-9, 6e-9, 100)\n",
    "amp_plotarray2 = simu_spectro_df_filt['amplitude']\n",
    "freqshift_array = []\n",
    "for d0_i, amp_i in zip(d0_plotarray2, amp_plotarray2):\n",
    "    # amp_i = min([amp_init, d0_i-liq_wall])\n",
    "    d_t_array1_i = np.linspace(d0_i, d0_i-amp_i, 100)\n",
    "    dx1_i = np.linspace(0, amp_i, 100) #CHECK\n",
    "    dF_vdw1_i = 2*H*R/(6*(d_t_array1_i**3))\n",
    "    osci_eng1 = simpson(y=dF_vdw1_i*dx1_i, x=dx1_i)\n",
    "    d_t_array2_i = np.linspace(d0_i, d0_i+amp_i, 100)\n",
    "    dx2_i = np.linspace(0, amp_i, 100) #CHECK\n",
    "    dF_vdw2_i = 2*H*R/(6*(d_t_array2_i**3))\n",
    "    osci_eng2 = simpson(y=dF_vdw2_i*dx2_i, x=dx2_i)\n",
    "    osci_eng = osci_eng1 + osci_eng2\n",
    "    # print(max(dF_vdw_i), min(dF_vdw_i))\n",
    "    # F_vdw_i = H*R/(6*(d_t_array_i**2))\n",
    "    \n",
    "    # print(d0_i, osci_eng)\n",
    "    k_eff = 1*osci_eng/(amp_i**2)\n",
    "    # k_eff2 = (np.sum(dF_vdw1_i) + np.sum(dF_vdw2_i))/200\n",
    "    print(k_eff, osci_eng1, osci_eng2, amp_i)#,dF_vdw1_i, dF_vdw2_i)\n",
    "    delta_f = fc*(1-np.sqrt(1+(k_eff/kc))) #theoretical freq shift assuming linear harmonic osci\n",
    "    freqshift_array.append(delta_f)\n",
    "    # print(d0_i, amp_i, d0_i-amp_i, osci_eng, k_eff, delta_f)\n",
    "\n",
    "\n",
    "sns.relplot(data=simu_spectro_df_filt, x='d', y='frequency', hue=label_name, #col='sweep direction', col_order=['Backward'],\n",
    "            kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': None, 'ylim': None})\n",
    "plt.plot(d0_plotarray2, freqshift_array, ':')\n",
    "plt.xlim(11e-9, 15e-9)\n",
    "plt.ylim(-400, 10)\n",
    "sns.relplot(data=simu_spectro_df_filt, x='d', y='d lower turn', hue=label_name, #col='sweep direction', col_order=['Backward'],\n",
    "            kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': None, 'ylim': None})\n",
    "# plt.xlim(11e-9, 15e-9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513217b2-374e-401a-96dd-fef0977b0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_datadf_filt = simu_noncontact_spectro_df_filt #spectro_datadf[spectro_datadf['direction']=='retract']\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "ax.plot(spectro_datadf_filt['d'], spectro_datadf_filt['amplitude'], '.-', color=colors[0])\n",
    "ax.plot(spectro_datadf_filt['d'], spectro_datadf_filt['d lower turn'], '-', color=colors[1])\n",
    "# ax.plot(spectro_datadf_filt['d'], spectro_datadf_filt['Capillary condensation distance'], '--', color='gray')\n",
    "ax.axhline(spectro_datadf_filt['Capillary condensation distance'].iloc[0], linestyle='--', color='gray')\n",
    "ax.set_xlabel('Distance (nm)')\n",
    "ax.set_ylabel('Amplitude (nm)')\n",
    "ax.set_xlim(3.5, 20)\n",
    "ax.set_ylim(-1, 15)\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(spectro_datadf_filt['d'], spectro_datadf_filt['frequency'], '.-', color=colors[2])\n",
    "ax2.set_ylabel('Frequency shift (Hz)')\n",
    "ax2.set_ylim(-100, 2050)\n",
    "ax.spines['left'].set_color(colors[0])\n",
    "ax.yaxis.label.set_color(colors[0])\n",
    "ax.tick_params(axis='y', colors=colors[0])\n",
    "ax2.spines['left'].set_color(colors[0])\n",
    "ax2.yaxis.label.set_color(colors[2])\n",
    "ax2.spines['right'].set_color(colors[2])\n",
    "ax2.tick_params(axis='y', colors=colors[2])\n",
    "fig.savefig(f'data/noncontact_ampvsdistance_withfreq_humid{humid_select:.2f}_contactang{contang_select[0]}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# g = sns.lineplot(data=simu_noncontact_setpointdf_filt, x='Amplitude setpoint', y='frequency', hue=label_name, #col='sweep direction',\n",
    "#                  legend='auto', palette=[colors[0], colors[1]], marker='.', markeredgewidth=0)#, facet_kws={'xlim': None, 'ylim': plot_freqrange}) #style=label_name2)\n",
    "# g.set_ylabel('Frequency shift (Hz)')\n",
    "# g.figure.savefig(f'data/noncontact_setpointplot_humid{humid_select:.2f}.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d985d9a-be4b-42ce-8f54-aa83934e832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'Sample contact angle' #colour variable\n",
    "\n",
    "#redimension for plotting\n",
    "simu_spectro_df_filt = simu_spectro_df_all.copy(deep=True)\n",
    "simu_setpointdf_filt = simu_noncontact_setpointdf_all.copy(deep=True)\n",
    "for simu_df_i in [simu_spectro_df_filt, simu_setpointdf_filt]:\n",
    "    simu_df_i['d'] = simu_df_i['d']/1e-9\n",
    "    simu_df_i['amplitude'] = simu_df_i['amplitude']/1e-9\n",
    "    simu_df_i['amp_ratio'] = simu_df_i['amp_ratio']/1e-9\n",
    "    simu_df_i['d lower turn'] = simu_df_i['d lower turn']/1e-9\n",
    "    simu_df_i['deflection'] = simu_df_i['deflection']/1e-9\n",
    "    simu_df_i['Free resonance amplitude'] = simu_df_i['Free resonance amplitude']/1e-9\n",
    "    simu_df_i['Capillary condensation distance'] = simu_df_i['Capillary condensation distance']/1e-9\n",
    "\n",
    "simu_k_list = simu_spectro_df_filt[\"Spring constant\"].unique()\n",
    "simu_contang_list = simu_spectro_df_filt[\"Sample contact angle\"].unique()\n",
    "simu_freeamp_list = simu_spectro_df_filt[\"Free resonance amplitude\"].unique()\n",
    "simu_humid_list = simu_spectro_df_filt[\"Humidity\"].unique()\n",
    "\n",
    "print('Spring constant', simu_k_list, '\\n',\n",
    "      'Contact angle', simu_contang_list, '\\n',\n",
    "      'Free amplitude', simu_freeamp_list, '\\n',      \n",
    "      'Humidity', simu_humid_list)\n",
    "\n",
    "k_select = simu_k_list[0]\n",
    "contang_select = [30]\n",
    "free_amp_select = simu_freeamp_list[0]\n",
    "humid_select = simu_humid_list[3]\n",
    "\n",
    "print('Spring constant', k_select, '\\n',\n",
    "      'Contact angle', contang_select, '\\n',\n",
    "      'Free amplitude', free_amp_select, '\\n',      \n",
    "      'Humidity', humid_select)\n",
    "\n",
    "d_lims = (6, 15)\n",
    "amp_lims = (-0.01, free_amp_select*1.1)\n",
    "phase_lims = (89, 150)\n",
    "freq_lims = (-50, 600)\n",
    "# simu_spectro_df_filt = simu_spectro_df_all[simu_spectro_df_all['sweep direction']=='Backward']\n",
    "\n",
    "query_string1 = ''.join([\n",
    "    f\"`Mode` == 'noncontact' and \",\n",
    "    f\"`Spring constant` == {k_select} and \",\n",
    "    f\"`Sample contact angle` in {contang_select} and \",\n",
    "    f\"`Free resonance amplitude` == {free_amp_select} and \",\n",
    "    f\"`Humidity` == {humid_select} and \",\n",
    "    f\"`stability` == 'stable' and \",\n",
    "    f\"`sweep direction` == 'Backward'\"\n",
    "])\n",
    "\n",
    "query_string2 = ''.join([\n",
    "    f\"`Mode` == 'tapping' and \",\n",
    "    f\"`frequency` == 70000 and \", #ADJUST THIS!\n",
    "    f\"`Spring constant` == {k_select} and \",\n",
    "    f\"`Sample contact angle` in {contang_select} and \",\n",
    "    f\"`Free resonance amplitude` == {free_amp_select} and \",\n",
    "    f\"`Humidity` == {humid_select} and \",\n",
    "    f\"`stability` == 'stable' and \",\n",
    "    f\"`direction` == 'approach'\"\n",
    "])\n",
    "\n",
    "simu_noncontact_spectro_df_filt = simu_spectro_df_filt.query(query_string1)\n",
    "simu_noncontact_setpointdf_filt = simu_setpointdf_filt.query(query_string1)\n",
    "\n",
    "simu_tapping_spectro_df_filt = simu_spectro_df_filt.query(query_string2)\n",
    "simu_tapping_setpointdf_filt = simu_setpointdf_filt.query(query_string2)\n",
    "\n",
    "\n",
    "simu_noncontact_spectro_df_filt['frequency'] = simu_noncontact_spectro_df_filt['frequency']*(-1)\n",
    "simu_noncontact_setpointdf_filt['frequency'] = simu_noncontact_setpointdf_filt['frequency']*(-1)\n",
    "simu_noncontact_spectro_df_filt[label_name] = simu_noncontact_spectro_df_filt[label_name].round(2).astype('category') #makes colors more uniform\n",
    "simu_tapping_spectro_df_filt[label_name] = simu_tapping_spectro_df_filt[label_name].round(2).astype('category') #makes colors more uniform\n",
    "simu_noncontact_setpointdf_filt[label_name] = simu_noncontact_setpointdf_filt[label_name].round(2).astype('category') #makes colors more uniform\n",
    "simu_tapping_setpointdf_filt[label_name] = simu_tapping_setpointdf_filt[label_name].round(2).astype('category') #makes colors more uniform\n",
    "\n",
    "fig1, ax1 = plt.subplots(2, 2, figsize=(10,8))\n",
    "# fig2, ax2 = plt.subplots(2, 1, figsize=(5,10))\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "color_palette = 'Greens'\n",
    "g1 = sns.lineplot(data=simu_noncontact_spectro_df_filt, x='d', y='frequency', hue=label_name,\n",
    "                 legend=None, marker='.', markeredgewidth=0, palette=color_palette, ax=ax1[0][0]) #facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "# g1.set(xscale='log', yscale='log')\n",
    "ax1[0][0].grid(True, color='gray')\n",
    "\n",
    "g1_tw = ax1[0][0].twinx()\n",
    "color_palette = 'Reds'\n",
    "sns.lineplot(data=simu_noncontact_spectro_df_filt, x='d', y='amplitude', hue=label_name,\n",
    "             legend=False, marker='.', markeredgewidth=0, palette=color_palette, ax=g1_tw) #facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "color_palette = 'Blues'\n",
    "sns.lineplot(data=simu_noncontact_spectro_df_filt, x='d', y='d lower turn', hue=label_name, \n",
    "             legend=None, sort=False, estimator=None, linestyle='--', palette=color_palette, ax=g1_tw)\n",
    "sns.lineplot(data=simu_noncontact_spectro_df_filt, x='d', y='Capillary condensation distance', hue=label_name, \n",
    "             legend=None, sort=False, estimator=None, linestyle=':', palette=color_palette, ax=g1_tw)\n",
    "ax1[0][0].set_xlim(*d_lims)\n",
    "ax1[0][0].set_ylim(*freq_lims)\n",
    "g1_tw.set_ylim(*amp_lims)\n",
    "\n",
    "color_palette = 'Greens'\n",
    "g2 = sns.lineplot(data=simu_tapping_spectro_df_filt, x='d', y='phase', hue=label_name,\n",
    "                 legend=False, marker='.', markeredgewidth=0, palette=color_palette, ax=ax1[1][0]) #facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "# g1.set(xscale='log', yscale='log')\n",
    "# plt.grid(True)\n",
    "ax1[1][0].grid(True, color='gray')\n",
    "\n",
    "g2_tw = ax1[1][0].twinx()\n",
    "color_palette = 'Reds'\n",
    "sns.lineplot(data=simu_tapping_spectro_df_filt, x='d', y='amplitude', hue=label_name,\n",
    "             legend=False, marker='.', markeredgewidth=0, palette=color_palette, ax=g2_tw) #facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "color_palette = 'Blues'\n",
    "sns.lineplot(data=simu_tapping_spectro_df_filt, x='d', y='d lower turn', hue=label_name, \n",
    "             legend=None, sort=False, estimator=None, linestyle='--', palette=color_palette, ax=g2_tw)\n",
    "sns.lineplot(data=simu_tapping_spectro_df_filt, x='d', y='Capillary condensation distance', hue=label_name, \n",
    "             legend=None, sort=False, estimator=None, linestyle=':', palette=color_palette, ax=g2_tw)\n",
    "# g1.set_ylim(-50, 1000)\n",
    "ax1[1][0].set_xlim(*d_lims)\n",
    "ax1[1][0].set_ylim(*phase_lims)\n",
    "g2_tw.set_ylim(*amp_lims)\n",
    "\n",
    "# sns.move_legend(g1, \"upper center\", bbox_to_anchor=(1, -1.3), ncol=3)\n",
    "# plt.show()\n",
    "\n",
    "color_palette = 'Reds' #'flare'\n",
    "sns.lineplot(data=simu_noncontact_setpointdf_filt, x='Amplitude setpoint', y='frequency', hue=label_name, #col='sweep direction',\n",
    "                 legend='auto', palette=color_palette, marker='.', markeredgewidth=0, ax=ax1[0][1])#, facet_kws={'xlim': None, 'ylim': plot_freqrange}) #style=label_name2)\n",
    "sns.lineplot(data=simu_tapping_setpointdf_filt, x='Amplitude setpoint', y='phase', hue=label_name, #col='direction',\n",
    "                 legend=False, palette=color_palette, marker='.', markeredgewidth=0, ax=ax1[1][1])#, facet_kws={'xlim': None, 'ylim': plot_freqrange}) #style=label_name2)\n",
    "ax1[0][1].set_ylim(*freq_lims)\n",
    "ax1[1][1].set_ylim(*phase_lims)\n",
    "ax1[0][1].grid(True, color='gray')\n",
    "ax1[1][1].grid(True, color='gray')\n",
    "fig1.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#save plot\n",
    "# timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "# plot_name = f'summaryplot_k_{k_select}_humid_{humid_select}_freeamp_{humid_select}_{timestamp}.png'\n",
    "# plot_save_path = simudata_folderpath / Path('analysis') / plot_name\n",
    "# fig1.savefig(plot_save_path, bbox_inches='tight')\n",
    "# print('saved plot')\n",
    "\n",
    "\n",
    "# color_palette = 'Blues'\n",
    "# g2 = sns.lineplot(data=simu_spectro_df_filt, x='d', y='deflection', hue=label_name,\n",
    "#                  legend='auto', marker='.', markeredgewidth=0, palette=color_palette) #facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "# g2_tw = g2.twinx()\n",
    "# color_palette = 'YlOrBr'\n",
    "# sns.lineplot(data=simu_spectro_df_filt, x='d', y='d lower turn', hue=label_name,\n",
    "#              legend='auto', marker='.', markeredgewidth=0, palette=color_palette, ax=g2_tw) #facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "# plt.show()\n",
    "#'flare'\n",
    "# simu_noncontact_setpointdf_filt = simu_noncontact_setpointdf_all[simu_noncontact_setpointdf_all['sweep direction']=='Backward']\n",
    "# simu_noncontact_setpointdf_filt['frequency'] = simu_noncontact_setpointdf_filt['frequency']*(-1)\n",
    "# with sns.color_palette(\"blend:#3B82F6,#FF4C4C\"):\n",
    "#     g3 = sns.lineplot(data=simu_noncontact_setpointdf_filt, x='Amplitude setpoint', y='frequency', hue=label_name,\n",
    "#                       legend='auto', marker='.', markeredgewidth=0)\n",
    "#, palette=color_palette)\n",
    "# plt.show()\n",
    "# g1.figure.savefig(f'simu_freqampspectro_plot2.svg',bbox_inches='tight')\n",
    "# g2.figure.savefig(f'simu_defldlowspectro_plot.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69cf6f-2fc3-4e08-ab54-ec6af10a4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqresp_fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37dd69-a2cb-48b8-8875-2ce2dfec7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalculate non constact spectro from freq response\n",
    "simudata_inipath = Path(r'/home/pranav/Work/Data/Murcia/Cantilever simulation/')#Analysis/20240811 parametric study/non-contact mode/'\n",
    "header_lines = 37\n",
    "\n",
    "freqresp_data_files = list(filedialog.askopenfilenames(title='Choose spectroscopy file', \n",
    "                                                       initialdir=simudata_inipath, filetypes=(('data', '*.csv'),)))\n",
    "simudata_folderpath = Path(freqresp_data_files[0]).parent\n",
    "\n",
    "for freqresp_data_files_i in freqresp_data_files:\n",
    "    freqresp_data_path = Path(freqresp_data_files_i)\n",
    "    freqresp_fulldf = pd.read_csv(freqresp_data_path, header=header_lines)\n",
    "    d0_list_simu = freqresp_fulldf['d'].unique()\n",
    "    header_info_i = {}\n",
    "    header_dict_i = {}\n",
    "    with freqresp_data_path.open(mode=\"r\") as f_j:\n",
    "        for j in range(header_lines): #header lines\n",
    "            line_j = next(f_j).strip().split(':')\n",
    "            key_j = line_j[0].split('[')[0].strip()\n",
    "            val_j = line_j[1].strip()\n",
    "            header_info_i[line_j[0]] = line_j[1]\n",
    "            try:\n",
    "                header_dict_i[key_j] = float(val_j)\n",
    "            except:\n",
    "                header_dict_i[key_j] = val_j\n",
    "    \n",
    "    header_strings_i = [f\"{key}: {value}\" for key, value in header_info_i.items()]\n",
    "    header_df_i = pd.DataFrame(header_strings_i, columns=['Header'])\n",
    "\n",
    "    fc = header_dict_i['Resonance frequency']\n",
    "    a0 = header_dict_i['Intermolecular distance']\n",
    "    d_jumpin_ini = header_dict_i['Capillary condensation distance']\n",
    "    \n",
    "    freqresp_spectro = {'d': [], 'amplitude': [], 'frequency': [], 'deflection': [], \n",
    "                        'd lower turn':[], 'sweep direction': [], 'rupture distance': [],\n",
    "                       'jumpin distance': [], 'bridge volume': [], 'stability': []}\n",
    "    for d0_i in d0_list_simu:\n",
    "        temp1 = freqresp_fulldf[freqresp_fulldf['d']== d0_i]\n",
    "        for sweep_i in temp1['sweep direction'].unique():\n",
    "            temp2 = temp1[temp1['sweep direction']== sweep_i]\n",
    "            temp2['phasecross'] = np.sign((temp2['phase']-90)*(temp2['phase']-90).shift(-1))\n",
    "            cross_ind = temp2['phasecross'].loc[lambda x: x==-1].index\n",
    "            # print(cross_ind)\n",
    "            if len(cross_ind) > 0:\n",
    "                cross_ind1 = cross_ind[0]\n",
    "                if abs(temp2['phase'].loc[cross_ind1] - temp2['phase'].loc[cross_ind1+1]) > 1:\n",
    "                    stable_i = 'unstable'\n",
    "                else:\n",
    "                    stable_i = 'stable'\n",
    "                freq_i = np.mean([temp2['frequency'].loc[cross_ind1], temp2['frequency'].loc[cross_ind1+1]])\n",
    "                amp_i = np.mean([temp2['amplitude'].loc[cross_ind1], temp2['amplitude'].loc[cross_ind1+1]])\n",
    "                defl_i = np.mean([temp2['deflection'].loc[cross_ind1], temp2['deflection'].loc[cross_ind1+1]])\n",
    "                dlowturn_i = np.mean([temp2['d lower turn'].loc[cross_ind1], temp2['d lower turn'].loc[cross_ind1+1]])\n",
    "                d_rupt_i = np.mean([temp2['rupture distance'].loc[cross_ind1], temp2['rupture distance'].loc[cross_ind1+1]])\n",
    "                d_jumpin_i = np.mean([temp2['jumpin distance'].loc[cross_ind1], temp2['jumpin distance'].loc[cross_ind1+1]])\n",
    "                vol_bridge_i = np.mean([temp2['bridge volume'].loc[cross_ind1], temp2['bridge volume'].loc[cross_ind1+1]])\n",
    "            else:\n",
    "                stable_i = 'unstable'\n",
    "                freq_i = fc #temp2['frequency'].iloc[-1]\n",
    "                amp_i = 0 #temp2['amplitude'].iloc[-1]\n",
    "                defl_i = 0 #temp2['deflection'].iloc[-1]\n",
    "                dlowturn_i = 0\n",
    "                d_rupt_i = 0\n",
    "                d_jumpin_i = 0\n",
    "                vol_bridge_i = 0\n",
    "            freqresp_spectro['d'].append(d0_i)\n",
    "            freqresp_spectro['amplitude'].append(amp_i)\n",
    "            freqresp_spectro['frequency'].append(freq_i-fc)\n",
    "            freqresp_spectro['deflection'].append(defl_i)\n",
    "            freqresp_spectro['d lower turn'].append(dlowturn_i)\n",
    "            freqresp_spectro['sweep direction'].append(sweep_i)\n",
    "            freqresp_spectro['rupture distance'].append(d_rupt_i)\n",
    "            freqresp_spectro['jumpin distance'].append(d_jumpin_i)\n",
    "            freqresp_spectro['bridge volume'].append(vol_bridge_i)\n",
    "            freqresp_spectro['stability'].append(stable_i)\n",
    "    freqresp_spectro_df = pd.DataFrame(freqresp_spectro)\n",
    "    \n",
    "    freqresp_spectro_df_stable = freqresp_spectro_df[freqresp_spectro_df['stability'] == 'stable']\n",
    "    fig4, ax4 = plt.subplots(2, 2, figsize=(12,10))\n",
    "    sns.lineplot(data=freqresp_spectro_df_stable, x='d', y='amplitude', hue='sweep direction', \n",
    "                 legend='auto', ax=ax4[0][0], marker='.', markeredgewidth=0)\n",
    "    sns.lineplot(data=freqresp_spectro_df_stable, x='d', y='frequency', hue='sweep direction',\n",
    "                 legend=False, ax=ax4[0][1], marker='.', markeredgewidth=0)\n",
    "    sns.lineplot(data=freqresp_spectro_df_stable, x='d', y='deflection', hue='sweep direction',\n",
    "                 legend=False, ax=ax4[1][0], marker='.', markeredgewidth=0)\n",
    "    sns.lineplot(data=freqresp_spectro_df_stable, x='d', y='d lower turn', hue='sweep direction',\n",
    "                 legend=False, ax=ax4[1][1], marker='.', markeredgewidth=0)\n",
    "    ax4_00_ylim = ax4[0][0].get_ylim()\n",
    "    ax4[0][0].plot(d0_list_simu, d0_list_simu, linestyle='--', color='gray')\n",
    "    ax4[0][0].set_ylim(*ax4_00_ylim)\n",
    "    ax4_10_ylim = ax4[1][0].get_ylim()\n",
    "    ax4[1][0].plot(d0_list_simu, -d0_list_simu, linestyle='--', color='gray')\n",
    "    ax4[1][0].set_ylim(*ax4_10_ylim)\n",
    "    ax4[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "    ax4[1][1].axhline(d_jumpin_ini, linestyle='--', color='gray')\n",
    "    # plt.show()\n",
    "    \n",
    "    # g1 = sns.relplot(data=freqresp_fulldf, x='frequency', y='amplitude', col='sweep direction', hue='d', palette='flare', \n",
    "    #              kind='line', sort=False, estimator=None, legend=False)#, marker='.', markeredgewidth=0)\n",
    "    # for ax_i in g1.axes.flatten():\n",
    "    #     ax_i.axvline(fc, linestyle='--', color='gray')\n",
    "    # g2 = sns.relplot(data=freqresp_fulldf, x='frequency', y='phase', col='sweep direction', hue='d',palette='flare', \n",
    "    #                 kind='line', sort=False, estimator=None, legend=False, marker='.', markeredgewidth=0)#, ax=ax3[1])#, \n",
    "    # for ax_i in g2.axes.flatten():\n",
    "    #     ax_i.axhline(90, linestyle='--', color='gray')\n",
    "    # g3 = sns.relplot(data=freqresp_fulldf, x='frequency', y='deflection', col='sweep direction', hue='d',palette='flare', \n",
    "    #                  kind='line', sort=False, estimator=None, legend=False)#, ax=ax3[2])#, marker='.', markeredgewidth=0)\n",
    "    # g4 = sns.relplot(data=freqresp_fulldf, x='frequency', y='d lower turn', col='sweep direction', hue='d',palette='flare', \n",
    "    #                  kind='line', sort=False, estimator=None, legend=False)#, ax=ax3[3])#, marker='.', markeredgewidth=0)\n",
    "    # for ax_i in g4.axes.flatten():\n",
    "    #     ax_i.axhline(a0, linestyle='--', color='gray')\n",
    "    #     ax_i.axhline(d_jumpin_ini, linestyle='--', color='gray')\n",
    "    # # ax3[0][1].axhline(90, linestyle='--', color='k')\n",
    "    # # ax3[1][1].axhline(a0, linestyle='--', color='k')\n",
    "    # # handles, labels = ax3[0].get_legend_handles_labels()\n",
    "    # # new_labels = [f\"{float(label):.2e}\" for label in labels]\n",
    "    # # ax3[0].legend(handles, new_labels, title = 'd')\n",
    "    # # sns.move_legend(ax3[0], \"upper left\", bbox_to_anchor=(2.3, 1))\n",
    "    # plt.show()\n",
    "    # print(header_dict_i)\n",
    "\n",
    "# if save == True:\n",
    "    # timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    # file_suffix = f'thetas_{theta_s}_humidity_{humid:.2f}_ampres_{amp_res:1.1e}_kc_{kc:.0f}_fd_{fd_ini:.0f}_fdpts_{fd_pts}_{timestamp}'\n",
    "    datafile_name = freqresp_data_path.name.replace('freqresp_fulldfdata','stable_noncontact_spectrodata')\n",
    "    plotfile_name = freqresp_data_path.name.replace('freqresp_fulldfdata','stable_noncontact_spectroplot').replace('.csv', '.png')\n",
    "    data_save_path = simudata_folderpath / Path('analysis/noncontact_stable')\n",
    "    header_df_i.to_csv(data_save_path / datafile_name, index=False, header=False)\n",
    "    freqresp_spectro_df.to_csv(data_save_path / datafile_name, index=False, mode='a')\n",
    "    fig4.savefig(data_save_path / plotfile_name, dpi=300, bbox_inches='tight')\n",
    "    print('saved', datafile_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8d37e-f917-4ca4-ac01-1a72a7dea523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fe850-aa02-4cf3-9e3e-140a8ff3f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_drange = None#(10e-9, 12e-9)\n",
    "plot_freqrange = None#(-400, 5)\n",
    "plot_amprange = None#(8.2e-9, 10.2e-9)\n",
    "plot_dlowturnrange = None#(0.5e-9, 2e-9)\n",
    "color_palette = 'flare'\n",
    "g1 = sns.relplot(data=simu_noncontact_setpointdf_all, x='Amplitude setpoint', y='frequency', hue=label_name, col='sweep direction',\n",
    "                 kind='line', legend='full', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': plot_freqrange}) #style=label_name2)\n",
    "g8 = sns.relplot(data=simu_noncontact_setpointdf_all, x=label_name, y='frequency', hue='Amplitude setpoint', col='sweep direction',\n",
    "                 kind='line', legend='full', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': plot_freqrange}) #style=label_name2)\n",
    "g10 = sns.relplot(data=simu_noncontact_setpointdf_all, x='Amplitude setpoint', y='amp_in_liq_ratio', hue=label_name, col='sweep direction', #style=label_name2,\n",
    "                 kind='line', legend='auto', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': None})\n",
    "g11 = sns.relplot(data=simu_noncontact_setpointdf_all, x='energy_dissipated', y='amp_in_liq', hue=label_name, col='sweep direction', #style=label_name2,\n",
    "                 kind='line', legend='auto', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': None, 'ylim': None})\n",
    "g9 = sns.relplot(data=simu_spectro_df_all, x='d', y='amp_in_liq', hue=label_name, col='sweep direction', #style=label_name2,\n",
    "                 kind='line', legend='auto', palette=color_palette, marker='.', markeredgewidth=0, facet_kws={'xlim': plot_drange, 'ylim': None})\n",
    "g2 = sns.relplot(data=simu_spectro_df_all, x='d', y='amplitude', hue=label_name, col='sweep direction', \n",
    "                 kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': plot_drange, 'ylim': plot_amprange})\n",
    "g3 = sns.relplot(data=simu_spectro_df_all, x='d', y='frequency', hue=label_name, col='sweep direction',\n",
    "                 kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': plot_drange, 'ylim': plot_freqrange})\n",
    "g4 = sns.relplot(data=simu_spectro_df_all, x='d', y='d lower turn', hue=label_name, col='sweep direction',\n",
    "                 kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': plot_drange, 'ylim': plot_dlowturnrange})\n",
    "sns.lineplot(data=simu_spectro_df_all, x='d', y='Capillary condensation distance', hue=label_name, \n",
    "             legend=None, linestyle=':', palette=color_palette)\n",
    "g5 = sns.relplot(data=simu_spectro_df_all, x='d', y='deflection', hue=label_name, col='sweep direction', \n",
    "                 kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': plot_drange}, )\n",
    "g6 = sns.relplot(data=simu_spectro_df_all, x='d', y='energy_dissipated', hue=label_name, col='sweep direction', \n",
    "                 kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': plot_drange}, )\n",
    "g7 = sns.relplot(data=simu_spectro_df_all, x='d lower turn', y='energy_dissipated', hue=label_name, col='sweep direction', \n",
    "                 kind='line', legend='auto', marker='.', markeredgewidth=0, palette=color_palette, facet_kws={'xlim': plot_dlowturnrange, 'ylim': None})\n",
    "\n",
    "\n",
    "#add grid\n",
    "# for g_i in [g1, g2, g3, g4, g5, g6]:\n",
    "#     for ax_i in g_i.axes.flatten():\n",
    "#         ax_i.grid() \n",
    "\n",
    "plt.show()\n",
    "\n",
    "#save plots\n",
    "# timestamp = datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "# file_suffix = 'novdw_' if ((plot_drange==None) and (plot_freqrange==None) and (plot_amprange==None)) else 'filt_novdw_'\n",
    "# g1.figure.savefig(f'{simudata_folderpath}/setpoint_amp_frequency_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g8.figure.savefig(f'{simudata_folderpath}/freqvsangle_legend_ampsetpoint_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g10.figure.savefig(f'{simudata_folderpath}/setpoint_amp_ampinliqratio_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g11.figure.savefig(f'{simudata_folderpath}/ampinliqvseng_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g9.figure.savefig(f'{simudata_folderpath}/ampinliq_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g2.figure.savefig(f'{simudata_folderpath}/amplitude_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g3.figure.savefig(f'{simudata_folderpath}/frequency_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g4.figure.savefig(f'{simudata_folderpath}/dlowturn_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g5.figure.savefig(f'{simudata_folderpath}/deflection_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g6.figure.savefig(f'{simudata_folderpath}/energydiss_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "# g7.figure.savefig(f'{simudata_folderpath}/engvsdlow_spectroplot_legend_{label_name}_{file_suffix}{timestamp}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733766f2-e60a-47f7-ac79-d9a0eb5e1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency response simulation data analysis\n",
    "simudata_folderpath = '/home/pranav/Work/Data/Murcia/Cantilever simulation/'\n",
    "label_name = 'Sample contact angle' #choose from header names in simulation data\n",
    "freqresp_files = list(filedialog.askopenfilenames(title='Choose frequency response files', \n",
    "                                                  initialdir=simudata_folderpath, filetypes=(('data', '*.csv'),)))\n",
    "freqrespdf_list = []\n",
    "# simu_noncontact_setpointdf_list = []\n",
    "# amplitude_setpoint_list = np.linspace(0.99, 0.7, 10)\n",
    "for freqresp_file_i in freqresp_files:\n",
    "    freqresp_df_i = pd.read_csv(f'{freqresp_file_i}', header=36)\n",
    "    header_dict_i = {}\n",
    "    with open(f'{freqresp_file_i}', \"r\") as f_j:\n",
    "        for j in range(36):\n",
    "            line_j = next(f_j).strip().split(':')\n",
    "            key_j = line_j[0].split('[')[0].strip()\n",
    "            val_j = line_j[1].strip()\n",
    "            try:\n",
    "                header_dict_i[key_j] = float(val_j)\n",
    "            except:\n",
    "                header_dict_i[key_j] = val_j\n",
    "    # simu_spectro_df_i[label_name] = round(header_dict_i[label_name], 10)#','.join(simu_spectro_file_i.split('_')[3:7])\n",
    "    freqresp_df_i[label_name] = header_dict_i[label_name]\n",
    "    \n",
    "    # print(header_dict_i[label_name])\n",
    "    # simu_spectro_df_i['amp_ratio'] = simu_spectro_df_i['amplitude']/simu_spectro_df_i['amplitude'].loc[0]\n",
    "    # print(simu_spectro_df_i['amplitude'].loc[0])\n",
    "    freqrespdf_list.append(freqresp_df_i)\n",
    "    # for sweep_dir_i in freqresp_df_i['sweep direction'].unique():\n",
    "    #     simu_spectro_df_filt_i = simu_spectro_df_i[simu_spectro_df_i['sweep direction']==sweep_dir_i]\n",
    "        # for amp_setpoint_i in amplitude_setpoint_list:\n",
    "        #     simu_noncontact_setpointdf_i = simu_spectro_df_filt_i.iloc[(simu_spectro_df_filt_i['amp_ratio']-\\\n",
    "        #                                                                 amp_setpoint_i).abs().argsort()[:1]]\n",
    "        #     simu_noncontact_setpointdf_i['Amplitude setpoint'] = amp_setpoint_i\n",
    "        #     simu_noncontact_setpointdf_list.append(simu_noncontact_setpointdf_i)\n",
    "\n",
    "freqresp_df_all = pd.concat(freqrespdf_list)\n",
    "freqresp_df_all[label_name] = freqresp_df_all[label_name].astype('category') #makes colors more uniform\n",
    "# simu_noncontact_setpointdf_all = pd.concat(simu_noncontact_setpointdf_list)\n",
    "# simu_noncontact_setpointdf_all[label_name] = simu_noncontact_setpointdf_all[label_name].astype('category') #makes colors more uniform\n",
    "print('Frequency response: loaded files. Label:', label_name)\n",
    "\n",
    "# color_palette = 'rocket_r'\n",
    "# g1 = sns.relplot(data=simu_noncontact_setpointdf_all, x='Amplitude setpoint', y='frequency', hue=label_name, col='sweep direction',\n",
    "#                  kind='line', legend='full', marker='.', markeredgewidth=0, palette=color_palette)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63821e46-1eb1-4c99-bac1-3732a045522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = 'rocket_r'\n",
    "# freqresp_df_all['amplitude'] = freqresp_df_all['amplitude']*1e-9\n",
    "g1 = sns.relplot(data=freqresp_df_all, x='frequency', y='amplitude', hue='d', col='sweep direction', aspect=1.25,\n",
    "                 kind='line', legend=None, #marker='.', markeredgewidth=0, \n",
    "                 palette=color_palette, col_order=['Backward'])\n",
    "g2 = sns.relplot(data=freqresp_df_all, x='frequency', y='phase', hue='d', col='sweep direction', aspect=1.25,\n",
    "                 kind='line', legend=None, #marker='.', markeredgewidth=0, \n",
    "                 palette=color_palette, col_order=['Backward'])\n",
    "for ax_i in g2.axes.flatten():\n",
    "    ax_i.axhline(90, linestyle='--', color='gray')\n",
    "for ax_i in g1.axes.flatten():\n",
    "    ax_i.axvline(70000, linestyle='--', color='gray')\n",
    "plt.show()\n",
    "\n",
    "g1.figure.savefig(f'simu_ampfreq_plot.svg',bbox_inches='tight')\n",
    "g2.figure.savefig(f'simu_phasefreq_plot.svg',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627138f-5f07-41e0-a3ef-635960c9e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqresp_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30433fa5-9421-4a9a-a5ce-290fe252dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0_unique = freqresp_df_all['d'].unique()\n",
    "d0_select_range = 15e-9, 6e-9 #[d0_unique[36]] d0_unique\n",
    "d0_select_ind = np.argmin(abs(d0_unique-d0_select_range[0])), np.argmin(abs(d0_unique-d0_select_range[1]))\n",
    "d0_select_matched = d0_unique[min(d0_select_ind):max(d0_select_ind):1]\n",
    "print(d0_select_matched)\n",
    "# freqresp_df_filt = freqresp_df_all[freqresp_df_all['d']==d0_select_matched]\n",
    "# freqresp_df_filt = freqresp_df_all[freqresp_df_all['d'].isin(d0_select_matched)]\n",
    "\n",
    "color_palette = 'rocket_r'\n",
    "# print(cross_ind1, amp_i, freq_i)\n",
    "# fig3, ax3 = plt.subplots(2, 2, figsize=(12,10))\n",
    "# ax3[0][0].axvline(fc, linestyle='--', color='gray')\n",
    "# ax3[0][1].axvline(fc, linestyle='--', color='gray')\n",
    "# ax3[0][1].axhline(90, linestyle='--', color='gray')\n",
    "# ax3[1][0].axhline(-d0_select, linestyle='--', color='gray')\n",
    "# ax3[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "plot_freqrange = (67e3, 71e3)\n",
    "plot_amprange = (2e-9, 11e-9)\n",
    "plot_phaserange = (0, 180)\n",
    "plot_deflrange = (-1e-10, 0)\n",
    "plot_dlowturnrange = (0e-9, 2e-9)\n",
    "plotframe_list = []\n",
    "for i, d0_i in enumerate(d0_select_matched):\n",
    "    freqresp_df_filt = freqresp_df_all[freqresp_df_all['d']==d0_i]\n",
    "    \n",
    "    # Create the plot\n",
    "    # g = sns.relplot(x=\"total_bill\", y=\"tip\", kind=\"scatter\", hue=\"sex\", data=tips[tips['sex'] == hue])\n",
    "    # g.fig.suptitle(f'Hue: {hue}')  # Set the title\n",
    "    # g.fig.savefig(f\"data/frame_{i:02d}.png\")  # Save the figure\n",
    "    # plt.close(g.fig)  # Close the figure to free memory\n",
    "    \n",
    "    g1 = sns.relplot(data=freqresp_df_filt, x='frequency', y='amplitude', col='sweep direction', hue=label_name, palette=color_palette, \n",
    "                 kind='line', sort=False, estimator=None, legend='full', \n",
    "                     facet_kws={'xlim': plot_freqrange, 'ylim': plot_amprange})#, ax=ax3[0][0])#, marker='.', markeredgewidth=0)   \n",
    "    g2 = sns.relplot(data=freqresp_df_filt, x='frequency', y='phase', col='sweep direction', hue=label_name, palette=color_palette, \n",
    "                 kind='line', sort=False, estimator=None, legend='full', marker='.', markeredgewidth=0, \n",
    "                     facet_kws={'xlim': plot_freqrange, 'ylim': plot_phaserange})# ax=ax3[0][1])#, \n",
    "    g3 = sns.relplot(data=freqresp_df_filt, x='frequency', y='deflection', col='sweep direction', hue=label_name, palette=color_palette, \n",
    "                 kind='line', sort=False, estimator=None, legend='full', \n",
    "                     facet_kws={'xlim': plot_freqrange, 'ylim': plot_deflrange})#, ax=ax3[1][0])#, marker='.', markeredgewidth=0)\n",
    "    g4 = sns.relplot(data=freqresp_df_filt, x='frequency', y='d lower turn', col='sweep direction', hue=label_name, palette=color_palette, \n",
    "                 kind='line', sort=False, estimator=None, legend='full', \n",
    "                     facet_kws={'xlim': plot_freqrange, 'ylim': plot_dlowturnrange})#, ax=ax3[1][1])#, marker='.', markeredgewidth=0)\n",
    "    for ax_i in g2.axes.flatten():\n",
    "        ax_i.axhline(90, linestyle='--', color='gray')\n",
    "    for ax_i in g1.axes.flatten():\n",
    "        ax_i.axvline(70000, linestyle='--', color='gray')\n",
    "    g1.figure.suptitle(f'd = {d0_i:1.2e}')  # Set the title\n",
    "    combined_image_i = merge_figures_vertically([g1.figure, g2.figure, g4.figure, g3.figure])\n",
    "    plotframe_list.append(combined_image_i)\n",
    "\n",
    "# phasecross_ind_list = []\n",
    "# for d0_i in d0_select:\n",
    "#     temp1 = freqresp_df_filt[freqresp_df_filt['d']== d0_i]\n",
    "#     for sweep_i in temp1['sweep direction'].unique():\n",
    "#         temp2 = temp1[temp1['sweep direction']== sweep_i]\n",
    "#         temp2['phasecross'] = np.sign((temp2['phase']-90)*(temp2['phase']-90).shift(-1))\n",
    "#         cross_ind = temp2['phasecross'].loc[lambda x: x==-1].index\n",
    "#         # print(cross_ind)\n",
    "#         if len(cross_ind) > 0:\n",
    "#             cross_ind1 = cross_ind[0]\n",
    "#             phasecross_ind_list.append([d0_i, sweep_i, cross_ind])\n",
    "#             freq_i = np.mean([temp2['frequency'].loc[cross_ind1], temp2['frequency'].loc[cross_ind1+1]])\n",
    "#             amp_i = np.mean([temp2['amplitude'].loc[cross_ind1], temp2['amplitude'].loc[cross_ind1+1]])\n",
    "#             defl_i = np.mean([temp2['deflection'].loc[cross_ind1], temp2['deflection'].loc[cross_ind1+1]])\n",
    "#             dlowturn_i = np.mean([temp2['d lower turn'].loc[cross_ind1], temp2['d lower turn'].loc[cross_ind1+1]])            \n",
    "#         else:\n",
    "#             freq_i = fc #temp2['frequency'].iloc[-1]\n",
    "#             amp_i = 0 #temp2['amplitude'].iloc[-1]\n",
    "#             defl_i = 0 #temp2['deflection'].iloc[-1]\n",
    "#             dlowturn_i = 0\n",
    "\n",
    "# phase_cross_df = pd.DataFrame(phasecross_ind_list, columns=['d', 'sweep direction', 'cross index'])\n",
    "# for d0_i in d0_select:\n",
    "#     ind_forw = phase_cross_df[(phase_cross_df['d'] == d0_i) & (phase_cross_df['sweep direction'] == 'Forward')].iloc[0]['cross index']\n",
    "#     ind_back = phase_cross_df[(phase_cross_df['d'] == d0_i) & (phase_cross_df['sweep direction'] == 'Backward')].iloc[0]['cross index']\n",
    "#     # print(g1.axes)\n",
    "#     g1.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw], freqresp_df_filt['amplitude'].loc[ind_forw], 'x', color='red')\n",
    "#     g1.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw+1], freqresp_df_filt['amplitude'].loc[ind_forw+1], 'x', color='red')\n",
    "#     g1.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back], freqresp_df_filt['amplitude'].loc[ind_back], 'x', color='red')\n",
    "#     g1.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back+1], freqresp_df_filt['amplitude'].loc[ind_back+1], 'x', color='red')\n",
    "#     g2.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw], freqresp_df_filt['phase'].loc[ind_forw], 'x', color='red')\n",
    "#     g2.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw+1], freqresp_df_filt['phase'].loc[ind_forw+1], 'x', color='red')\n",
    "#     g2.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back], freqresp_df_filt['phase'].loc[ind_back], 'x', color='red')\n",
    "#     g2.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back+1], freqresp_df_filt['phase'].loc[ind_back+1], 'x', color='red')\n",
    "# handles, labels = ax3[0].get_legend_handles_labels()\n",
    "# new_labels = [f\"{float(label):.2e}\" for label in labels]\n",
    "# ax3[0].legend(handles, new_labels, title = 'd')\n",
    "# sns.move_legend(ax3[0], \"upper left\", bbox_to_anchor=(2.3, 1))\n",
    "\n",
    "# Format the labels with scientific notation\n",
    "# for g_i in [g1, g2, g3, g4]:\n",
    "#     handles, labels = g_i.legend.legend_handles, g_i.legend.get_texts()\n",
    "#     for label in labels:\n",
    "#         original_label = label.get_text()\n",
    "#         new_label = f\"{float(original_label):.2e}\"\n",
    "#         label.set_text(new_label)\n",
    "\n",
    "# plt.show()\n",
    "# Function to display the selected image\n",
    "def show_frame(frame_index):\n",
    "    image_frame = plotframe_list[frame_index]\n",
    "    display(image_frame)\n",
    "\n",
    "# Create the slider widget\n",
    "slider = widgets.IntSlider(value=0, min=0, max=len(plotframe_list) - 1, step=1, description=\"Frame\")\n",
    "\n",
    "# Use interact to update the image display based on slider value\n",
    "widgets.interact(show_frame, frame_index=slider)\n",
    "display(slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d1757-2ff6-4eb2-b0da-7a8890af1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.animation import FuncAnimation\n",
    "# # from IPython.display import HTML\n",
    "# # import numpy as np\n",
    "\n",
    "# # Load the dataset\n",
    "# tips = sns.load_dataset(\"tips\")\n",
    "\n",
    "# # Unique hue values\n",
    "# hue_values = tips['sex'].unique()\n",
    "\n",
    "# # Create a directory to save the frames\n",
    "# # os.makedirs(\"frames\", exist_ok=True)\n",
    "\n",
    "# # Generate and save each frame\n",
    "# for i, hue in enumerate(hue_values):\n",
    "#     # Create the plot\n",
    "#     g = sns.relplot(x=\"total_bill\", y=\"tip\", kind=\"scatter\", hue=\"sex\", data=tips[tips['sex'] == hue])\n",
    "#     g.fig.suptitle(f'Hue: {hue}')  # Set the title\n",
    "#     g.fig.savefig(f\"data/frame_{i:02d}.png\")  # Save the figure\n",
    "#     plt.close(g.fig)  # Close the figure to free memory\n",
    "\n",
    "# import imageio.v2 as imageio\n",
    "\n",
    "# # Get the list of saved frame images\n",
    "# frame_files = [f\"data/frame_{i:02d}.png\" for i in range(len(hue_values))]\n",
    "\n",
    "# # Read the images and create a video\n",
    "# with imageio.get_writer(\"data/animation.gif\", fps=1, loop=0) as writer:\n",
    "#     for filename in frame_files:\n",
    "#         image = imageio.imread(filename)\n",
    "#         writer.append_data(image)\n",
    "\n",
    "# # Optionally, display the video in the notebook\n",
    "# # from IPython.display import Video\n",
    "# # Video(\"data/animation.mp4\", embed=True)\n",
    "\n",
    "# # from IPython.display import Image as IPImage\n",
    "# IPImage(filename=\"data/animation.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e9962-3a97-45e3-a2f4-11adfda83ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_figures_vertically(figures):\n",
    "#     \"\"\"\n",
    "#     Merges multiple matplotlib figures into a single vertical image.\n",
    "\n",
    "#     Parameters:\n",
    "#     - figures: A list of matplotlib figure objects to merge.\n",
    "\n",
    "#     Returns:\n",
    "#     - A PIL Image object containing the vertically combined figure.\n",
    "#     \"\"\"\n",
    "#     # Capture all figures as images in memory\n",
    "#     buffers = []\n",
    "#     for fig in figures:\n",
    "#         buffer = io.BytesIO()\n",
    "#         fig.savefig(buffer, format='png', bbox_inches='tight')\n",
    "#         plt.close(fig)  # Close the figure to free memory\n",
    "#         buffer.seek(0)\n",
    "#         buffers.append(buffer)\n",
    "\n",
    "#     # Open all images from BytesIO buffers\n",
    "#     images = [PIL.Image.open(buffer) for buffer in buffers]\n",
    "\n",
    "#     # Determine the width and height of each image\n",
    "#     widths, heights = zip(*(img.size for img in images))\n",
    "\n",
    "#     # Calculate the dimensions of the new image\n",
    "#     total_width = max(widths)\n",
    "#     total_height = sum(heights)\n",
    "\n",
    "#     # Create a new blank image with the combined dimensions\n",
    "#     new_image =PIL.Image.new('RGB', (total_width, total_height))\n",
    "\n",
    "#     # Paste each image into the new image\n",
    "#     y_offset = 0\n",
    "#     for img in images:\n",
    "#         new_image.paste(img, (0, y_offset))\n",
    "#         y_offset += img.height\n",
    "\n",
    "#     return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d93ec-7e36-4daf-8bba-6a31c5b276fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency response data analysis\n",
    "\n",
    "simu_freqresp_df = pd.read_csv(f'{simu_folderpath}/{simu_freqresp_files[0]}', header=36)\n",
    "simu_spectro_df = pd.read_csv(f'{simu_folderpath}/{simu_spectro_files[0]}', header=36)\n",
    "\n",
    "d0_unique = simu_freqresp_df['d'].unique()\n",
    "d0_select = d0_unique[-25:-15] #[d0_unique[36]] d0_unique\n",
    "print(d0_select, len(d0_unique))\n",
    "d0_selectind = simu_freqresp_df['d'].isin(d0_select)\n",
    "freqresp_df_filt = simu_freqresp_df[d0_selectind]\n",
    "\n",
    "# print(cross_ind1, amp_i, freq_i)\n",
    "# fig3, ax3 = plt.subplots(2, 2, figsize=(12,10))\n",
    "# ax3[0][0].axvline(fc, linestyle='--', color='gray')\n",
    "# ax3[0][1].axvline(fc, linestyle='--', color='gray')\n",
    "# ax3[0][1].axhline(90, linestyle='--', color='gray')\n",
    "# ax3[1][0].axhline(-d0_select, linestyle='--', color='gray')\n",
    "# ax3[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "plot_freqrange = (68e3, 72e3)\n",
    "g1 = sns.relplot(data=freqresp_df_filt, x='frequency', y='amplitude', col='sweep direction', hue='d', palette='flare', \n",
    "             kind='line', sort=False, estimator=None, legend='full', facet_kws={'xlim': plot_freqrange})#, ax=ax3[0][0])#, marker='.', markeredgewidth=0)   \n",
    "g2 = sns.relplot(data=freqresp_df_filt, x='frequency', y='phase', col='sweep direction', hue='d',palette='flare', \n",
    "             kind='line', sort=False, estimator=None, legend='full', marker='.', markeredgewidth=0, facet_kws={'xlim': plot_freqrange})# ax=ax3[0][1])#, \n",
    "g3 = sns.relplot(data=freqresp_df_filt, x='frequency', y='deflection', col='sweep direction', hue='d',palette='flare', \n",
    "             kind='line', sort=False, estimator=None, legend='full', facet_kws={'xlim': plot_freqrange})#, ax=ax3[1][0])#, marker='.', markeredgewidth=0)\n",
    "g4 = sns.relplot(data=freqresp_df_filt, x='frequency', y='d lower turn', col='sweep direction', hue='d',palette='flare', \n",
    "             kind='line', sort=False, estimator=None, legend='full', facet_kws={'xlim': plot_freqrange})#, ax=ax3[1][1])#, marker='.', markeredgewidth=0)\n",
    "for ax_i in g2.axes.flatten():\n",
    "    ax_i.axhline(90, linestyle='--', color='gray')\n",
    "\n",
    "phasecross_ind_list = []\n",
    "for d0_i in d0_select:\n",
    "    temp1 = freqresp_df_filt[freqresp_df_filt['d']== d0_i]\n",
    "    for sweep_i in temp1['sweep direction'].unique():\n",
    "        temp2 = temp1[temp1['sweep direction']== sweep_i]\n",
    "        temp2['phasecross'] = np.sign((temp2['phase']-90)*(temp2['phase']-90).shift(-1))\n",
    "        cross_ind = temp2['phasecross'].loc[lambda x: x==-1].index\n",
    "        # print(cross_ind)\n",
    "        if len(cross_ind) > 0:\n",
    "            cross_ind1 = cross_ind[0]\n",
    "            phasecross_ind_list.append([d0_i, sweep_i, cross_ind])\n",
    "            freq_i = np.mean([temp2['frequency'].loc[cross_ind1], temp2['frequency'].loc[cross_ind1+1]])\n",
    "            amp_i = np.mean([temp2['amplitude'].loc[cross_ind1], temp2['amplitude'].loc[cross_ind1+1]])\n",
    "            defl_i = np.mean([temp2['deflection'].loc[cross_ind1], temp2['deflection'].loc[cross_ind1+1]])\n",
    "            dlowturn_i = np.mean([temp2['d lower turn'].loc[cross_ind1], temp2['d lower turn'].loc[cross_ind1+1]])            \n",
    "        else:\n",
    "            freq_i = fc #temp2['frequency'].iloc[-1]\n",
    "            amp_i = 0 #temp2['amplitude'].iloc[-1]\n",
    "            defl_i = 0 #temp2['deflection'].iloc[-1]\n",
    "            dlowturn_i = 0\n",
    "\n",
    "phase_cross_df = pd.DataFrame(phasecross_ind_list, columns=['d', 'sweep direction', 'cross index'])\n",
    "for d0_i in d0_select:\n",
    "    ind_forw = phase_cross_df[(phase_cross_df['d'] == d0_i) & (phase_cross_df['sweep direction'] == 'Forward')].iloc[0]['cross index']\n",
    "    ind_back = phase_cross_df[(phase_cross_df['d'] == d0_i) & (phase_cross_df['sweep direction'] == 'Backward')].iloc[0]['cross index']\n",
    "    # print(g1.axes)\n",
    "    g1.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw], freqresp_df_filt['amplitude'].loc[ind_forw], 'x', color='red')\n",
    "    g1.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw+1], freqresp_df_filt['amplitude'].loc[ind_forw+1], 'x', color='red')\n",
    "    g1.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back], freqresp_df_filt['amplitude'].loc[ind_back], 'x', color='red')\n",
    "    g1.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back+1], freqresp_df_filt['amplitude'].loc[ind_back+1], 'x', color='red')\n",
    "    g2.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw], freqresp_df_filt['phase'].loc[ind_forw], 'x', color='red')\n",
    "    g2.axes[0][0].plot(freqresp_df_filt['frequency'].loc[ind_forw+1], freqresp_df_filt['phase'].loc[ind_forw+1], 'x', color='red')\n",
    "    g2.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back], freqresp_df_filt['phase'].loc[ind_back], 'x', color='red')\n",
    "    g2.axes[0][1].plot(freqresp_df_filt['frequency'].loc[ind_back+1], freqresp_df_filt['phase'].loc[ind_back+1], 'x', color='red')\n",
    "# handles, labels = ax3[0].get_legend_handles_labels()\n",
    "# new_labels = [f\"{float(label):.2e}\" for label in labels]\n",
    "# ax3[0].legend(handles, new_labels, title = 'd')\n",
    "# sns.move_legend(ax3[0], \"upper left\", bbox_to_anchor=(2.3, 1))\n",
    "\n",
    "# Format the labels with scientific notation\n",
    "for g_i in [g1, g2, g3, g4]:\n",
    "    handles, labels = g_i.legend.legend_handles, g_i.legend.get_texts()\n",
    "    for label in labels:\n",
    "        original_label = label.get_text()\n",
    "        new_label = f\"{float(original_label):.2e}\"\n",
    "        label.set_text(new_label)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig4, ax4 = plt.subplots(2, 2, figsize=(12,10))\n",
    "sns.lineplot(data=simu_spectro_df, x='d', y='amplitude', hue='sweep direction', \n",
    "             legend='auto', ax=ax4[0][0], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=simu_spectro_df, x='d', y='frequency', hue='sweep direction',\n",
    "             legend=False, ax=ax4[0][1], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=simu_spectro_df, x='d', y='deflection', hue='sweep direction',\n",
    "             legend=False, ax=ax4[1][0], marker='.', markeredgewidth=0)\n",
    "sns.lineplot(data=simu_spectro_df, x='d', y='d lower turn', hue='sweep direction',\n",
    "             legend=False, ax=ax4[1][1], marker='.', markeredgewidth=0)\n",
    "for ax_i in ax4.flatten():\n",
    "    for d0_select_i in (min(d0_select), max(d0_select)):\n",
    "        ax_i.axvline(d0_select_i, linestyle='--', color='gray')\n",
    "# ax4_00_ylim = ax4[0][0].get_ylim()\n",
    "# ax4[0][0].plot(d0_list_simu, d0_list_simu, linestyle='--', color='gray')\n",
    "# ax4[0][0].set_ylim(*ax4_00_ylim)\n",
    "# ax4_10_ylim = ax4[1][0].get_ylim()\n",
    "# ax4[1][0].plot(d0_list_simu, -d0_list_simu, linestyle='--', color='gray')\n",
    "# ax4[1][0].set_ylim(*ax4_10_ylim)\n",
    "# ax4[1][1].axhline(a0, linestyle='--', color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762bda8b-beb5-4768-ba9a-38751783e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "gamma = 0.1\n",
    "omega_0 = 1.0\n",
    "F_0 = 1.0\n",
    "omega_range = np.linspace(0.1, 2.0, 500)\n",
    "\n",
    "# Arrays to hold phase values\n",
    "phases = []\n",
    "\n",
    "# Calculate phase for each driving frequency\n",
    "for omega in omega_range:\n",
    "    phi = np.arctan2(2 * gamma * omega, omega_0**2 - omega**2)\n",
    "    phases.append(phi*180/np.pi)\n",
    "\n",
    "# Convert list to array for plotting\n",
    "phases = np.array(phases)\n",
    "\n",
    "# Plotting phase vs driving frequency\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(omega_range, phases)\n",
    "plt.title('Phase vs Driving Frequency for Driven Harmonic Oscillator')\n",
    "plt.xlabel('Driving Frequency (omega)')\n",
    "plt.ylabel('Phase (radians)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ae616-6763-4c1f-a592-3c2f8172a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "fs = 1000  # Sampling frequency in Hz\n",
    "t = np.arange(0, 1, 1/fs)  # Time vector from 0 to 1 second\n",
    "f_signal = 50  # Signal frequency in Hz\n",
    "\n",
    "# Generate a cosine wave\n",
    "cosine_wave = np.cos(2 * np.pi * f_signal * t)\n",
    "\n",
    "# Compute the FFT\n",
    "N = len(cosine_wave)\n",
    "X = np.fft.fft(cosine_wave)\n",
    "\n",
    "# Define the frequency of interest\n",
    "f = f_signal  # Frequency at which to find amplitude and phase\n",
    "\n",
    "# Calculate the index corresponding to the frequency\n",
    "index = int(f * N / fs)\n",
    "\n",
    "# Extract the FFT coefficient at the specified frequency\n",
    "fft_coefficient = X[index]\n",
    "\n",
    "# Calculate amplitude and phase angle\n",
    "amplitude = np.abs(fft_coefficient) *2 / N\n",
    "phase_angle = np.angle(fft_coefficient)\n",
    "\n",
    "print(f\"Amplitude at {f} Hz: {amplitude}\")\n",
    "print(f\"Phase angle at {f} Hz: {phase_angle} radians\")\n",
    "\n",
    "\n",
    "omega = np.fft.fftfreq(N, t[1] - t[0])\n",
    "omega = np.fft.fftshift(omega)\n",
    "X = np.fft.fftshift(X)\n",
    "plt.plot(omega, X, '-')\n",
    "plt.gca().set_xlim(25, 75)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c0d82-082f-4384-b285-5d16f9e9e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(phase_shift + np.pi)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9b0a27-cc99-41e7-95be-7f8fe82c87eb",
   "metadata": {},
   "source": [
    "## LIQUID NECK SIMULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f0df9-67e9-4a7e-9f36-7b85280bf600",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_t = 20e-9 #tip radius (m)\n",
    "R_s = 5e9 #sample radius (m)\n",
    "# R1 = 20e-9 #tip radius\n",
    "theta_s = 0 #contact angle with sample (deg)\n",
    "theta_t = 0 #contact angle with tip (deg)\n",
    "humid = 0.8 # humidity\n",
    "\n",
    "R1 = 1/((1/R_t)+(1/R_s)) #effective Derjaguin radius (m)\n",
    "T_temp = 298 #Temperature (K)\n",
    "surf_ten = 72e-3 #surface tension (N/m)\n",
    "dens = 1000 #density (kg/m3)\n",
    "mol_wt = 18e-3 #molecular wt (kg/mol)\n",
    "R_gas = 8.314 #Ideal gas constant (J/K⋅mol)\n",
    "mol_vol = mol_wt/dens #molar volume\n",
    "kelv_len = (surf_ten*mol_vol)/(R_gas*T_temp) #kelvin length\n",
    "r_kelv = -kelv_len/np.log(humid) #kelvin radius\n",
    "\n",
    "D_ts_array = np.linspace(0.0e-10, 5e-9, 20) #tip-sample distance (m)\n",
    "# beta_guess = 10 #initial guess for beta (deg)\n",
    "\n",
    "alpha0 = 2\n",
    "alpha1 = -np.pi/4\n",
    "alpha2 = -(np.pi**2)/64\n",
    "F_cp_array = []\n",
    "\n",
    "for D_ts_i in D_ts_array:\n",
    "    # F_cp_i = (2*np.pi*surf_ten*R1)*((alpha0*(1-(D_ts_i/(2*r_kelv)))) + (alpha1*(1+(D_ts_i/(4*r_kelv)))*np.sqrt(r_kelv/R1)) + (alpha2*(r_kelv/R1)))\n",
    "    F_cp_array.append(F_cp_i)\n",
    "\n",
    "plt.plot(D_ts_array, F_cp_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff0530-28d9-4df9-b74e-0628ce88a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "R_t = 20e-9 #tip radius (m)\n",
    "R_s = 5e9 #sample radius (m)\n",
    "# R1 = 20e-9 #tip radius\n",
    "theta_s = 0 #contact angle with sample (deg)\n",
    "theta_t = 0 #contact angle with tip (deg)\n",
    "humid = 0.5 # humidity\n",
    "\n",
    "R1 = 1/((1/R_t)+(1/R_s)) #effective Derjaguin radius (m)\n",
    "T_temp = 298 #Temperature (K)\n",
    "surf_ten = 72e-3 #surface tension (N/m)\n",
    "dens = 1000 #density (kg/m3)\n",
    "mol_wt = 18e-3 #molecular wt (kg/mol)\n",
    "R_gas = 8.314 #Ideal gas constant (J/K⋅mol)\n",
    "mol_vol = mol_wt/dens #molar volume\n",
    "kelv_len = (surf_ten*mol_vol)/(R_gas*T_temp) #kelvin length\n",
    "\n",
    "D_ts_array = np.linspace(0.0e-10, 5e-9, 200) #tip-sample distance (m)\n",
    "beta_guess = 10 #initial guess for beta (deg)\n",
    "\n",
    "# rm_eq = -kelv_len/np.log(humid) #equilibrium meniscus radius (for constant pressure)\n",
    "def find_beta_cp(beta, D_ts):\n",
    "    c_theta = (np.cos(theta_s*np.pi/180)+np.cos((theta_t+beta)*np.pi/180))/2 #effective contact angle\n",
    "    r_eq = (R1*(1-np.cos(beta*np.pi/180)) + D_ts)/(2*c_theta)\n",
    "    l_eq = (R1*np.sin(beta*np.pi/180)) - (r_eq*(1-np.cos((theta_t+beta)*np.pi/180)))\n",
    "    humid_calc = np.exp(-kelv_len*((1/r_eq)-(1/l_eq)))\n",
    "    # print(c_theta, r_eq, l_eq, humid_calc)\n",
    "    return humid - humid_calc\n",
    "\n",
    "\n",
    "D_ts_cp_array = []\n",
    "D_ts_cv_array = []\n",
    "F_cp_array = []\n",
    "F_cv_array = []\n",
    "F_cp_approx_array = []\n",
    "F_cv_approx_array = []\n",
    "F_cp2_array = []\n",
    "humid_cp_array = []\n",
    "humid_cv_array = []\n",
    "r_eq_cp_array = []\n",
    "r_eq_cv_array = []\n",
    "l_eq_cp_array = []\n",
    "l_eq_cv_array = []\n",
    "vol_cp_array = []\n",
    "vol_cv_array = []\n",
    "beta_cp_array = []\n",
    "beta_cv_array = []\n",
    "# beta_array = np.logspace(0, 1, 10000)\n",
    "for D_ts_i in D_ts_array:\n",
    "    solver_out_i = fsolve(find_beta_cp, beta_guess, args = (D_ts_i), full_output=True)\n",
    "    # print(solver_out_i)\n",
    "    beta_i = solver_out_i[0][0]\n",
    "    if solver_out_i[2] != 1:\n",
    "        print('break', D_ts_i, humid_i, vol_i)#, solver_out_i[3])\n",
    "        # break\n",
    "    # for beta_i in beta_array:\n",
    "        # beta_i = beta_i\n",
    "    c_theta_i = (np.cos(theta_s*np.pi/180)+np.cos((theta_t+beta_i)*np.pi/180))/2\n",
    "    r_eq_i = (R1*(1-np.cos(beta_i*np.pi/180)) + D_ts_i)/(2*c_theta_i)\n",
    "    l_eq_i = (R1*np.sin(beta_i*np.pi/180)) - (r_eq_i*(1-np.cos((theta_t+beta_i)*np.pi/180)))\n",
    "    humid_i = np.exp(-kelv_len*((1/r_eq_i)-(1/l_eq_i)))\n",
    "\n",
    "    # if abs(humid_i-humid) > 0.01:\n",
    "    #     break\n",
    "    F_cp_i = np.pi*surf_ten*R1*np.sin(beta_i*np.pi/180)*(2*np.sin((theta_t+beta_i)*np.pi/180)+\\\n",
    "                                                         (R1*np.sin(beta_i*np.pi/180)*((1/r_eq_i)-(1/l_eq_i))))\n",
    "    h_i = 2*r_eq_i*c_theta_i\n",
    "    # print(D_ts_i, h_i, 2*r_eq_i, c_theta_i, (2*r_eq_i)-h_i)\n",
    "    vol_term1_i = R1 * np.sin(beta_i*np.pi/180)\n",
    "    vol_term2_i = R1 * (1 - np.cos(beta_i*np.pi/180))\n",
    "    vol_i = (np.pi*h_i*vol_term1_i**2) - ((np.pi*vol_term2_i/6)*((3*vol_term1_i**2)+vol_term2_i**2))\n",
    "\n",
    "    F_cp_approx_i = 2*np.pi*surf_ten*R1*((np.cos(theta_s*np.pi/180)+np.cos(theta_t*np.pi/180))-(D_ts_i/(-kelv_len/np.log(humid))))\n",
    "    \n",
    "    F_cp2_i = (2*np.pi*surf_ten*R1)*((alpha0*(1-(D_ts_i/(2*r_kelv)))) + (alpha1*(1+(D_ts_i/(4*r_kelv)))*np.sqrt(r_kelv/R1)) + (alpha2*(r_kelv/R1)))\n",
    "    F_cp2_array.append(F_cp2_i)\n",
    "    \n",
    "    F_cp_array.append(F_cp_i)\n",
    "    F_cp_approx_array.append(F_cp_approx_i)\n",
    "    humid_cp_array.append(humid_i)\n",
    "    r_eq_cp_array.append(r_eq_i)\n",
    "    l_eq_cp_array.append(l_eq_i)\n",
    "    beta_cp_array.append(beta_i)\n",
    "    vol_cp_array.append(vol_i)\n",
    "    D_ts_cp_array.append(D_ts_i)\n",
    "    beta_guess = beta_i\n",
    "        # print(D_ts_i, Fcap_i, humid_i, beta_i, r_eq_i, l_eq_i) \n",
    "r_gauss_cp_array = [1/((1/r_i)-(1/l_i)) for r_i, l_i in zip(r_eq_cp_array, l_eq_cp_array)]\n",
    "\n",
    "humid_diff = np.array([abs(hum_i-humid) for hum_i in humid_cp_array])\n",
    "hum_thresh = 100*np.std(humid_diff[:10])\n",
    "stable_ind = np.argmax(humid_diff > hum_thresh) - 1\n",
    "D_ts_cond = D_ts_array[stable_ind] #condensation distance\n",
    "vol_cond = vol_cp_array[stable_ind] #condensation volume (used for constant volume calculations)\n",
    "c_theta = (np.cos(theta_s*np.pi/180)+np.cos(theta_t*np.pi/180))/2 #effective contact angle\n",
    "d_rupt = (1+(np.arccos(c_theta)/4))*((vol_cond**(1/3)) - ((vol_cond**(2/3))/(5*R1))) #Willett et. al. (2000)\n",
    "rupture_ind = np.argmax(D_ts_array > d_rupt) - 1\n",
    "D_ts_cond_theory = -2*c_theta*kelv_len/np.log(humid)\n",
    "cond_approx_ind = np.argmax(D_ts_array > D_ts_cond_theory) - 1\n",
    "\n",
    "print(D_ts_cond, d_rupt, vol_cond)\n",
    "# print(stable_ind, rupture_ind)\n",
    "\n",
    "def find_beta_cv(beta, D_ts):\n",
    "    c_theta = (np.cos(theta_s*np.pi/180)+np.cos((theta_t+beta)*np.pi/180))/2 #effective contact angle\n",
    "    r_eq = (R1*(1-np.cos(beta*np.pi/180)) + D_ts)/(2*c_theta)\n",
    "    l_eq = (R1*np.sin(beta*np.pi/180)) - (r_eq*(1-np.cos((theta_t+beta)*np.pi/180)))\n",
    "\n",
    "    h = 2*r_eq*c_theta\n",
    "    vol_term1 = R1 * np.sin(beta*np.pi/180)\n",
    "    vol_term2 = R1 * (1 - np.cos(beta*np.pi/180))\n",
    "    vol = (np.pi*h*vol_term1**2) - ((np.pi*vol_term2/6)*((3*vol_term1**2)+vol_term2**2))\n",
    "    # humid_calc = np.exp(-kelv_len*((1/r_eq)-(1/l_eq)))\n",
    "    # print(c_theta, r_eq, l_eq, humid_calc)\n",
    "    return vol_cond - vol\n",
    "\n",
    "beta_guess = 10 #initial guess for beta (deg)\n",
    "for D_ts_i in D_ts_array:\n",
    "    beta_i = fsolve(find_beta_cv, beta_guess, args = (D_ts_i))[0]\n",
    "    beta_guess = beta_i\n",
    "    # for beta_i in beta_array:\n",
    "        # beta_i = beta_i\n",
    "    c_theta_i = (np.cos(theta_s*np.pi/180)+np.cos((theta_t+beta_i)*np.pi/180))/2\n",
    "    r_eq_i = (R1*(1-np.cos(beta_i*np.pi/180)) + D_ts_i)/(2*c_theta_i)\n",
    "    l_eq_i = (R1*np.sin(beta_i*np.pi/180)) - (r_eq_i*(1-np.cos((theta_t+beta_i)*np.pi/180)))\n",
    "    humid_i = np.exp(-kelv_len*((1/r_eq_i)-(1/l_eq_i)))\n",
    "    F_cv_i = np.pi*surf_ten*R1*np.sin(beta_i*np.pi/180)*(2*np.sin((theta_t+beta_i)*np.pi/180)+\\\n",
    "                                                         (R1*np.sin(beta_i*np.pi/180)*((1/r_eq_i)-(1/l_eq_i))))\n",
    "    h_i = 2*r_eq_i*c_theta_i\n",
    "    vol_term1_i = R1 * np.sin(beta_i*np.pi/180)\n",
    "    vol_term2_i = R1 * (1 - np.cos(beta_i*np.pi/180))\n",
    "    vol_i = (np.pi*h_i*vol_term1_i**2) - ((np.pi*vol_term2_i/6)*((3*vol_term1_i**2)+vol_term2_i**2))\n",
    "\n",
    "    # F_cp_approx_i = 2*np.pi*surf_ten*R1*((np.cos(theta_s*np.pi/180)+np.cos(theta_t*np.pi/180))-(D_ts_i/(-kelv_len/np.log(humid))))\n",
    "    c_theta_i = (np.cos(theta_s*np.pi/180)+np.cos((theta_t)*np.pi/180))\n",
    "    F_cv_approx_i = 2*np.pi*surf_ten*R1*c_theta_i*(1-(D_ts_i/np.sqrt(((vol_cond/(np.pi*R1))+D_ts_i**2))))\n",
    "    \n",
    "    F_cv_array.append(F_cv_i)\n",
    "    F_cv_approx_array.append(F_cv_approx_i)\n",
    "    humid_cv_array.append(humid_i)\n",
    "    r_eq_cv_array.append(r_eq_i)\n",
    "    l_eq_cv_array.append(l_eq_i)\n",
    "    beta_cv_array.append(beta_i)\n",
    "    vol_cv_array.append(vol_i)\n",
    "    D_ts_cv_array.append(D_ts_i)\n",
    "    \n",
    "    # F_cv_array.append(F_cv_i)\n",
    "\n",
    "\n",
    "F_cp_array[stable_ind:] = [0]*(len(F_cp_array)-stable_ind)\n",
    "F_cv_array[rupture_ind:] = [0]*(len(F_cv_array)-rupture_ind)\n",
    "F_cp_approx_array[cond_approx_ind:] = [0]*(len(F_cp_approx_array)-cond_approx_ind)\n",
    "\n",
    "cap_datadict = {'Distance_cp': D_ts_cp_array,\n",
    "                'Distance_cv': D_ts_cv_array,\n",
    "                'Force_cp': F_cp_array,\n",
    "                'Force_cp_approx': F_cp_approx_array,\n",
    "                'Force_cp2': F_cp2_array,\n",
    "                'beta_cp': beta_cp_array,\n",
    "                'r_cp': r_eq_cp_array,\n",
    "                'l_cp': l_eq_cp_array,\n",
    "                'r_gauss_cp': r_gauss_cp_array,\n",
    "                'humidity calc_cp': humid_cp_array,\n",
    "                'volume_cp': vol_cp_array,\n",
    "                'Force_cv': F_cv_array,\n",
    "                'Force_cv_approx': F_cv_approx_array,\n",
    "                'beta_cv': beta_cv_array,\n",
    "                'r_cv': r_eq_cv_array,\n",
    "                'l_cv': l_eq_cv_array,\n",
    "                # 'r_gauss_cv': r_gauss_cv_array,\n",
    "                'humidity calc_cv': humid_cv_array,\n",
    "                'volume_cv': vol_cv_array\n",
    "               }\n",
    "\n",
    "\n",
    "color_list = sns.color_palette()\n",
    "fig, ax = plt.subplots(3,2, figsize=(10,15))\n",
    "sns.lineplot(x='Distance_cp', y='Force_cp', data=cap_datadict, marker=None, color=color_list[0], ax=ax[0][0])\n",
    "ax[0][0].plot(D_ts_array[stable_ind], F_cp_array[stable_ind], 'o')\n",
    "sns.lineplot(x='Distance_cv', y='Force_cv', data=cap_datadict, marker=None, color=color_list[1], ax=ax[0][0])\n",
    "sns.lineplot(x='Distance_cp', y='Force_cp2', data=cap_datadict, linestyle='--', color=color_list[0], ax=ax[0][0])\n",
    "sns.lineplot(x='Distance_cp', y='Force_cp_approx', data=cap_datadict, linestyle=':', color=color_list[0], ax=ax[0][0])\n",
    "sns.lineplot(x='Distance_cv', y='Force_cv_approx', data=cap_datadict, linestyle=':', color=color_list[1], ax=ax[0][0])\n",
    "ax[0][0].axhline(0, linestyle=':')\n",
    "ax[0][0].axvline(D_ts_cond_theory, linestyle=':')\n",
    "\n",
    "# plt.show()\n",
    "sns.lineplot(x='Distance_cp', y='beta_cp', data=cap_datadict, marker='.', color=color_list[0], ax=ax[0][1])\n",
    "sns.lineplot(x='Distance_cv', y='beta_cv', data=cap_datadict, marker='.', color=color_list[1], ax=ax[0][1])\n",
    "ax[0][1].plot(D_ts_array[stable_ind], beta_cp_array[stable_ind], 'o')\n",
    "# plt.show()\n",
    "sns.lineplot(x='Distance_cp', y='r_cp', data=cap_datadict, marker='.', color=color_list[0], ax=ax[1][1])\n",
    "sns.lineplot(x='Distance_cv', y='r_cv', data=cap_datadict, marker='.', color=color_list[1], ax=ax[1][1])\n",
    "ax[1][1].plot(D_ts_array[stable_ind], r_eq_cp_array[stable_ind], 'o')\n",
    "# plt.show()\n",
    "sns.lineplot(x='Distance_cp', y='l_cp', data=cap_datadict, marker='.', color=color_list[0], ax=ax[2][1])\n",
    "sns.lineplot(x='Distance_cv', y='l_cv', data=cap_datadict, marker='.', color=color_list[1], ax=ax[2][1])\n",
    "ax[2][1].plot(D_ts_array[stable_ind], l_eq_cp_array[stable_ind], 'o')\n",
    "# plt.show()\n",
    "# sns.lineplot(x='Distance', y='r_gauss', data=cap_datadict)\n",
    "# plt.show()\n",
    "sns.lineplot(x='Distance_cp', y='humidity calc_cp', data=cap_datadict, marker='.', color=color_list[0], ax=ax[1][0])\n",
    "# sns.lineplot(x='Distance_cv', y='humidity calc_cv', data=cap_datadict, marker='.', color=color_list[1], ax=ax[1][0])\n",
    "ax[1][0].plot(D_ts_array[stable_ind], humid_cp_array[stable_ind], 'o')\n",
    "# plt.show()\n",
    "sns.lineplot(x='Distance_cp', y='volume_cp', data=cap_datadict, marker='.', color=color_list[0], ax=ax[2][0])\n",
    "sns.lineplot(x='Distance_cv', y='volume_cv', data=cap_datadict, marker='.', color=color_list[1], ax=ax[2][0])\n",
    "ax[2][0].plot(D_ts_array[stable_ind], vol_cp_array[stable_ind], 'o')\n",
    "plt.show()\n",
    "# plt.plot(humid_array[:10000], F_cp_array[:10000], '-')\n",
    "# plt.plot(humid_array[-10000:], F_cp_array[-10000:], '-')\n",
    "# plt.show()\n",
    "# plt.plot(humid_array[:10000], r_eq_array[:10000], '-')\n",
    "# plt.plot(humid_array[-10000:], r_eq_array[-10000:], '-')\n",
    "# plt.show()\n",
    "# plt.plot(humid_array[:10000], l_eq_array[:10000], '-')\n",
    "# plt.plot(humid_array[-10000:], l_eq_array[-10000:], '-')\n",
    "# plt.show()\n",
    "# plt.plot(humid_array[:10000], r_gauss_array[:10000], '-')\n",
    "# plt.plot(humid_array[-10000:], r_gauss_array[-10000:], '-')\n",
    "# plt.show()\n",
    "# plt.plot(humid_array[:10000], beta_array[:10000], '-')\n",
    "# plt.plot(humid_array[-10000:], beta_array[-10000:], '-')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf96646-8c12-445f-9029-1881764a465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_cp_array = []\n",
    "vol_cp_array = []\n",
    "humid_cp_array = []\n",
    "beta_plot_array = []\n",
    "D_ts_plot_array = []\n",
    "r_eq_cp_array = []\n",
    "l_eq_cp_array = []\n",
    "h_array = []\n",
    "D_ts_array = np.linspace(0.0e-10, 1.5e-9, 10) #tip-sample distance (m)\n",
    "beta_array = np.linspace(1, 20, 100)\n",
    "for D_ts_i in D_ts_array:\n",
    "    # beta_i = fsolve(find_beta_cp, beta_guess, args = (D_ts_i))[0]\n",
    "    # beta_guess = beta_i\n",
    "    for beta_i in beta_array:\n",
    "        # beta_i = beta_i\n",
    "        c_theta_i = (np.cos(theta_s*np.pi/180)+np.cos((theta_t+beta_i)*np.pi/180))/2\n",
    "        r_eq_i = (R1*(1-np.cos(beta_i*np.pi/180)) + D_ts_i)/(2*c_theta_i)\n",
    "        l_eq_i = (R1*np.sin(beta_i*np.pi/180)) - (r_eq_i*(1-np.cos((theta_t+beta_i)*np.pi/180)))\n",
    "        humid_i = np.exp(-kelv_len*((1/r_eq_i)-(1/l_eq_i)))\n",
    "        F_cp_i = np.pi*surf_ten*R1*np.sin(beta_i*np.pi/180)*(2*np.sin((theta_t+beta_i)*np.pi/180)+\\\n",
    "                                                             (R1*np.sin(beta_i*np.pi/180)*((1/r_eq_i)-(1/l_eq_i))))\n",
    "        h_i = 2*r_eq_i*c_theta_i\n",
    "        # print(D_ts_i, h_i, 2*r_eq_i, c_theta_i, (2*r_eq_i)-h_i)\n",
    "        vol_term1_i = R1 * np.sin(beta_i*np.pi/180)\n",
    "        vol_term2_i = R1 * (1 - np.cos(beta_i*np.pi/180))\n",
    "        vol_i = (np.pi*h_i*vol_term1_i**2) - ((np.pi*vol_term2_i/6)*((3*vol_term1_i**2)+vol_term2_i**2))\n",
    "\n",
    "        F_cp_array.append(F_cp_i)\n",
    "        vol_cp_array.append(vol_i)\n",
    "        humid_cp_array.append(humid_i)\n",
    "        beta_plot_array.append(beta_i)\n",
    "        D_ts_plot_array.append(D_ts_i)\n",
    "        r_eq_cp_array.append(r_eq_i)\n",
    "        l_eq_cp_array.append(l_eq_i)\n",
    "        h_array.append(h_i)\n",
    "\n",
    "cap_datadict2 = {'Distance': D_ts_plot_array,\n",
    "                'Force_cp': F_cp_array,\n",
    "                'beta': beta_plot_array,\n",
    "                'Volume': vol_cp_array,\n",
    "                'Humidity': humid_cp_array,\n",
    "                 'r_cp': r_eq_cp_array,\n",
    "                'l_cp': l_eq_cp_array,\n",
    "                 'h_cp': h_array,\n",
    "               }\n",
    "color_list = sns.color_palette()\n",
    "fig, ax = plt.subplots(2,3, figsize=(15,10))\n",
    "sns.lineplot(x='beta', y='Force_cp', hue='Distance', data=cap_datadict2, ax=ax[0][0], legend=False)\n",
    "sns.lineplot(x='beta', y='Volume', hue='Distance', data=cap_datadict2, ax=ax[0][1], legend='full')\n",
    "sns.lineplot(x='beta', y='Humidity', hue='Distance', data=cap_datadict2, ax=ax[0][2], legend=False)\n",
    "sns.lineplot(x='r_cp', y='Humidity', hue='Distance', data=cap_datadict2, ax=ax[1][0], legend=False)\n",
    "sns.lineplot(x='l_cp', y='Humidity', hue='Distance', data=cap_datadict2, ax=ax[1][1], legend=False)\n",
    "sns.lineplot(x='h_cp', y='Humidity', hue='Distance', data=cap_datadict2, ax=ax[1][2], legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abf110-9b7e-45dc-8567-d078aec9e237",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Condensation distance vs contact angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e6123-5894-4c70-a1fd-23e9abf0f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# beta_array = np.logspace(0, 1, 10000)\n",
    "D_ts_cond_array = []\n",
    "vol_cond_array = []\n",
    "humid_cond_array = []\n",
    "theta_s_cond_array = []\n",
    "beta_array = []\n",
    "humid_calc_array = []\n",
    "r_eq_array = []\n",
    "l_eq_array = []\n",
    "\n",
    "R_t = 20e-9 #tip radius (m)\n",
    "R_s = 5e9 #sample radius (m)\n",
    "# R1 = 20e-9 #tip radius\n",
    "# theta_s = 0 #contact angle with sample (deg)\n",
    "theta_t = 0 #contact angle with tip (deg)\n",
    "# humid = 0.7 # humidity\n",
    "\n",
    "R1 = 1/((1/R_t)+(1/R_s)) #effective Derjaguin radius (m)\n",
    "T_temp = 298 #Temperature (K)\n",
    "surf_ten = 72e-3 #surface tension (N/m)\n",
    "dens = 1000 #density (kg/m3)\n",
    "mol_wt = 18e-3 #molecular wt (kg/mol)\n",
    "R_gas = 8.314 #Ideal gas constant (J/K⋅mol)\n",
    "mol_vol = mol_wt/dens #molar volume\n",
    "kelv_len = (surf_ten*mol_vol)/(R_gas*T_temp) #kelvin length\n",
    "\n",
    "# D_ts_array = np.linspace(1e-9, 0, 10000) #tip-sample distance (m)\n",
    "# D_ts_array = 2e-9 - np.logspace(-8.7,-10, 10000) #tip-sample distance (m)\n",
    "D_ts_array = 3e-9 -np.logspace(-8.53,-10, 10000)\n",
    "theta_s_array = np.linspace(0, 90, 50)\n",
    "humid_array = [0.8] #np.linspace(0.3, 0.7, 5)\n",
    "\n",
    "\n",
    "# rm_eq = -kelv_len/np.log(humid) #equilibrium meniscus radius (for constant pressure)\n",
    "def find_beta_cp2(beta, D_ts, humid, theta_s):\n",
    "    c_theta = (np.cos(theta_s*np.pi/180)+np.cos((theta_t+beta)*np.pi/180))/2 #effective contact angle\n",
    "    r_eq = (R1*(1-np.cos(beta*np.pi/180)) + D_ts)/(2*c_theta)\n",
    "    l_eq = (R1*np.sin(beta*np.pi/180)) - (r_eq*(1-np.cos((theta_t+beta)*np.pi/180)))\n",
    "    humid_calc = np.exp(-kelv_len*((1/r_eq)-(1/l_eq)))\n",
    "    # print(c_theta, r_eq, l_eq, humid_calc)\n",
    "    return humid - humid_calc\n",
    "\n",
    "for humid_i in humid_array:\n",
    "    # beta_guess = 15 #initial guess for beta (deg)\n",
    "    for theta_s_i in theta_s_array:\n",
    "        beta_guess = 10 #initial guess for beta (deg)\n",
    "        for D_ts_i in D_ts_array:\n",
    "            solver_out_i = fsolve(find_beta_cp2, beta_guess, args = (D_ts_i, humid_i, theta_s_i), #xtol=1e-10, \n",
    "                                  full_output=True)\n",
    "            beta_i = solver_out_i[0][0]\n",
    "            # print(solver_out_i)                \n",
    "            # for beta_i in beta_array:\n",
    "                # beta_i = beta_i            \n",
    "            if solver_out_i[2] != 1: #no solution converged\n",
    "                # beta_i = solver_out_i[0][0]\n",
    "                beta_i = beta_guess #previous value where solution was found\n",
    "                \n",
    "                # print('break', D_cond_i, beta_i, theta_s_i, humid_i)#, solver_out_i[3])\n",
    "                c_theta_i = (np.cos(theta_s_i*np.pi/180)+np.cos((theta_t+beta_i)*np.pi/180))/2\n",
    "                r_eq_i = (R1*(1-np.cos(beta_i*np.pi/180)) + D_cond_i)/(2*c_theta_i)\n",
    "                l_eq_i = (R1*np.sin(beta_i*np.pi/180)) - (r_eq_i*(1-np.cos((theta_t+beta_i)*np.pi/180)))\n",
    "                humid_calc_i = np.exp(-kelv_len*((1/r_eq_i)-(1/l_eq_i)))\n",
    "                # print(humid_i, humid_calc_i, humid_i-humid_calc_i)\n",
    "                # if abs(humid_i-humid) > 0.01:\n",
    "                #     break\n",
    "                F_cp_i = np.pi*surf_ten*R1*np.sin(beta_i*np.pi/180)*(2*np.sin((theta_t+beta_i)*np.pi/180)+\\\n",
    "                                                                     (R1*np.sin(beta_i*np.pi/180)*((1/r_eq_i)-(1/l_eq_i))))\n",
    "                h_i = 2*r_eq_i*c_theta_i\n",
    "                # print(D_ts_i, h_i, 2*r_eq_i, c_theta_i, (2*r_eq_i)-h_i)\n",
    "                vol_term1_i = R1 * np.sin(beta_i*np.pi/180)\n",
    "                vol_term2_i = R1 * (1 - np.cos(beta_i*np.pi/180))\n",
    "                vol_i = (np.pi*h_i*vol_term1_i**2) - ((np.pi*vol_term2_i/6)*((3*vol_term1_i**2)+vol_term2_i**2))\n",
    "                \n",
    "                D_ts_cond_array.append(D_cond_i)\n",
    "                vol_cond_array.append(vol_i)\n",
    "                humid_cond_array.append(humid_i)\n",
    "                theta_s_cond_array.append(theta_s_i)\n",
    "                beta_array.append(beta_i)\n",
    "                humid_calc_array.append(humid_calc_i)\n",
    "                r_eq_array.append(r_eq_i)\n",
    "                l_eq_array.append(l_eq_i)\n",
    "                break\n",
    "            else:\n",
    "                D_cond_i = D_ts_i\n",
    "                beta_guess = beta_i\n",
    "\n",
    "cap_datadict3 = {'Humidity': humid_cond_array,\n",
    "                'Contact angle': theta_s_cond_array,\n",
    "                'Condensation distance': D_ts_cond_array,\n",
    "                'Condensation volume': vol_cond_array,\n",
    "                 'beta': beta_array,\n",
    "                 'r_cond': r_eq_array,\n",
    "                'l_cond': l_eq_array,\n",
    "                 'humidity calc': humid_calc_array,\n",
    "               }\n",
    "\n",
    "fit_order = 3\n",
    "cap_datadf3 = pd.DataFrame(cap_datadict3)\n",
    "cap_fit_dict = {} #fitting parameters\n",
    "cap_datadf3_fitlist = [] #dataframe list containing fitted data in column\n",
    "for humid_i in humid_array:\n",
    "    cap_fit_dict[humid_i] = {}\n",
    "    cap_datadf3_filt = cap_datadf3[cap_datadf3['Humidity'] == humid_i]\n",
    "    cap_fit_dict[humid_i]['cond_distance'] = np.polyfit(cap_datadf3_filt['Contact angle'], \n",
    "                                                        cap_datadf3_filt['Condensation distance'], fit_order)\n",
    "    cap_fit_dict[humid_i]['cond_volume'] = np.polyfit(cap_datadf3_filt['Contact angle'], \n",
    "                                                        cap_datadf3_filt['Condensation volume'], fit_order)\n",
    "    cap_datadf3_filt['cond_distance_fit'] = np.polyval(cap_fit_dict[humid_i]['cond_distance'], \n",
    "                                                       cap_datadf3_filt['Contact angle'])\n",
    "    cap_datadf3_filt['cond_volume_fit'] = np.polyval(cap_fit_dict[humid_i]['cond_volume'], \n",
    "                                                       cap_datadf3_filt['Contact angle'])\n",
    "    cap_datadf3_fitlist.append(cap_datadf3_filt)\n",
    "\n",
    "cap_datadf3_fit = pd.concat(cap_datadf3_fitlist)\n",
    "cap_datadf3_fit['Humidity'] = cap_datadf3_fit['Humidity'].astype('category')\n",
    "\n",
    "color_list = sns.color_palette()\n",
    "fig, ax = plt.subplots(2,3, figsize=(15,10))\n",
    "sns.lineplot(x='Contact angle', y='Condensation distance', hue='Humidity', data=cap_datadf3_fit, ax=ax[0][0], legend=False)\n",
    "sns.lineplot(x='Contact angle', y='cond_distance_fit', hue='Humidity', data=cap_datadf3_fit,\n",
    "             linestyle=\":\", ax=ax[0][0], legend=False)\n",
    "sns.lineplot(x='Contact angle', y='Condensation volume', hue='Humidity', data=cap_datadf3_fit, ax=ax[0][1], legend=False)\n",
    "sns.lineplot(x='Contact angle', y='cond_volume_fit', hue='Humidity', data=cap_datadf3_fit, \n",
    "             linestyle=\":\", ax=ax[0][1], legend=False)\n",
    "sns.lineplot(x='Contact angle', y='beta', hue='Humidity', data=cap_datadf3_fit, ax=ax[0][2], legend='full')\n",
    "sns.lineplot(x='Contact angle', y='r_cond', hue='Humidity', data=cap_datadf3_fit, ax=ax[1][0], legend=False)\n",
    "sns.lineplot(x='Contact angle', y='l_cond', hue='Humidity', data=cap_datadf3_fit, ax=ax[1][1], legend=False)\n",
    "sns.lineplot(x='Contact angle', y='humidity calc', hue='Humidity', data=cap_datadf3_fit, ax=ax[1][2], legend=False)\n",
    "plt.show()\n",
    "\n",
    "cap_fit_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db659179-d64e-43a0-9330-65bbb80ea79c",
   "metadata": {},
   "source": [
    "### Kelvin radius vs Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476998b-588c-4aff-b93f-28c1de600a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "humid_array2 = np.linspace(0.1,0.9,50)\n",
    "kelv_rad = -kelv_len/np.log(humid_array2)\n",
    "kelv_datadict = {'Humidity': humid_array2, 'Kelvin radius': kelv_rad}\n",
    "sns.lineplot(x='Humidity', y='Kelvin radius', data=temp_dict)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c03c42-709d-4c51-80f2-62aadacd6aa6",
   "metadata": {},
   "source": [
    "## OSCILLOSCOPE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18167cb4-14dd-41ad-aa3c-6b97c5e53c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "osci_folderpath = Path('/home/pranav/Work/Data/Murcia/oscilloscope/20241216-0001_liquidneckonglass/')\n",
    "\n",
    "osci_datalist = []\n",
    "for osci_file_i in osci_folderpath.iterdir():\n",
    "    osci_df_i = pd.read_csv(osci_file_i, delimiter=\";\", header=0, decimal=\",\", skiprows=[1],\n",
    "                           dtype={\"Time\": float, \"Channel A\": float, \"Channel B\": float, \"Channel C\": float, \"Channel D\": float})\n",
    "    # osci_df_i = osci_df_i.drop([0]).reset_index()\n",
    "    osci_datalist.append(osci_df_i)\n",
    "    # print(osci_file_i)\n",
    "    # print(osci_df_i)\n",
    "    # break\n",
    "\n",
    "fig = plotly_lineplot(data=osci_datalist[8], x='Time', y='Channel C')\n",
    "# plt.plot(osci_df_i['Channel C'])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f974483-ee55-46ed-a892-a5652001913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscidf_long = pd.melt(osci_datalist[0], id_vars=['Time'], value_vars=['Channel A', 'Channel B', 'Channel C', 'Channel D'])\n",
    "fig2, yax_dict = plotly_multiyplot(data=oscidf_long, multiy_col='variable', yvars=['Channel C', 'Channel D'], x='Time', y='value')\n",
    "fig2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
